{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Tagging_Testkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagger f√ºr POS\n",
    "In diesem Jupyter Notebook wird ein Testkorpus testkorpus_divers_50.csv erstellt, welches verschiedene Schwierigkeiten wie Rechtschreibfehler, Hashes, @ und Emojis enth√§lt. Danach wird die Datei anhand mehrerer verschiedener Modelle getaggt, sodass verglichen werden kann, welches Modell am besten abschneidet. Die Entscheidung wird mit meinem pers√∂nlichen Eindruck begr√ºndet und nicht quantifiziert.\n",
    "Im Folgenden werden immer die gleichen 50 Zeilen der Testkorpora gezeigt, um einen ersten Eindruck der Performance zu erhalten. F√ºr einen zuverl√§ssigen und quaitativ h√∂heren Eindruck wurden die Dateien allerdings alle einzeln ge√∂ffnet und Zeile f√ºr Zeile miteinander verglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verschiedene Tagsets:\n",
    "https://universaldependencies.org/introduction.html\n",
    "- Penn Treebank Tags: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "- Universal Dependencies:\n",
    "https://universaldependencies.org/u/pos/\n",
    "https://huggingface.co/flair/upos-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcher Tagger eignet sich am Besten:\n",
    "- 01 Spacy\n",
    "- 02 Flair\n",
    "- 03 Bert\n",
    "- 04 Tweebank\n",
    "- 05 Stanza\n",
    "- Variationen & Kombinationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testkorpus, mit dem verschiedene Tagger getestet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation: conda install -c conda-forge pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41873</th>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>3498743628</td>\n",
       "      <td>Reminder: The Miss Universe competition will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>367977996541788160</td>\n",
       "      <td>@Timc1021 Thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50189</th>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>344775405057753088</td>\n",
       "      <td>\"\"@_KatherineWebb: Looking forward to #MissUSA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14002</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>110498268480198144</td>\n",
       "      <td>Addressing  the Rise of Chronic Childhood Illn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35985</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>1259672385286012928</td>\n",
       "      <td>RT @darhar981: Attorney General Barr‚Äôs Office ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11663</th>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>111274504071323312</td>\n",
       "      <td>RT  @MagaGlamüá∫üá∏‚ô•Ô∏è Bring Back  Trump  üíôüá∫üá∏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22194</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>109360482610823936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>2755</td>\n",
       "      <td>The CBP Home App is now available across all m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84855</th>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>1087867453684834304</td>\n",
       "      <td>Congratulations to Mariano Rivera on unanimous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63673</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>616265476616900608</td>\n",
       "      <td>My recent statement re: @macys -- We must have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73306</th>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>888429879603191808</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25584</th>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>108982117859170992</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75452</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>1047477260624773120</td>\n",
       "      <td>Thank you Governor Phil Bryant - it was my gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74381</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>819541997325316096</td>\n",
       "      <td>Thank you to Linda Bean of L.L.Bean for your g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64455</th>\n",
       "      <td>2015-05-21</td>\n",
       "      <td>601265719007944704</td>\n",
       "      <td>\"\"@HarmonBrew: @FoxNews @megynkelly  DonaldTru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>1308</td>\n",
       "      <td>We now have complete and total control of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2025-07-27</td>\n",
       "      <td>537</td>\n",
       "      <td>https://www.thegatewaypundit.com/2025/07/her-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16522</th>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>111495112104730624</td>\n",
       "      <td>https://www.foxnews.com/politics/hunter-biden-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58345</th>\n",
       "      <td>2014-05-23</td>\n",
       "      <td>469850924102737920</td>\n",
       "      <td>Via @BreitbartNews by @TheTonyLee: \"\"@Citizens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62504</th>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>639018768665063424</td>\n",
       "      <td>\"\"@LBabcock2:  @oreillyfactor @FoxNews I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34847</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1247268841845141504</td>\n",
       "      <td>Congratulations to State Representative Karen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38961</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>1242432301885198336</td>\n",
       "      <td>Congress must approve the deal, without all of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16744</th>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>111454972255115328</td>\n",
       "      <td>https://justthenews.com/politics-policy/all-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33783</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>1209838086730981376</td>\n",
       "      <td>RT @FLOTUS: Wishing you all a very #MerryChris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>2877</td>\n",
       "      <td>The United States of America is going to take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>3717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12733</th>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>111092587326199136</td>\n",
       "      <td>RT  @mrddmiaIf Trump didn't  incite the Januar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31395</th>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>1058482506037641216</td>\n",
       "      <td>JOBS, JOBS, JOBS! #MAGA https://t.co/ZqPjsPUX0t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72689</th>\n",
       "      <td>2017-09-27</td>\n",
       "      <td>913034591879024640</td>\n",
       "      <td>Facebook was always anti-Trump.The Networks we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56697</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>506380656998641664</td>\n",
       "      <td>\"\"@NPHerron: @realDonaldTrump For president #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49389</th>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>357591410251284480</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>1324928487807995904</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26930</th>\n",
       "      <td>2011-09-11</td>\n",
       "      <td>112707729209876672</td>\n",
       "      <td>RT  @IStandWithTrump47November 5th can‚Äôt  come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64605</th>\n",
       "      <td>2015-05-15</td>\n",
       "      <td>599019686286774272</td>\n",
       "      <td>\"\"@JDrago28: It was such an honor to meet @rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82034</th>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>1153992334054440960</td>\n",
       "      <td>Why didn‚Äôt Robert Mueller &amp;amp, his band of 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33698</th>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>1258465767751856128</td>\n",
       "      <td>Today, @FLOTUS celebrates the two year anniver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73710</th>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>865957909565366272</td>\n",
       "      <td>Thank you to the BRAVE servicemen &amp;amp, women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38651</th>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>1296579488998928384</td>\n",
       "      <td>THANK YOU PENNSYLVANIA! #MAGA https://t.co/5Bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32258</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>1271082251791499264</td>\n",
       "      <td>THOSE THAT DENY THEIR HISTORY ARE DOOMED TO RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18604</th>\n",
       "      <td>2011-09-12</td>\n",
       "      <td>113125743674703328</td>\n",
       "      <td>https://www.washingtonexaminer.com/news/campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79037</th>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>1194414141550796800</td>\n",
       "      <td>RT @IvankaTrump: It is an honor to serve our g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49923</th>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>350632506485243904</td>\n",
       "      <td>Situated in the heart of downtown Toronto, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13576</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>110579568469291920</td>\n",
       "      <td>RT  @realDonaldTrumpUsing Impoundment to  Slas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13843</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>110519725006339152</td>\n",
       "      <td>RT  @gatewaypunditANOTHER  BOGUS ATTACK: DC Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34004</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>1272155593143353344</td>\n",
       "      <td>Thank you Philip! https://t.co/jGspqbtSgL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58615</th>\n",
       "      <td>2014-05-02</td>\n",
       "      <td>462220477185150976</td>\n",
       "      <td>With @VanityFair circulation and advertising r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57196</th>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>491668720444792832</td>\n",
       "      <td>Thanks @LilJon for coming to my defense in Rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31889</th>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>1256625602528006144</td>\n",
       "      <td>RT @ScottAdamsSays: Poll for Democrats only. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55874</th>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>523144417532997632</td>\n",
       "      <td>I love seeing that Graydon Carter and @VanityF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>3157</td>\n",
       "      <td>The month of February, my first full month in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                   id  \\\n",
       "41873  2010-11-04           3498743628   \n",
       "48694  2013-08-15   367977996541788160   \n",
       "50189  2013-06-12   344775405057753088   \n",
       "14002  2011-09-04   110498268480198144   \n",
       "35985  2020-05-11  1259672385286012928   \n",
       "11663  2011-09-07   111274504071323312   \n",
       "22194  2011-09-01   109360482610823936   \n",
       "2495   2025-03-19                 2755   \n",
       "84855  2019-01-23  1087867453684834304   \n",
       "63673  2015-07-01   616265476616900608   \n",
       "73306  2017-07-21   888429879603191808   \n",
       "25584  2011-08-31   108982117859170992   \n",
       "75452  2018-10-03  1047477260624773120   \n",
       "74381  2017-01-12   819541997325316096   \n",
       "64455  2015-05-21   601265719007944704   \n",
       "1204   2025-06-17                 1308   \n",
       "480    2025-07-27                  537   \n",
       "16522  2011-09-07   111495112104730624   \n",
       "58345  2014-05-23   469850924102737920   \n",
       "62504  2015-09-02   639018768665063424   \n",
       "34847  2020-04-06  1247268841845141504   \n",
       "38961  2020-03-24  1242432301885198336   \n",
       "16744  2011-09-07   111454972255115328   \n",
       "33783  2019-12-25  1209838086730981376   \n",
       "2610   2025-03-12                 2877   \n",
       "3211   2025-01-31                 3717   \n",
       "12733  2011-09-06   111092587326199136   \n",
       "31395  2018-11-02  1058482506037641216   \n",
       "72689  2017-09-27   913034591879024640   \n",
       "56697  2014-09-01   506380656998641664   \n",
       "49389  2013-07-17   357591410251284480   \n",
       "31099  2020-11-07  1324928487807995904   \n",
       "26930  2011-09-11   112707729209876672   \n",
       "64605  2015-05-15   599019686286774272   \n",
       "82034  2019-07-24  1153992334054440960   \n",
       "33698  2020-05-07  1258465767751856128   \n",
       "73710  2017-05-20   865957909565366272   \n",
       "38651  2020-08-20  1296579488998928384   \n",
       "32258  2020-06-11  1271082251791499264   \n",
       "18604  2011-09-12   113125743674703328   \n",
       "79037  2019-11-13  1194414141550796800   \n",
       "49923  2013-06-28   350632506485243904   \n",
       "13576  2011-09-05   110579568469291920   \n",
       "13843  2011-09-05   110519725006339152   \n",
       "34004  2020-06-14  1272155593143353344   \n",
       "58615  2014-05-02   462220477185150976   \n",
       "57196  2014-07-22   491668720444792832   \n",
       "31889  2020-05-02  1256625602528006144   \n",
       "55874  2014-10-17   523144417532997632   \n",
       "2772   2025-03-01                 3157   \n",
       "\n",
       "                                                    text  \n",
       "41873  Reminder: The Miss Universe competition will b...  \n",
       "48694                                  @Timc1021 Thanks!  \n",
       "50189  \"\"@_KatherineWebb: Looking forward to #MissUSA...  \n",
       "14002  Addressing  the Rise of Chronic Childhood Illn...  \n",
       "35985  RT @darhar981: Attorney General Barr‚Äôs Office ...  \n",
       "11663           RT  @MagaGlamüá∫üá∏‚ô•Ô∏è Bring Back  Trump  üíôüá∫üá∏  \n",
       "22194                                                NaN  \n",
       "2495   The CBP Home App is now available across all m...  \n",
       "84855  Congratulations to Mariano Rivera on unanimous...  \n",
       "63673  My recent statement re: @macys -- We must have...  \n",
       "73306  ICYMI- This week we hosted a #MadeInAmerica ev...  \n",
       "25584  https://www.mediaite.com/tv/trump-team-scored-...  \n",
       "75452  Thank you Governor Phil Bryant - it was my gre...  \n",
       "74381  Thank you to Linda Bean of L.L.Bean for your g...  \n",
       "64455  \"\"@HarmonBrew: @FoxNews @megynkelly  DonaldTru...  \n",
       "1204   We now have complete and total control of the ...  \n",
       "480    https://www.thegatewaypundit.com/2025/07/her-b...  \n",
       "16522  https://www.foxnews.com/politics/hunter-biden-...  \n",
       "58345  Via @BreitbartNews by @TheTonyLee: \"\"@Citizens...  \n",
       "62504  \"\"@LBabcock2:  @oreillyfactor @FoxNews I have ...  \n",
       "34847  Congratulations to State Representative Karen ...  \n",
       "38961  Congress must approve the deal, without all of...  \n",
       "16744  https://justthenews.com/politics-policy/all-th...  \n",
       "33783  RT @FLOTUS: Wishing you all a very #MerryChris...  \n",
       "2610   The United States of America is going to take ...  \n",
       "3211                                                 NaN  \n",
       "12733  RT  @mrddmiaIf Trump didn't  incite the Januar...  \n",
       "31395    JOBS, JOBS, JOBS! #MAGA https://t.co/ZqPjsPUX0t  \n",
       "72689  Facebook was always anti-Trump.The Networks we...  \n",
       "56697  \"\"@NPHerron: @realDonaldTrump For president #2...  \n",
       "49389  The Zimmerman trial is over.  It is time to mo...  \n",
       "31099  RT @dbongino: The Polls Were More Wrong in 202...  \n",
       "26930  RT  @IStandWithTrump47November 5th can‚Äôt  come...  \n",
       "64605  \"\"@JDrago28: It was such an honor to meet @rea...  \n",
       "82034  Why didn‚Äôt Robert Mueller &amp, his band of 18...  \n",
       "33698  Today, @FLOTUS celebrates the two year anniver...  \n",
       "73710  Thank you to the BRAVE servicemen &amp, women ...  \n",
       "38651  THANK YOU PENNSYLVANIA! #MAGA https://t.co/5Bf...  \n",
       "32258  THOSE THAT DENY THEIR HISTORY ARE DOOMED TO RE...  \n",
       "18604  https://www.washingtonexaminer.com/news/campai...  \n",
       "79037  RT @IvankaTrump: It is an honor to serve our g...  \n",
       "49923  Situated in the heart of downtown Toronto, the...  \n",
       "13576  RT  @realDonaldTrumpUsing Impoundment to  Slas...  \n",
       "13843  RT  @gatewaypunditANOTHER  BOGUS ATTACK: DC Co...  \n",
       "34004          Thank you Philip! https://t.co/jGspqbtSgL  \n",
       "58615  With @VanityFair circulation and advertising r...  \n",
       "57196  Thanks @LilJon for coming to my defense in Rol...  \n",
       "31889  RT @ScottAdamsSays: Poll for Democrats only. A...  \n",
       "55874  I love seeing that Graydon Carter and @VanityF...  \n",
       "2772   The month of February, my first full month in ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ziel: ein m√∂glichst diverses Korpus erstellen, das alle relevanten F√§lle pr√ºft\n",
    "import pandas as pd\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from IPython.display import display\n",
    "\n",
    "spell = SpellChecker(language=\"en\")\n",
    "df = pd.read_csv(\"tta_final_clean.csv\")\n",
    "\n",
    "# Funktionen f√ºr verschiedene Post-Typen\n",
    "def has_mention(x): return \"@\" in str(x)\n",
    "def has_hashtag(x): return \"#\" in str(x)\n",
    "def has_url(x): return re.search(r\"http[s]?://\", str(x)) is not None\n",
    "def has_emoji(x): return re.search(r\"[\\U00010000-\\U0010ffff]\", str(x)) is not None\n",
    "def is_long(x): return len(str(x)) > 200\n",
    "def has_typo(x): return re.compile(\n",
    "    r\"\\b(\"\n",
    "    r\"teh|recieve|definately|seperat(?:e|ely)|occured|untill|wich|\"\n",
    "    r\"neccessary|adress|tomm?orow|becuase|wierd|yeee?s\"\n",
    "    r\")\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "def has_typo_spellchecker(text):\n",
    "    words = str(text).split()\n",
    "    misspelled = spell.unknown(words)   # W√∂rter, die nicht im W√∂rterbuch sind\n",
    "    return len(misspelled) > 0\n",
    "\n",
    "samples = []\n",
    "# je 5 Beispiele (wenn vorhanden)\n",
    "samples.append(df[df['text'].apply(is_long)].sample(n=5, random_state=1))\n",
    "samples.append(df[df['text'].apply(has_mention)].sample(n=5, random_state=2))\n",
    "samples.append(df[df['text'].apply(has_hashtag)].sample(n=5, random_state=3))\n",
    "samples.append(df[df['text'].apply(has_url)].sample(n=5, random_state=4))\n",
    "samples.append(df[df['text'].apply(has_emoji)].sample(n=5, random_state=5))\n",
    "#samples.append(df[df['text'].apply(has_typo)].sample(n=5, random_state=6))\n",
    "samples.append(df[df[\"text\"].apply(has_typo_spellchecker)].sample(n=5, random_state=6))\n",
    "#df[\"text\"].apply(has_typo_spellchecker)\n",
    "\n",
    "# Rest zuf√§llig auff√ºllen bis 50\n",
    "already = pd.concat(samples)\n",
    "remaining = df.drop(already.index)\n",
    "rest = remaining.sample(n=50-len(already), random_state=42)\n",
    "\n",
    "# finales Testkorpus\n",
    "test_divers = pd.concat([already, rest]).sample(frac=1, random_state=99)\n",
    "test_divers.to_csv(\"test_full.csv\", index=False)\n",
    "test_divers = test_divers[['date', 'id', 'text']]\n",
    "display(test_divers.head(50))\n",
    "test_divers.to_csv(\"testkorpus_divers_50.csv\", index=False)\n",
    "# Anmerkung: statt print verwende ich aufgrund der sch√∂neren Ansicht display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_divers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_divers.to_json(\"testkorpus_divers_50.json\", orient=\"records\", force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 SpaCy\n",
    "- https://huggingface.co/spacy/en_core_web_sm\n",
    "- https://github.com/explosion/spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Donald PROPN NNP\n",
      "Trump Trump PROPN NNP\n",
      "posted post VERB VBD\n",
      "a a DET DT\n",
      "new new ADJ JJ\n",
      "tweet tweet NOUN NN\n",
      ". . PUNCT .\n",
      "# # X ADD\n",
      "realdonaldtrump realdonaldtrump NOUN NN\n",
      "@realdonaldtrump @realdonaldtrump PROPN NNP\n",
      "! ! PUNCT .\n",
      "@ben4appel @ben4appel PROPN NNP\n",
      "ü§£ ü§£ PROPN NNP\n",
      ":) :) PUNCT :\n",
      "https://t.co/bsB6rVV7Yn https://t.co/bsb6rvv7yn NOUN NN\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Donald Trump posted a new tweet. #realdonaldtrump @realdonaldtrump! @ben4appel ü§£ :) https://t.co/bsB6rVV7Yn\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_)\n",
    "# besser w√§re, wenn die Hashes nicht zerlegt werden.\n",
    "# und Emojis nicht als Eigennamen angesehen werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>16</td>\n",
       "      <td>skies</td>\n",
       "      <td>sky</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>sky_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>16</td>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "      <td>ADP</td>\n",
       "      <td>over_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>16</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Iran</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Iran_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>16</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Iran</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Iran_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>16</td>\n",
       "      <td>had</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>have_VERB</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>16</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>good_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>16</td>\n",
       "      <td>sky</td>\n",
       "      <td>sky</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>sky_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>16</td>\n",
       "      <td>trackers</td>\n",
       "      <td>tracker</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>tracker_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>16</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>16</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>other_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>16</td>\n",
       "      <td>defensive</td>\n",
       "      <td>defensive</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>defensive_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>16</td>\n",
       "      <td>equipment</td>\n",
       "      <td>equipment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>equipment_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>16</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>16</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>16</td>\n",
       "      <td>plenty</td>\n",
       "      <td>plenty</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>plenty_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>16</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>16</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>16</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>16</td>\n",
       "      <td>but</td>\n",
       "      <td>but</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>but_CCONJ</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>16</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>16</td>\n",
       "      <td>does</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>do_AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>16</td>\n",
       "      <td>n‚Äôt</td>\n",
       "      <td>not</td>\n",
       "      <td>PART</td>\n",
       "      <td>not_PART</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>16</td>\n",
       "      <td>compare</td>\n",
       "      <td>compare</td>\n",
       "      <td>VERB</td>\n",
       "      <td>compare_VERB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>16</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>16</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>American_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>16</td>\n",
       "      <td>made</td>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>make_VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>16</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>16</td>\n",
       "      <td>conceived</td>\n",
       "      <td>conceive</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conceive_VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>16</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>16</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>16</td>\n",
       "      <td>manufactured</td>\n",
       "      <td>manufacture</td>\n",
       "      <td>VERB</td>\n",
       "      <td>manufacture_VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>16</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "      <td>``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>16</td>\n",
       "      <td>stuff</td>\n",
       "      <td>stuff</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>stuff_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>16</td>\n",
       "      <td>‚Äù</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "      <td>''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>16</td>\n",
       "      <td>Nobody</td>\n",
       "      <td>nobody</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nobody_PRON</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>16</td>\n",
       "      <td>does</td>\n",
       "      <td>do</td>\n",
       "      <td>VERB</td>\n",
       "      <td>do_VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>16</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>16</td>\n",
       "      <td>better</td>\n",
       "      <td>well</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>well_ADJ</td>\n",
       "      <td>JJR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>16</td>\n",
       "      <td>than</td>\n",
       "      <td>than</td>\n",
       "      <td>ADP</td>\n",
       "      <td>than_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>16</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>16</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>good_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>16</td>\n",
       "      <td>ol‚Äô</td>\n",
       "      <td>ol‚Äô</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ol‚Äô_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>16</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>USA_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>17</td>\n",
       "      <td>https://www.thegatewaypundit.com/2025/07/her-b...</td>\n",
       "      <td>https://www.thegatewaypundit.com/2025/07/her-b...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>https://www.thegatewaypundit.com/2025/07/her-b...</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>18</td>\n",
       "      <td>https://www.foxnews.com/politics/hunter-biden-...</td>\n",
       "      <td>https://www.foxnews.com/politics/hunter-biden-...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>https://www.foxnews.com/politics/hunter-biden-...</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>19</td>\n",
       "      <td>Via</td>\n",
       "      <td>Via</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Via_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>19</td>\n",
       "      <td>@BreitbartNews</td>\n",
       "      <td>@BreitbartNews</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@BreitbartNews_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                               word  \\\n",
       "310       16                                              skies   \n",
       "311       16                                               over   \n",
       "312       16                                               Iran   \n",
       "313       16                                                  .   \n",
       "314       16                                               Iran   \n",
       "315       16                                                had   \n",
       "316       16                                               good   \n",
       "317       16                                                sky   \n",
       "318       16                                           trackers   \n",
       "319       16                                                and   \n",
       "320       16                                              other   \n",
       "321       16                                          defensive   \n",
       "322       16                                          equipment   \n",
       "323       16                                                  ,   \n",
       "324       16                                                and   \n",
       "325       16                                             plenty   \n",
       "326       16                                                 of   \n",
       "327       16                                                 it   \n",
       "328       16                                                  ,   \n",
       "329       16                                                but   \n",
       "330       16                                                 it   \n",
       "331       16                                               does   \n",
       "332       16                                                n‚Äôt   \n",
       "333       16                                            compare   \n",
       "334       16                                                 to   \n",
       "335       16                                           American   \n",
       "336       16                                               made   \n",
       "337       16                                                  ,   \n",
       "338       16                                          conceived   \n",
       "339       16                                                  ,   \n",
       "340       16                                                and   \n",
       "341       16                                       manufactured   \n",
       "342       16                                                  ‚Äú   \n",
       "343       16                                              stuff   \n",
       "344       16                                                  .   \n",
       "345       16                                                  ‚Äù   \n",
       "346       16                                             Nobody   \n",
       "347       16                                               does   \n",
       "348       16                                                 it   \n",
       "349       16                                             better   \n",
       "350       16                                               than   \n",
       "351       16                                                the   \n",
       "352       16                                               good   \n",
       "353       16                                                ol‚Äô   \n",
       "354       16                                                USA   \n",
       "355       16                                                  .   \n",
       "356       17  https://www.thegatewaypundit.com/2025/07/her-b...   \n",
       "357       18  https://www.foxnews.com/politics/hunter-biden-...   \n",
       "358       19                                                Via   \n",
       "359       19                                     @BreitbartNews   \n",
       "\n",
       "                                                 lemma    pos  \\\n",
       "310                                                sky   NOUN   \n",
       "311                                               over    ADP   \n",
       "312                                               Iran  PROPN   \n",
       "313                                                  .  PUNCT   \n",
       "314                                               Iran  PROPN   \n",
       "315                                               have   VERB   \n",
       "316                                               good    ADJ   \n",
       "317                                                sky   NOUN   \n",
       "318                                            tracker   NOUN   \n",
       "319                                                and  CCONJ   \n",
       "320                                              other    ADJ   \n",
       "321                                          defensive    ADJ   \n",
       "322                                          equipment   NOUN   \n",
       "323                                                  ,  PUNCT   \n",
       "324                                                and  CCONJ   \n",
       "325                                             plenty   NOUN   \n",
       "326                                                 of    ADP   \n",
       "327                                                 it   PRON   \n",
       "328                                                  ,  PUNCT   \n",
       "329                                                but  CCONJ   \n",
       "330                                                 it   PRON   \n",
       "331                                                 do    AUX   \n",
       "332                                                not   PART   \n",
       "333                                            compare   VERB   \n",
       "334                                                 to    ADP   \n",
       "335                                           American  PROPN   \n",
       "336                                               make   VERB   \n",
       "337                                                  ,  PUNCT   \n",
       "338                                           conceive   VERB   \n",
       "339                                                  ,  PUNCT   \n",
       "340                                                and  CCONJ   \n",
       "341                                        manufacture   VERB   \n",
       "342                                                  \"  PUNCT   \n",
       "343                                              stuff   NOUN   \n",
       "344                                                  .  PUNCT   \n",
       "345                                                  \"  PUNCT   \n",
       "346                                             nobody   PRON   \n",
       "347                                                 do   VERB   \n",
       "348                                                 it   PRON   \n",
       "349                                               well    ADJ   \n",
       "350                                               than    ADP   \n",
       "351                                                the    DET   \n",
       "352                                               good    ADJ   \n",
       "353                                                ol‚Äô    ADJ   \n",
       "354                                                USA  PROPN   \n",
       "355                                                  .  PUNCT   \n",
       "356  https://www.thegatewaypundit.com/2025/07/her-b...  PROPN   \n",
       "357  https://www.foxnews.com/politics/hunter-biden-...  PROPN   \n",
       "358                                                Via  PROPN   \n",
       "359                                     @BreitbartNews  PROPN   \n",
       "\n",
       "                                               lemma_p  tag  \n",
       "310                                           sky_NOUN  NNS  \n",
       "311                                           over_ADP   IN  \n",
       "312                                         Iran_PROPN  NNP  \n",
       "313                                            ._PUNCT    .  \n",
       "314                                         Iran_PROPN  NNP  \n",
       "315                                          have_VERB  VBD  \n",
       "316                                           good_ADJ   JJ  \n",
       "317                                           sky_NOUN   NN  \n",
       "318                                       tracker_NOUN  NNS  \n",
       "319                                          and_CCONJ   CC  \n",
       "320                                          other_ADJ   JJ  \n",
       "321                                      defensive_ADJ   JJ  \n",
       "322                                     equipment_NOUN   NN  \n",
       "323                                            ,_PUNCT    ,  \n",
       "324                                          and_CCONJ   CC  \n",
       "325                                        plenty_NOUN   NN  \n",
       "326                                             of_ADP   IN  \n",
       "327                                            it_PRON  PRP  \n",
       "328                                            ,_PUNCT    ,  \n",
       "329                                          but_CCONJ   CC  \n",
       "330                                            it_PRON  PRP  \n",
       "331                                             do_AUX  VBZ  \n",
       "332                                           not_PART   RB  \n",
       "333                                       compare_VERB   VB  \n",
       "334                                             to_ADP   IN  \n",
       "335                                     American_PROPN  NNP  \n",
       "336                                          make_VERB  VBN  \n",
       "337                                            ,_PUNCT    ,  \n",
       "338                                      conceive_VERB  VBN  \n",
       "339                                            ,_PUNCT    ,  \n",
       "340                                          and_CCONJ   CC  \n",
       "341                                   manufacture_VERB  VBN  \n",
       "342                                            \"_PUNCT   ``  \n",
       "343                                         stuff_NOUN   NN  \n",
       "344                                            ._PUNCT    .  \n",
       "345                                            \"_PUNCT   ''  \n",
       "346                                        nobody_PRON   NN  \n",
       "347                                            do_VERB  VBZ  \n",
       "348                                            it_PRON  PRP  \n",
       "349                                           well_ADJ  JJR  \n",
       "350                                           than_ADP   IN  \n",
       "351                                            the_DET   DT  \n",
       "352                                           good_ADJ   JJ  \n",
       "353                                            ol‚Äô_ADJ   JJ  \n",
       "354                                          USA_PROPN  NNP  \n",
       "355                                            ._PUNCT    .  \n",
       "356  https://www.thegatewaypundit.com/2025/07/her-b...  NNP  \n",
       "357  https://www.foxnews.com/politics/hunter-biden-...  NNP  \n",
       "358                                          Via_PROPN  NNP  \n",
       "359                               @BreitbartNews_PROPN  NNP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### SpaCy ####\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "all_results = []\n",
    "\n",
    "for idx, text in enumerate(df[\"text\"], start=1):\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    doc = nlp(str(text))\n",
    "    for token in doc:\n",
    "        all_results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"word\": token.text,\n",
    "            \"lemma\": token.lemma_,\n",
    "            \"pos\": token.pos_,\n",
    "            \"lemma_p\": f\"{token.lemma_}_{token.pos_}\",\n",
    "            \"tag\": token.tag_\n",
    "        })\n",
    "\n",
    "sp = pd.DataFrame(all_results)\n",
    "sp.to_csv(\"testkorpus_divers_50_spacy.csv\", index=False)\n",
    "display(sp[310:360])\n",
    "# der Code funktioniert; allerdings werden Emojis, @ und Post-spezifische Dinge nicht erkannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>SYM</td>\n",
       "      <td>#_SYM</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>11</td>\n",
       "      <td>MadeInAmerica</td>\n",
       "      <td>MadeInAmerica</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>MadeInAmerica_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>event_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>ADV</td>\n",
       "      <td>right_ADV</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "      <td>ADV</td>\n",
       "      <td>here_ADV</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>at_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>11</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11</td>\n",
       "      <td>@WhiteHouse</td>\n",
       "      <td>@whitehouse</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>@whitehouse_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>11</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>11</td>\n",
       "      <td>If</td>\n",
       "      <td>if</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>if_SCONJ</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>11</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>11</td>\n",
       "      <td>MADE</td>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>make_VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id           word          lemma    pos              lemma_p  tag\n",
       "200       11              #              #    SYM                #_SYM    $\n",
       "201       11  MadeInAmerica  MadeInAmerica  PROPN  MadeInAmerica_PROPN  NNP\n",
       "202       11          event          event   NOUN           event_NOUN   NN\n",
       "203       11              ,              ,  PUNCT              ,_PUNCT    ,\n",
       "204       11          right          right    ADV            right_ADV   RB\n",
       "205       11           here           here    ADV             here_ADV   RB\n",
       "206       11             at             at    ADP               at_ADP   IN\n",
       "207       11            the            the    DET              the_DET   DT\n",
       "208       11    @WhiteHouse    @whitehouse   NOUN     @whitehouse_NOUN   NN\n",
       "209       11              !              !  PUNCT              !_PUNCT    .\n",
       "210       11             If             if  SCONJ             if_SCONJ   IN\n",
       "211       11             it             it   PRON              it_PRON  PRP\n",
       "212       11             is             be    AUX               be_AUX  VBZ\n",
       "213       11           MADE           make   VERB            make_VERB  VBN\n",
       "214       11             IN             in    ADP               in_ADP   IN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sp = pd.read_csv(\"testkorpus_divers_50_spacy.csv\")\n",
    "display(sp[200:215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>50</td>\n",
       "      <td>ALL</td>\n",
       "      <td>all</td>\n",
       "      <td>PRON</td>\n",
       "      <td>all_PRON</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>50</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>50</td>\n",
       "      <td>them</td>\n",
       "      <td>they</td>\n",
       "      <td>PRON</td>\n",
       "      <td>they_PRON</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>50</td>\n",
       "      <td>were</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>50</td>\n",
       "      <td>released</td>\n",
       "      <td>release</td>\n",
       "      <td>VERB</td>\n",
       "      <td>release_VERB</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>50</td>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>ADP</td>\n",
       "      <td>into_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>50</td>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>our_PRON</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>50</td>\n",
       "      <td>Country</td>\n",
       "      <td>Country</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Country_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>50</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>50</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>thank</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>thank_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>50</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>50</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>50</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>50</td>\n",
       "      <td>Administration</td>\n",
       "      <td>Administration</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Administration_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>50</td>\n",
       "      <td>Policies</td>\n",
       "      <td>Policies</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Policies_PROPN</td>\n",
       "      <td>NNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>50</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>50</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>50</td>\n",
       "      <td>Border</td>\n",
       "      <td>Border</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Border_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>50</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>50</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>closed</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>closed_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>50</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>50</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>50</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Illegal_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>50</td>\n",
       "      <td>Immigrants</td>\n",
       "      <td>Immigrants</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Immigrants_PROPN</td>\n",
       "      <td>NNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>50</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>50</td>\n",
       "      <td>Anyone</td>\n",
       "      <td>anyone</td>\n",
       "      <td>PRON</td>\n",
       "      <td>anyone_PRON</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>50</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "      <td>PRON</td>\n",
       "      <td>who_PRON</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>50</td>\n",
       "      <td>tries</td>\n",
       "      <td>try</td>\n",
       "      <td>VERB</td>\n",
       "      <td>try_VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>50</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>50</td>\n",
       "      <td>illegally</td>\n",
       "      <td>illegally</td>\n",
       "      <td>ADV</td>\n",
       "      <td>illegally_ADV</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>50</td>\n",
       "      <td>enter</td>\n",
       "      <td>enter</td>\n",
       "      <td>VERB</td>\n",
       "      <td>enter_VERB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>50</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>50</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>U.S.A._PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>50</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>50</td>\n",
       "      <td>face</td>\n",
       "      <td>face</td>\n",
       "      <td>VERB</td>\n",
       "      <td>face_VERB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>50</td>\n",
       "      <td>significant</td>\n",
       "      <td>significant</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>significant_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>50</td>\n",
       "      <td>criminal</td>\n",
       "      <td>criminal</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>criminal_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>50</td>\n",
       "      <td>penalties</td>\n",
       "      <td>penalty</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>penalty_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>50</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>50</td>\n",
       "      <td>immediate</td>\n",
       "      <td>immediate</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>immediate_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>50</td>\n",
       "      <td>deportation</td>\n",
       "      <td>deportation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>deportation_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>50</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id            word           lemma    pos               lemma_p  \\\n",
       "1200       50             ALL             all   PRON              all_PRON   \n",
       "1201       50              of              of    ADP                of_ADP   \n",
       "1202       50            them            they   PRON             they_PRON   \n",
       "1203       50            were              be    AUX                be_AUX   \n",
       "1204       50        released         release   VERB          release_VERB   \n",
       "1205       50            into            into    ADP              into_ADP   \n",
       "1206       50             our             our   PRON              our_PRON   \n",
       "1207       50         Country         Country  PROPN         Country_PROPN   \n",
       "1208       50               .               .  PUNCT               ._PUNCT   \n",
       "1209       50          Thanks           thank   NOUN            thank_NOUN   \n",
       "1210       50              to              to    ADP                to_ADP   \n",
       "1211       50             the             the    DET               the_DET   \n",
       "1212       50           Trump           Trump  PROPN           Trump_PROPN   \n",
       "1213       50  Administration  Administration  PROPN  Administration_PROPN   \n",
       "1214       50        Policies        Policies  PROPN        Policies_PROPN   \n",
       "1215       50               ,               ,  PUNCT               ,_PUNCT   \n",
       "1216       50             the             the    DET               the_DET   \n",
       "1217       50          Border          Border  PROPN          Border_PROPN   \n",
       "1218       50              is              be    AUX                be_AUX   \n",
       "1219       50          CLOSED          closed    ADJ            closed_ADJ   \n",
       "1220       50              to              to    ADP                to_ADP   \n",
       "1221       50             all             all    DET               all_DET   \n",
       "1222       50         Illegal         Illegal  PROPN         Illegal_PROPN   \n",
       "1223       50      Immigrants      Immigrants  PROPN      Immigrants_PROPN   \n",
       "1224       50               .               .  PUNCT               ._PUNCT   \n",
       "1225       50          Anyone          anyone   PRON           anyone_PRON   \n",
       "1226       50             who             who   PRON              who_PRON   \n",
       "1227       50           tries             try   VERB              try_VERB   \n",
       "1228       50              to              to   PART               to_PART   \n",
       "1229       50       illegally       illegally    ADV         illegally_ADV   \n",
       "1230       50           enter           enter   VERB            enter_VERB   \n",
       "1231       50             the             the    DET               the_DET   \n",
       "1232       50          U.S.A.          U.S.A.  PROPN          U.S.A._PROPN   \n",
       "1233       50            will            will    AUX              will_AUX   \n",
       "1234       50            face            face   VERB             face_VERB   \n",
       "1235       50     significant     significant    ADJ       significant_ADJ   \n",
       "1236       50        criminal        criminal    ADJ          criminal_ADJ   \n",
       "1237       50       penalties         penalty   NOUN          penalty_NOUN   \n",
       "1238       50             and             and  CCONJ             and_CCONJ   \n",
       "1239       50       immediate       immediate    ADJ         immediate_ADJ   \n",
       "1240       50     deportation     deportation   NOUN      deportation_NOUN   \n",
       "1241       50               .               .  PUNCT               ._PUNCT   \n",
       "\n",
       "       tag  \n",
       "1200    DT  \n",
       "1201    IN  \n",
       "1202   PRP  \n",
       "1203   VBD  \n",
       "1204   VBN  \n",
       "1205    IN  \n",
       "1206  PRP$  \n",
       "1207   NNP  \n",
       "1208     .  \n",
       "1209   NNS  \n",
       "1210    IN  \n",
       "1211    DT  \n",
       "1212   NNP  \n",
       "1213   NNP  \n",
       "1214  NNPS  \n",
       "1215     ,  \n",
       "1216    DT  \n",
       "1217   NNP  \n",
       "1218   VBZ  \n",
       "1219    JJ  \n",
       "1220    IN  \n",
       "1221    DT  \n",
       "1222   NNP  \n",
       "1223  NNPS  \n",
       "1224     .  \n",
       "1225    NN  \n",
       "1226    WP  \n",
       "1227   VBZ  \n",
       "1228    TO  \n",
       "1229    RB  \n",
       "1230    VB  \n",
       "1231    DT  \n",
       "1232   NNP  \n",
       "1233    MD  \n",
       "1234    VB  \n",
       "1235    JJ  \n",
       "1236    JJ  \n",
       "1237   NNS  \n",
       "1238    CC  \n",
       "1239    JJ  \n",
       "1240    NN  \n",
       "1241     .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sp[1200:1242])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>Office</td>\n",
       "      <td>office</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>office_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>Shreds</td>\n",
       "      <td>shred</td>\n",
       "      <td>VERB</td>\n",
       "      <td>shred_VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>NBC</td>\n",
       "      <td>NBC</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NBC_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Chuck_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Todd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Todd_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>For</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>for_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'_PUNCT</td>\n",
       "      <td>``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Deceptive_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5</td>\n",
       "      <td>Editing</td>\n",
       "      <td>editing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>editing_NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äô</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'_PUNCT</td>\n",
       "      <td>''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5</td>\n",
       "      <td>Barr</td>\n",
       "      <td>Barr</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Barr_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>comment_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>\\n_SPACE</td>\n",
       "      <td>_SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "      <td>``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5</td>\n",
       "      <td>Meet</td>\n",
       "      <td>Meet</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Meet_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>The_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Press_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Äù</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "      <td>''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>todd_ADJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "      <td>NFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "      <td>_SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6</td>\n",
       "      <td>@MagaGlam</td>\n",
       "      <td>@magaglam</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@magaglam_SYM</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>X</td>\n",
       "      <td>üá∫_X</td>\n",
       "      <td>ADD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>üá∏_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6</td>\n",
       "      <td>‚ô•</td>\n",
       "      <td>‚ô•</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>‚ô•_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6</td>\n",
       "      <td>Ô∏è</td>\n",
       "      <td>Ô∏è</td>\n",
       "      <td>X</td>\n",
       "      <td>Ô∏è_X</td>\n",
       "      <td>ADD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADP</td>\n",
       "      <td>back_ADP</td>\n",
       "      <td>RP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "      <td>_SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>6</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "      <td>_SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6</td>\n",
       "      <td>üíô</td>\n",
       "      <td>üíô</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>üíô_PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>üá∫_NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id       word      lemma    pos          lemma_p  tag\n",
       "70         5         ‚Äôs         ‚Äôs   PART          ‚Äôs_PART  POS\n",
       "71         5     Office     office   NOUN      office_NOUN   NN\n",
       "72         5     Shreds      shred   VERB       shred_VERB  VBZ\n",
       "73         5        NBC        NBC  PROPN        NBC_PROPN  NNP\n",
       "74         5         ‚Äôs         ‚Äôs   PART          ‚Äôs_PART  POS\n",
       "75         5      Chuck      Chuck  PROPN      Chuck_PROPN  NNP\n",
       "76         5       Todd       Todd  PROPN       Todd_PROPN  NNP\n",
       "77         5        For        for    ADP          for_ADP   IN\n",
       "78         5          ‚Äò          '  PUNCT          '_PUNCT   ``\n",
       "79         5  Deceptive  Deceptive  PROPN  Deceptive_PROPN  NNP\n",
       "80         5    Editing    editing   NOUN     editing_NOUN   NN\n",
       "81         5          ‚Äô          '  PUNCT          '_PUNCT   ''\n",
       "82         5         Of         of    ADP           of_ADP   IN\n",
       "83         5       Barr       Barr  PROPN       Barr_PROPN  NNP\n",
       "84         5         ‚Äôs         ‚Äôs   PART          ‚Äôs_PART  POS\n",
       "85         5   Comments    comment   NOUN     comment_NOUN  NNS\n",
       "86         5         \\n         \\n  SPACE         \\n_SPACE  _SP\n",
       "87         5         On         on    ADP           on_ADP   IN\n",
       "88         5          ‚Äú          \"  PUNCT          \"_PUNCT   ``\n",
       "89         5       Meet       Meet  PROPN       Meet_PROPN  NNP\n",
       "90         5        The        The  PROPN        The_PROPN  NNP\n",
       "91         5      Press      Press  PROPN      Press_PROPN  NNP\n",
       "92         5          ,          ,  PUNCT          ,_PUNCT    ,\n",
       "93         5          ‚Äù          \"  PUNCT          \"_PUNCT   ''\n",
       "94         5       Todd       todd    ADJ         todd_ADJ   JJ\n",
       "95         5          ‚Ä¶          ‚Ä¶  PUNCT          ‚Ä¶_PUNCT  NFP\n",
       "96         6         RT         RT  PROPN         RT_PROPN  NNP\n",
       "97         6                        SPACE           _SPACE  _SP\n",
       "98         6  @MagaGlam  @magaglam    SYM    @magaglam_SYM  SYM\n",
       "99         6          üá∫          üá∫      X              üá∫_X  ADD\n",
       "100        6          üá∏          üá∏   NOUN           üá∏_NOUN  NNS\n",
       "101        6          ‚ô•          ‚ô•  PROPN          ‚ô•_PROPN  NNP\n",
       "102        6          Ô∏è          Ô∏è      X              Ô∏è_X  ADD\n",
       "103        6      Bring      bring   VERB       bring_VERB   VB\n",
       "104        6       Back       back    ADP         back_ADP   RP\n",
       "105        6                        SPACE           _SPACE  _SP\n",
       "106        6      Trump      Trump  PROPN      Trump_PROPN  NNP\n",
       "107        6                        SPACE           _SPACE  _SP\n",
       "108        6          üíô          üíô  PROPN          üíô_PROPN  NNP\n",
       "109        6          üá∫          üá∫   NOUN           üá∫_NOUN  NNS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sp[70:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.shape # Wie viele Tags wurden vergeben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>token_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>19</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>by_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>20</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>other_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>21</td>\n",
       "      <td>countries</td>\n",
       "      <td>country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>country_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>22</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>23</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>24</td>\n",
       "      <td>frankly</td>\n",
       "      <td>frankly</td>\n",
       "      <td>ADV</td>\n",
       "      <td>frankly_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>25</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>26</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td>by_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>27</td>\n",
       "      <td>incompetent</td>\n",
       "      <td>incompetent</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>incompetent_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>28</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>U.S._PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>29</td>\n",
       "      <td>leadership</td>\n",
       "      <td>leadership</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>leadership_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>30</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>31</td>\n",
       "      <td>We</td>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>we_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>32</td>\n",
       "      <td>'re</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>33</td>\n",
       "      <td>going</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>go_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>34</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>35</td>\n",
       "      <td>take</td>\n",
       "      <td>take</td>\n",
       "      <td>VERB</td>\n",
       "      <td>take_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>36</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>back_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>37</td>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>our_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>38</td>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>wealth_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>39</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>40</td>\n",
       "      <td>we</td>\n",
       "      <td>we</td>\n",
       "      <td>PRON</td>\n",
       "      <td>we_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>41</td>\n",
       "      <td>'re</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>42</td>\n",
       "      <td>take</td>\n",
       "      <td>take</td>\n",
       "      <td>VERB</td>\n",
       "      <td>take_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>43</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>back_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>44</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>a_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>45</td>\n",
       "      <td>lot</td>\n",
       "      <td>lot</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>lot_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>46</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>47</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>48</td>\n",
       "      <td>companies</td>\n",
       "      <td>company</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>company_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>49</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>that_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>50</td>\n",
       "      <td>left</td>\n",
       "      <td>leave</td>\n",
       "      <td>VERB</td>\n",
       "      <td>leave_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>25</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>51</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>1</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>3</td>\n",
       "      <td>@mrddmiaIf</td>\n",
       "      <td>@mrddmiaIf</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@mrddmiaIf_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>4</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>5</td>\n",
       "      <td>did</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>do_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>6</td>\n",
       "      <td>n't</td>\n",
       "      <td>not</td>\n",
       "      <td>PART</td>\n",
       "      <td>not_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>8</td>\n",
       "      <td>incite</td>\n",
       "      <td>incite</td>\n",
       "      <td>VERB</td>\n",
       "      <td>incite_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>9</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>10</td>\n",
       "      <td>January</td>\n",
       "      <td>January</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>January_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>11</td>\n",
       "      <td>6th</td>\n",
       "      <td>6th</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>6th_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>12</td>\n",
       "      <td>riot</td>\n",
       "      <td>riot</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>riot_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>13</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>14</td>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>what_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>15</td>\n",
       "      <td>'s</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>16</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>17</td>\n",
       "      <td>actual</td>\n",
       "      <td>actual</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>actual_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>18</td>\n",
       "      <td>crime</td>\n",
       "      <td>crime</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>crime_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>19</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>20</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>21</td>\n",
       "      <td>conspiracy?Objecting</td>\n",
       "      <td>conspiracy?objecte</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conspiracy?objecte_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>27</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>22</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date  token_id                  word               lemma  \\\n",
       "500       25  2025-03-12        19                    by                  by   \n",
       "501       25  2025-03-12        20                 other               other   \n",
       "502       25  2025-03-12        21             countries             country   \n",
       "503       25  2025-03-12        22                   and                 and   \n",
       "504       25  2025-03-12        23                     ,                   ,   \n",
       "505       25  2025-03-12        24               frankly             frankly   \n",
       "506       25  2025-03-12        25                     ,                   ,   \n",
       "507       25  2025-03-12        26                    by                  by   \n",
       "508       25  2025-03-12        27           incompetent         incompetent   \n",
       "509       25  2025-03-12        28                  U.S.                U.S.   \n",
       "510       25  2025-03-12        29            leadership          leadership   \n",
       "511       25  2025-03-12        30                     .                   .   \n",
       "512       25  2025-03-12        31                    We                  we   \n",
       "513       25  2025-03-12        32                   're                  be   \n",
       "514       25  2025-03-12        33                 going                  go   \n",
       "515       25  2025-03-12        34                    to                  to   \n",
       "516       25  2025-03-12        35                  take                take   \n",
       "517       25  2025-03-12        36                  back                back   \n",
       "518       25  2025-03-12        37                   our                 our   \n",
       "519       25  2025-03-12        38                wealth              wealth   \n",
       "520       25  2025-03-12        39                   and                 and   \n",
       "521       25  2025-03-12        40                    we                  we   \n",
       "522       25  2025-03-12        41                   're                  be   \n",
       "523       25  2025-03-12        42                  take                take   \n",
       "524       25  2025-03-12        43                  back                back   \n",
       "525       25  2025-03-12        44                     a                   a   \n",
       "526       25  2025-03-12        45                   lot                 lot   \n",
       "527       25  2025-03-12        46                    of                  of   \n",
       "528       25  2025-03-12        47                   the                 the   \n",
       "529       25  2025-03-12        48             companies             company   \n",
       "530       25  2025-03-12        49                  that                that   \n",
       "531       25  2025-03-12        50                  left               leave   \n",
       "532       25  2025-03-12        51                     ‚Ä¶                   ‚Ä¶   \n",
       "533       27  2011-09-06         1                    RT                  RT   \n",
       "534       27  2011-09-06         2                                             \n",
       "535       27  2011-09-06         3            @mrddmiaIf          @mrddmiaIf   \n",
       "536       27  2011-09-06         4                 Trump               Trump   \n",
       "537       27  2011-09-06         5                   did                  do   \n",
       "538       27  2011-09-06         6                   n't                 not   \n",
       "539       27  2011-09-06         7                                             \n",
       "540       27  2011-09-06         8                incite              incite   \n",
       "541       27  2011-09-06         9                   the                 the   \n",
       "542       27  2011-09-06        10               January             January   \n",
       "543       27  2011-09-06        11                   6th                 6th   \n",
       "544       27  2011-09-06        12                  riot                riot   \n",
       "545       27  2011-09-06        13                     ,                   ,   \n",
       "546       27  2011-09-06        14                  what                what   \n",
       "547       27  2011-09-06        15                    's                  be   \n",
       "548       27  2011-09-06        16                   the                 the   \n",
       "549       27  2011-09-06        17                actual              actual   \n",
       "550       27  2011-09-06        18                 crime               crime   \n",
       "551       27  2011-09-06        19                   and                 and   \n",
       "552       27  2011-09-06        20                                             \n",
       "553       27  2011-09-06        21  conspiracy?Objecting  conspiracy?objecte   \n",
       "554       27  2011-09-06        22                    to                  to   \n",
       "\n",
       "       pos                  lemma_p  \n",
       "500    ADP                   by_ADP  \n",
       "501    ADJ                other_ADJ  \n",
       "502   NOUN             country_NOUN  \n",
       "503  CCONJ                and_CCONJ  \n",
       "504  PUNCT                  ,_PUNCT  \n",
       "505    ADV              frankly_ADV  \n",
       "506  PUNCT                  ,_PUNCT  \n",
       "507    ADP                   by_ADP  \n",
       "508    ADJ          incompetent_ADJ  \n",
       "509  PROPN               U.S._PROPN  \n",
       "510   NOUN          leadership_NOUN  \n",
       "511  PUNCT                  ._PUNCT  \n",
       "512   PRON                  we_PRON  \n",
       "513    AUX                   be_AUX  \n",
       "514   VERB                  go_VERB  \n",
       "515   PART                  to_PART  \n",
       "516   VERB                take_VERB  \n",
       "517    ADV                 back_ADV  \n",
       "518   PRON                 our_PRON  \n",
       "519   NOUN              wealth_NOUN  \n",
       "520  CCONJ                and_CCONJ  \n",
       "521   PRON                  we_PRON  \n",
       "522    AUX                   be_AUX  \n",
       "523   VERB                take_VERB  \n",
       "524    ADV                 back_ADV  \n",
       "525    DET                    a_DET  \n",
       "526   NOUN                 lot_NOUN  \n",
       "527    ADP                   of_ADP  \n",
       "528    DET                  the_DET  \n",
       "529   NOUN             company_NOUN  \n",
       "530   PRON                that_PRON  \n",
       "531   VERB               leave_VERB  \n",
       "532  PUNCT                  ‚Ä¶_PUNCT  \n",
       "533  PROPN                 RT_PROPN  \n",
       "534  SPACE                   _SPACE  \n",
       "535  PROPN         @mrddmiaIf_PROPN  \n",
       "536  PROPN              Trump_PROPN  \n",
       "537    AUX                   do_AUX  \n",
       "538   PART                 not_PART  \n",
       "539  SPACE                   _SPACE  \n",
       "540   VERB              incite_VERB  \n",
       "541    DET                  the_DET  \n",
       "542  PROPN            January_PROPN  \n",
       "543   NOUN                 6th_NOUN  \n",
       "544   NOUN                riot_NOUN  \n",
       "545  PUNCT                  ,_PUNCT  \n",
       "546   PRON                what_PRON  \n",
       "547    AUX                   be_AUX  \n",
       "548    DET                  the_DET  \n",
       "549    ADJ               actual_ADJ  \n",
       "550   NOUN               crime_NOUN  \n",
       "551  CCONJ                and_CCONJ  \n",
       "552  SPACE                   _SPACE  \n",
       "553   VERB  conspiracy?objecte_VERB  \n",
       "554    ADP                   to_ADP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### 02 SpaCy ###\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "all_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    if pd.isna(text) or str(text).strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    doc = nlp(str(text))\n",
    "    \n",
    "    for token_id, token in enumerate(doc, start=1):\n",
    "        all_results.append({\n",
    "            \"post_id\": idx + 1,\n",
    "            \"date\": row[\"date\"],\n",
    "            \"token_id\": token_id,\n",
    "            \"word\": token.text,\n",
    "            \"lemma\": token.lemma_,\n",
    "            \"pos\": token.pos_,\n",
    "            \"lemma_p\": f\"{token.lemma_}_{token.pos_}\"\n",
    "        })\n",
    "\n",
    "sp2 = pd.DataFrame(all_results)\n",
    "sp2.to_csv(\"testkorpus_divers_50_spacy2.csv\", index=False, encoding=\"utf-8\")\n",
    "display(sp2[500:555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>token_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>7</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>8</td>\n",
       "      <td>Office</td>\n",
       "      <td>office</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>office_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>9</td>\n",
       "      <td>Shreds</td>\n",
       "      <td>shred</td>\n",
       "      <td>VERB</td>\n",
       "      <td>shred_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>10</td>\n",
       "      <td>NBC</td>\n",
       "      <td>NBC</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NBC_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>12</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Chuck_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>13</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Todd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Todd_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>14</td>\n",
       "      <td>For</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>for_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>15</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>16</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Deceptive_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>17</td>\n",
       "      <td>Editing</td>\n",
       "      <td>editing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>editing_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>18</td>\n",
       "      <td>‚Äô</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>19</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>20</td>\n",
       "      <td>Barr</td>\n",
       "      <td>Barr</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Barr_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>21</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>22</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>comment_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>23</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>\\n_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>24</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>25</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>26</td>\n",
       "      <td>Meet</td>\n",
       "      <td>Meet</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Meet_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>27</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>The_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>28</td>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Press_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>29</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>30</td>\n",
       "      <td>‚Äù</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>31</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>todd_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>32</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>1</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>3</td>\n",
       "      <td>@MagaGlam</td>\n",
       "      <td>@magaglam</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@magaglam_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>4</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>X</td>\n",
       "      <td>üá∫_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>5</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>üá∏_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>6</td>\n",
       "      <td>‚ô•</td>\n",
       "      <td>‚ô•</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>‚ô•_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>7</td>\n",
       "      <td>Ô∏è</td>\n",
       "      <td>Ô∏è</td>\n",
       "      <td>X</td>\n",
       "      <td>Ô∏è_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>8</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>9</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADP</td>\n",
       "      <td>back_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>11</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>13</td>\n",
       "      <td>üíô</td>\n",
       "      <td>üíô</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>üíô_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>14</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>üá∫_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date  token_id       word      lemma    pos  \\\n",
       "70         5  2020-05-11         7         ‚Äôs         ‚Äôs   PART   \n",
       "71         5  2020-05-11         8     Office     office   NOUN   \n",
       "72         5  2020-05-11         9     Shreds      shred   VERB   \n",
       "73         5  2020-05-11        10        NBC        NBC  PROPN   \n",
       "74         5  2020-05-11        11         ‚Äôs         ‚Äôs   PART   \n",
       "75         5  2020-05-11        12      Chuck      Chuck  PROPN   \n",
       "76         5  2020-05-11        13       Todd       Todd  PROPN   \n",
       "77         5  2020-05-11        14        For        for    ADP   \n",
       "78         5  2020-05-11        15          ‚Äò          '  PUNCT   \n",
       "79         5  2020-05-11        16  Deceptive  Deceptive  PROPN   \n",
       "80         5  2020-05-11        17    Editing    editing   NOUN   \n",
       "81         5  2020-05-11        18          ‚Äô          '  PUNCT   \n",
       "82         5  2020-05-11        19         Of         of    ADP   \n",
       "83         5  2020-05-11        20       Barr       Barr  PROPN   \n",
       "84         5  2020-05-11        21         ‚Äôs         ‚Äôs   PART   \n",
       "85         5  2020-05-11        22   Comments    comment   NOUN   \n",
       "86         5  2020-05-11        23         \\n         \\n  SPACE   \n",
       "87         5  2020-05-11        24         On         on    ADP   \n",
       "88         5  2020-05-11        25          ‚Äú          \"  PUNCT   \n",
       "89         5  2020-05-11        26       Meet       Meet  PROPN   \n",
       "90         5  2020-05-11        27        The        The  PROPN   \n",
       "91         5  2020-05-11        28      Press      Press  PROPN   \n",
       "92         5  2020-05-11        29          ,          ,  PUNCT   \n",
       "93         5  2020-05-11        30          ‚Äù          \"  PUNCT   \n",
       "94         5  2020-05-11        31       Todd       todd    ADJ   \n",
       "95         5  2020-05-11        32          ‚Ä¶          ‚Ä¶  PUNCT   \n",
       "96         6  2011-09-07         1         RT         RT  PROPN   \n",
       "97         6  2011-09-07         2                        SPACE   \n",
       "98         6  2011-09-07         3  @MagaGlam  @magaglam    SYM   \n",
       "99         6  2011-09-07         4          üá∫          üá∫      X   \n",
       "100        6  2011-09-07         5          üá∏          üá∏   NOUN   \n",
       "101        6  2011-09-07         6          ‚ô•          ‚ô•  PROPN   \n",
       "102        6  2011-09-07         7          Ô∏è          Ô∏è      X   \n",
       "103        6  2011-09-07         8      Bring      bring   VERB   \n",
       "104        6  2011-09-07         9       Back       back    ADP   \n",
       "105        6  2011-09-07        10                        SPACE   \n",
       "106        6  2011-09-07        11      Trump      Trump  PROPN   \n",
       "107        6  2011-09-07        12                        SPACE   \n",
       "108        6  2011-09-07        13          üíô          üíô  PROPN   \n",
       "109        6  2011-09-07        14          üá∫          üá∫   NOUN   \n",
       "\n",
       "             lemma_p  \n",
       "70           ‚Äôs_PART  \n",
       "71       office_NOUN  \n",
       "72        shred_VERB  \n",
       "73         NBC_PROPN  \n",
       "74           ‚Äôs_PART  \n",
       "75       Chuck_PROPN  \n",
       "76        Todd_PROPN  \n",
       "77           for_ADP  \n",
       "78           '_PUNCT  \n",
       "79   Deceptive_PROPN  \n",
       "80      editing_NOUN  \n",
       "81           '_PUNCT  \n",
       "82            of_ADP  \n",
       "83        Barr_PROPN  \n",
       "84           ‚Äôs_PART  \n",
       "85      comment_NOUN  \n",
       "86          \\n_SPACE  \n",
       "87            on_ADP  \n",
       "88           \"_PUNCT  \n",
       "89        Meet_PROPN  \n",
       "90         The_PROPN  \n",
       "91       Press_PROPN  \n",
       "92           ,_PUNCT  \n",
       "93           \"_PUNCT  \n",
       "94          todd_ADJ  \n",
       "95           ‚Ä¶_PUNCT  \n",
       "96          RT_PROPN  \n",
       "97            _SPACE  \n",
       "98     @magaglam_SYM  \n",
       "99               üá∫_X  \n",
       "100           üá∏_NOUN  \n",
       "101          ‚ô•_PROPN  \n",
       "102              Ô∏è_X  \n",
       "103       bring_VERB  \n",
       "104         back_ADP  \n",
       "105           _SPACE  \n",
       "106      Trump_PROPN  \n",
       "107           _SPACE  \n",
       "108          üíô_PROPN  \n",
       "109           üá∫_NOUN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sp2 = pd.read_csv(\"testkorpus_divers_50_spacy2.csv\")\n",
    "display(sp2[70:110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>21</td>\n",
       "      <td>https://t.co</td>\n",
       "      <td>https://t.co</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>https://t.co_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>21</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>/_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>21</td>\n",
       "      <td>v6z46rUDtg</td>\n",
       "      <td>v6z46rUDtg</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>v6z46rUDtg_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>22</td>\n",
       "      <td>Congress</td>\n",
       "      <td>Congress</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Congress_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>22</td>\n",
       "      <td>must</td>\n",
       "      <td>must</td>\n",
       "      <td>AUX</td>\n",
       "      <td>must_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>22</td>\n",
       "      <td>approve</td>\n",
       "      <td>approve</td>\n",
       "      <td>VERB</td>\n",
       "      <td>approve_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>22</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>22</td>\n",
       "      <td>deal,</td>\n",
       "      <td>deal,</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>deal,_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>22</td>\n",
       "      <td>without</td>\n",
       "      <td>without</td>\n",
       "      <td>ADP</td>\n",
       "      <td>without_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>22</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>PRON</td>\n",
       "      <td>all_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>22</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>22</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>22</td>\n",
       "      <td>nonsense,</td>\n",
       "      <td>nonsense,</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nonsense,_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>22</td>\n",
       "      <td>today.</td>\n",
       "      <td>today.</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>today._NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>22</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>PRON</td>\n",
       "      <td>the_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>22</td>\n",
       "      <td>longer</td>\n",
       "      <td>long</td>\n",
       "      <td>ADV</td>\n",
       "      <td>long_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>22</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>22</td>\n",
       "      <td>takes,</td>\n",
       "      <td>takes,</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>takes,_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>22</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>PRON</td>\n",
       "      <td>the_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>22</td>\n",
       "      <td>harder</td>\n",
       "      <td>hard</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>hard_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>22</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>22</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>22</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>22</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>22</td>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "      <td>VERB</td>\n",
       "      <td>start_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>22</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>ADP</td>\n",
       "      <td>up_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>22</td>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>our_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>22</td>\n",
       "      <td>economy.</td>\n",
       "      <td>economy.</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>economy._NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>22</td>\n",
       "      <td>Our</td>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>our_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>22</td>\n",
       "      <td>workers</td>\n",
       "      <td>worker</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>worker_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>22</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>22</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>22</td>\n",
       "      <td>hurt!</td>\n",
       "      <td>hurt!</td>\n",
       "      <td>VERB</td>\n",
       "      <td>hurt!_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>23</td>\n",
       "      <td>https://justthenews.com</td>\n",
       "      <td>https://justthenews.com</td>\n",
       "      <td>X</td>\n",
       "      <td>https://justthenews.com_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>23</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>/_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>23</td>\n",
       "      <td>politics</td>\n",
       "      <td>politic</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>politic_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>23</td>\n",
       "      <td>policy</td>\n",
       "      <td>policy</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>policy_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>23</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>/_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>23</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>PRON</td>\n",
       "      <td>all_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>23</td>\n",
       "      <td>things</td>\n",
       "      <td>thing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>thing_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>23</td>\n",
       "      <td>trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>trump_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>23</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>/_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>23</td>\n",
       "      <td>trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>trump_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>23</td>\n",
       "      <td>serves</td>\n",
       "      <td>serve</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>serve_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>23</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>23</td>\n",
       "      <td>meals</td>\n",
       "      <td>meal</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>meal_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                     word                    lemma    pos  \\\n",
       "450       21             https://t.co             https://t.co  PROPN   \n",
       "451       21                        /                        /    SYM   \n",
       "452       21               v6z46rUDtg               v6z46rUDtg  PROPN   \n",
       "453       22                 Congress                 Congress  PROPN   \n",
       "454       22                     must                     must    AUX   \n",
       "455       22                  approve                  approve   VERB   \n",
       "456       22                      the                      the    DET   \n",
       "457       22                    deal,                    deal,   NOUN   \n",
       "458       22                  without                  without    ADP   \n",
       "459       22                      all                      all   PRON   \n",
       "460       22                       of                       of    ADP   \n",
       "461       22                      the                      the    DET   \n",
       "462       22                nonsense,                nonsense,   NOUN   \n",
       "463       22                   today.                   today.   NOUN   \n",
       "464       22                      The                      the   PRON   \n",
       "465       22                   longer                     long    ADV   \n",
       "466       22                       it                       it   PRON   \n",
       "467       22                   takes,                   takes,   NOUN   \n",
       "468       22                      the                      the   PRON   \n",
       "469       22                   harder                     hard    ADJ   \n",
       "470       22                       it                       it   PRON   \n",
       "471       22                     will                     will    AUX   \n",
       "472       22                       be                       be    AUX   \n",
       "473       22                       to                       to   PART   \n",
       "474       22                    start                    start   VERB   \n",
       "475       22                       up                       up    ADP   \n",
       "476       22                      our                      our   PRON   \n",
       "477       22                 economy.                 economy.   NOUN   \n",
       "478       22                      Our                      our   PRON   \n",
       "479       22                  workers                   worker   NOUN   \n",
       "480       22                     will                     will    AUX   \n",
       "481       22                       be                       be    AUX   \n",
       "482       22                    hurt!                    hurt!   VERB   \n",
       "483       23  https://justthenews.com  https://justthenews.com      X   \n",
       "484       23                        /                        /    SYM   \n",
       "485       23                 politics                  politic   NOUN   \n",
       "486       23                        -                        -  PUNCT   \n",
       "487       23                   policy                   policy   NOUN   \n",
       "488       23                        /                        /    SYM   \n",
       "489       23                      all                      all   PRON   \n",
       "490       23                        -                        -  PUNCT   \n",
       "491       23                   things                    thing   NOUN   \n",
       "492       23                        -                        -  PUNCT   \n",
       "493       23                    trump                    trump   NOUN   \n",
       "494       23                        /                        /    SYM   \n",
       "495       23                    trump                    trump   NOUN   \n",
       "496       23                        -                        -  PUNCT   \n",
       "497       23                   serves                    serve   NOUN   \n",
       "498       23                        -                        -  PUNCT   \n",
       "499       23                    meals                     meal   NOUN   \n",
       "\n",
       "                       lemma_p  \n",
       "450         https://t.co_PROPN  \n",
       "451                      /_SYM  \n",
       "452           v6z46rUDtg_PROPN  \n",
       "453             Congress_PROPN  \n",
       "454                   must_AUX  \n",
       "455               approve_VERB  \n",
       "456                    the_DET  \n",
       "457                 deal,_NOUN  \n",
       "458                without_ADP  \n",
       "459                   all_PRON  \n",
       "460                     of_ADP  \n",
       "461                    the_DET  \n",
       "462             nonsense,_NOUN  \n",
       "463                today._NOUN  \n",
       "464                   the_PRON  \n",
       "465                   long_ADV  \n",
       "466                    it_PRON  \n",
       "467                takes,_NOUN  \n",
       "468                   the_PRON  \n",
       "469                   hard_ADJ  \n",
       "470                    it_PRON  \n",
       "471                   will_AUX  \n",
       "472                     be_AUX  \n",
       "473                    to_PART  \n",
       "474                 start_VERB  \n",
       "475                     up_ADP  \n",
       "476                   our_PRON  \n",
       "477              economy._NOUN  \n",
       "478                   our_PRON  \n",
       "479                worker_NOUN  \n",
       "480                   will_AUX  \n",
       "481                     be_AUX  \n",
       "482                 hurt!_VERB  \n",
       "483  https://justthenews.com_X  \n",
       "484                      /_SYM  \n",
       "485               politic_NOUN  \n",
       "486                    -_PUNCT  \n",
       "487                policy_NOUN  \n",
       "488                      /_SYM  \n",
       "489                   all_PRON  \n",
       "490                    -_PUNCT  \n",
       "491                 thing_NOUN  \n",
       "492                    -_PUNCT  \n",
       "493                 trump_NOUN  \n",
       "494                      /_SYM  \n",
       "495                 trump_NOUN  \n",
       "496                    -_PUNCT  \n",
       "497                 serve_NOUN  \n",
       "498                    -_PUNCT  \n",
       "499                  meal_NOUN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### SpaCy mit Twitter ####\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import re\n",
    "\n",
    "def create_twitter_tokenizer(nlp):\n",
    "    # Erweiterte Infix-Regel f√ºr Hashtags und Mentions (z.B. #NLP, @user)\n",
    "    infix_re = spacy.util.compile_infix_regex(\n",
    "        nlp.Defaults.infixes + [r'(?<=\\w)[#@](?=\\w)']\n",
    "    )\n",
    "    return Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.tokenizer = create_twitter_tokenizer(nlp)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, text in enumerate(df[\"text\"], start=1):\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    doc = nlp(str(text))\n",
    "    for token in doc:\n",
    "        all_results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"word\": token.text,\n",
    "            \"lemma\": token.lemma_,\n",
    "            \"pos\": token.pos_,\n",
    "            \"lemma_p\": f\"{token.lemma_}_{token.pos_}\"\n",
    "        })\n",
    "\n",
    "spt = pd.DataFrame(all_results)\n",
    "spt.to_csv(\"testkorpus_divers_50_spacy_twitter.csv\", index=False, encoding=\"utf-8\")\n",
    "display(spt[450:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>12</td>\n",
       "      <td>scored</td>\n",
       "      <td>score</td>\n",
       "      <td>VERB</td>\n",
       "      <td>score_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>12</td>\n",
       "      <td>big</td>\n",
       "      <td>big</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>big_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12</td>\n",
       "      <td>win</td>\n",
       "      <td>win</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>win_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>12</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td>with_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12</td>\n",
       "      <td>potentially</td>\n",
       "      <td>potentially</td>\n",
       "      <td>ADV</td>\n",
       "      <td>potentially_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>12</td>\n",
       "      <td>explosive</td>\n",
       "      <td>explosive</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>explosive_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>12</td>\n",
       "      <td>ruling</td>\n",
       "      <td>rule</td>\n",
       "      <td>VERB</td>\n",
       "      <td>rule_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id         word        lemma    pos          lemma_p\n",
       "200       12            -            -  PUNCT          -_PUNCT\n",
       "201       12       scored        score   VERB       score_VERB\n",
       "202       12            -            -  PUNCT          -_PUNCT\n",
       "203       12          big          big    ADJ          big_ADJ\n",
       "204       12            -            -  PUNCT          -_PUNCT\n",
       "205       12          win          win   NOUN         win_NOUN\n",
       "206       12            -            -  PUNCT          -_PUNCT\n",
       "207       12         with         with    ADP         with_ADP\n",
       "208       12            -            -  PUNCT          -_PUNCT\n",
       "209       12  potentially  potentially    ADV  potentially_ADV\n",
       "210       12            -            -  PUNCT          -_PUNCT\n",
       "211       12    explosive    explosive    ADJ    explosive_ADJ\n",
       "212       12            -            -  PUNCT          -_PUNCT\n",
       "213       12       ruling         rule   VERB        rule_VERB\n",
       "214       12            -            -  PUNCT          -_PUNCT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spt = pd.read_csv(\"testkorpus_divers_50_spacy_twitter.csv\")\n",
    "display(spt[200:215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1244, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>22</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>22</td>\n",
       "      <td>Our</td>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>our_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>22</td>\n",
       "      <td>workers</td>\n",
       "      <td>worker</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>worker_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>22</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>22</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>22</td>\n",
       "      <td>hurt</td>\n",
       "      <td>hurt</td>\n",
       "      <td>VERB</td>\n",
       "      <td>hurt_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>22</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>23</td>\n",
       "      <td>https://justthenews.com/politics-policy/all-th...</td>\n",
       "      <td>https://justthenews.com/politics-policy/all-th...</td>\n",
       "      <td>URL</td>\n",
       "      <td>https://justthenews.com/politics-policy/all-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>24</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>24</td>\n",
       "      <td>@FLOTUS</td>\n",
       "      <td>@FLOTUS</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@FLOTUS_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>24</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>24</td>\n",
       "      <td>Wishing</td>\n",
       "      <td>wish</td>\n",
       "      <td>VERB</td>\n",
       "      <td>wish_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>24</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>PRON</td>\n",
       "      <td>you_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>24</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>24</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>PRON</td>\n",
       "      <td>a_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>24</td>\n",
       "      <td>very</td>\n",
       "      <td>very</td>\n",
       "      <td>ADV</td>\n",
       "      <td>very_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>24</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>SYM</td>\n",
       "      <td>#_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>24</td>\n",
       "      <td>MerryChristmas</td>\n",
       "      <td>MerryChristmas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>MerryChristmas_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>24</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>24</td>\n",
       "      <td>May</td>\n",
       "      <td>may</td>\n",
       "      <td>AUX</td>\n",
       "      <td>may_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>24</td>\n",
       "      <td>your</td>\n",
       "      <td>your</td>\n",
       "      <td>PRON</td>\n",
       "      <td>your_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>24</td>\n",
       "      <td>day</td>\n",
       "      <td>day</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>day_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>24</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>24</td>\n",
       "      <td>filled</td>\n",
       "      <td>fill</td>\n",
       "      <td>VERB</td>\n",
       "      <td>fill_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>24</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "      <td>with_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>24</td>\n",
       "      <td>peace</td>\n",
       "      <td>peace</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>peace_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>24</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>24</td>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>love_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>24</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>24</td>\n",
       "      <td>happiness</td>\n",
       "      <td>happiness</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>happiness_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>24</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>24</td>\n",
       "      <td>https://t.co/yE6Vejihfo</td>\n",
       "      <td>https://t.co/yE6Vejihfo</td>\n",
       "      <td>URL</td>\n",
       "      <td>https://t.co/yE6Vejihfo_URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>25</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>25</td>\n",
       "      <td>United</td>\n",
       "      <td>United</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>United_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>25</td>\n",
       "      <td>States</td>\n",
       "      <td>States</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>States_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>25</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>25</td>\n",
       "      <td>America</td>\n",
       "      <td>America</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>America_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>25</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>25</td>\n",
       "      <td>going</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>go_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>25</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>25</td>\n",
       "      <td>take</td>\n",
       "      <td>take</td>\n",
       "      <td>VERB</td>\n",
       "      <td>take_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>25</td>\n",
       "      <td>back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>back_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>25</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>a_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>25</td>\n",
       "      <td>lot</td>\n",
       "      <td>lot</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>lot_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>25</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>25</td>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>what_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>25</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>25</td>\n",
       "      <td>stolen</td>\n",
       "      <td>steal</td>\n",
       "      <td>VERB</td>\n",
       "      <td>steal_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>25</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>from_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>25</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                               word  \\\n",
       "450       22                                                  .   \n",
       "451       22                                                Our   \n",
       "452       22                                            workers   \n",
       "453       22                                               will   \n",
       "454       22                                                 be   \n",
       "455       22                                               hurt   \n",
       "456       22                                                  !   \n",
       "457       23  https://justthenews.com/politics-policy/all-th...   \n",
       "458       24                                                 RT   \n",
       "459       24                                            @FLOTUS   \n",
       "460       24                                                  :   \n",
       "461       24                                            Wishing   \n",
       "462       24                                                you   \n",
       "463       24                                                all   \n",
       "464       24                                                  a   \n",
       "465       24                                               very   \n",
       "466       24                                                  #   \n",
       "467       24                                     MerryChristmas   \n",
       "468       24                                                  !   \n",
       "469       24                                                May   \n",
       "470       24                                               your   \n",
       "471       24                                                day   \n",
       "472       24                                                 be   \n",
       "473       24                                             filled   \n",
       "474       24                                               with   \n",
       "475       24                                              peace   \n",
       "476       24                                                  ,   \n",
       "477       24                                               love   \n",
       "478       24                                                and   \n",
       "479       24                                          happiness   \n",
       "480       24                                                  !   \n",
       "481       24                            https://t.co/yE6Vejihfo   \n",
       "482       25                                                The   \n",
       "483       25                                             United   \n",
       "484       25                                             States   \n",
       "485       25                                                 of   \n",
       "486       25                                            America   \n",
       "487       25                                                 is   \n",
       "488       25                                              going   \n",
       "489       25                                                 to   \n",
       "490       25                                               take   \n",
       "491       25                                               back   \n",
       "492       25                                                  a   \n",
       "493       25                                                lot   \n",
       "494       25                                                 of   \n",
       "495       25                                               what   \n",
       "496       25                                                was   \n",
       "497       25                                             stolen   \n",
       "498       25                                               from   \n",
       "499       25                                                 it   \n",
       "\n",
       "                                                 lemma    pos  \\\n",
       "450                                                  .  PUNCT   \n",
       "451                                                our   PRON   \n",
       "452                                             worker   NOUN   \n",
       "453                                               will    AUX   \n",
       "454                                                 be    AUX   \n",
       "455                                               hurt   VERB   \n",
       "456                                                  !  PUNCT   \n",
       "457  https://justthenews.com/politics-policy/all-th...    URL   \n",
       "458                                                 RT  PROPN   \n",
       "459                                            @FLOTUS  PROPN   \n",
       "460                                                  :  PUNCT   \n",
       "461                                               wish   VERB   \n",
       "462                                                you   PRON   \n",
       "463                                                all    DET   \n",
       "464                                                  a   PRON   \n",
       "465                                               very    ADV   \n",
       "466                                                  #    SYM   \n",
       "467                                     MerryChristmas  PROPN   \n",
       "468                                                  !  PUNCT   \n",
       "469                                                may    AUX   \n",
       "470                                               your   PRON   \n",
       "471                                                day   NOUN   \n",
       "472                                                 be    AUX   \n",
       "473                                               fill   VERB   \n",
       "474                                               with    ADP   \n",
       "475                                              peace   NOUN   \n",
       "476                                                  ,  PUNCT   \n",
       "477                                               love   NOUN   \n",
       "478                                                and  CCONJ   \n",
       "479                                          happiness   NOUN   \n",
       "480                                                  !  PUNCT   \n",
       "481                            https://t.co/yE6Vejihfo    URL   \n",
       "482                                                the    DET   \n",
       "483                                             United  PROPN   \n",
       "484                                             States  PROPN   \n",
       "485                                                 of    ADP   \n",
       "486                                            America  PROPN   \n",
       "487                                                 be    AUX   \n",
       "488                                                 go   VERB   \n",
       "489                                                 to   PART   \n",
       "490                                               take   VERB   \n",
       "491                                               back    ADV   \n",
       "492                                                  a    DET   \n",
       "493                                                lot   NOUN   \n",
       "494                                                 of    ADP   \n",
       "495                                               what   PRON   \n",
       "496                                                 be    AUX   \n",
       "497                                              steal   VERB   \n",
       "498                                               from    ADP   \n",
       "499                                                 it   PRON   \n",
       "\n",
       "                                               lemma_p  \n",
       "450                                            ._PUNCT  \n",
       "451                                           our_PRON  \n",
       "452                                        worker_NOUN  \n",
       "453                                           will_AUX  \n",
       "454                                             be_AUX  \n",
       "455                                          hurt_VERB  \n",
       "456                                            !_PUNCT  \n",
       "457  https://justthenews.com/politics-policy/all-th...  \n",
       "458                                           RT_PROPN  \n",
       "459                                      @FLOTUS_PROPN  \n",
       "460                                            :_PUNCT  \n",
       "461                                          wish_VERB  \n",
       "462                                           you_PRON  \n",
       "463                                            all_DET  \n",
       "464                                             a_PRON  \n",
       "465                                           very_ADV  \n",
       "466                                              #_SYM  \n",
       "467                               MerryChristmas_PROPN  \n",
       "468                                            !_PUNCT  \n",
       "469                                            may_AUX  \n",
       "470                                          your_PRON  \n",
       "471                                           day_NOUN  \n",
       "472                                             be_AUX  \n",
       "473                                          fill_VERB  \n",
       "474                                           with_ADP  \n",
       "475                                         peace_NOUN  \n",
       "476                                            ,_PUNCT  \n",
       "477                                          love_NOUN  \n",
       "478                                          and_CCONJ  \n",
       "479                                     happiness_NOUN  \n",
       "480                                            !_PUNCT  \n",
       "481                        https://t.co/yE6Vejihfo_URL  \n",
       "482                                            the_DET  \n",
       "483                                       United_PROPN  \n",
       "484                                       States_PROPN  \n",
       "485                                             of_ADP  \n",
       "486                                      America_PROPN  \n",
       "487                                             be_AUX  \n",
       "488                                            go_VERB  \n",
       "489                                            to_PART  \n",
       "490                                          take_VERB  \n",
       "491                                           back_ADV  \n",
       "492                                              a_DET  \n",
       "493                                           lot_NOUN  \n",
       "494                                             of_ADP  \n",
       "495                                          what_PRON  \n",
       "496                                             be_AUX  \n",
       "497                                         steal_VERB  \n",
       "498                                           from_ADP  \n",
       "499                                            it_PRON  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.symbols import ORTH\n",
    "import re\n",
    "\n",
    "# Regex-Regeln\n",
    "HASHTAG_RE = re.compile(r\"^#\\w+\")\n",
    "MENTION_RE = re.compile(r\"^@\\w+\")\n",
    "EMOJI_RE = re.compile(\n",
    "    r\"[\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    r\"\\U0001F300-\\U0001F5FF\"   # Symbole & Piktogramme\n",
    "    r\"\\U0001F680-\\U0001F6FF\"   # Transport & Karten\n",
    "    r\"\\U0001F1E0-\\U0001F1FF\"   # Flaggen\n",
    "    r\"]\", flags=re.UNICODE\n",
    ")\n",
    "URL_RE = re.compile(r\"^(https?://[^\\s]+|www\\.[^\\s]+|[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})(/[^\\s]*)?$\", flags=re.IGNORECASE)\n",
    "\n",
    "def custom_pos(token):\n",
    "    if HASHTAG_RE.match(token.text):\n",
    "        return \"ADD\"\n",
    "    elif MENTION_RE.match(token.text):\n",
    "        return \"PROPN\"\n",
    "    elif EMOJI_RE.match(token.text):\n",
    "        return \"NFP\"\n",
    "    elif URL_RE.match(token.text):\n",
    "        return \"URL\"\n",
    "    return token.pos_\n",
    "\n",
    "# Pipeline laden\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Spezialf√§lle dem Tokenizer hinzuf√ºgen, damit sie nicht zerschnitten werden\n",
    "def add_special_cases(nlp):\n",
    "    # Beispiel: Hashtags, Mentions, Emojis\n",
    "    for prefix in [\"#\", \"@\"]:\n",
    "        nlp.tokenizer.add_special_case(prefix, [{ORTH: prefix}])\n",
    "    # Optional: URLs & Emoji-Samples als spezielle Tokens\n",
    "    # F√ºr alle URLs oder Emojis in Texten kann man dynamisch vorab Tokens sammeln und hinzuf√ºgen\n",
    "\n",
    "add_special_cases(nlp)\n",
    "\n",
    "# Daten laden\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "all_results = []\n",
    "for idx, text in enumerate(df[\"text\"], start=1):\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    doc = nlp(str(text))\n",
    "    for token in doc:\n",
    "        pos_tag = custom_pos(token)\n",
    "        all_results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"word\": token.text,\n",
    "            \"lemma\": token.lemma_,\n",
    "            \"pos\": pos_tag,\n",
    "            \"lemma_p\": f\"{token.lemma_}_{pos_tag}\"\n",
    "        })\n",
    "\n",
    "spt2 = pd.DataFrame(all_results)\n",
    "spt2.to_csv(\"testkorpus_divers_50_spacy_tags.csv\", index=False, encoding=\"utf-8\")\n",
    "display(spt2[450:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>SYM</td>\n",
       "      <td>#_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>11</td>\n",
       "      <td>MadeInAmerica</td>\n",
       "      <td>MadeInAmerica</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>MadeInAmerica_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>event_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>ADV</td>\n",
       "      <td>right_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "      <td>ADV</td>\n",
       "      <td>here_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>at_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>11</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11</td>\n",
       "      <td>@WhiteHouse</td>\n",
       "      <td>@whitehouse</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@whitehouse_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>11</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>11</td>\n",
       "      <td>If</td>\n",
       "      <td>if</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>if_SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>11</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>11</td>\n",
       "      <td>MADE</td>\n",
       "      <td>make</td>\n",
       "      <td>VERB</td>\n",
       "      <td>make_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in_ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id           word          lemma    pos              lemma_p\n",
       "200       11              #              #    SYM                #_SYM\n",
       "201       11  MadeInAmerica  MadeInAmerica  PROPN  MadeInAmerica_PROPN\n",
       "202       11          event          event   NOUN           event_NOUN\n",
       "203       11              ,              ,  PUNCT              ,_PUNCT\n",
       "204       11          right          right    ADV            right_ADV\n",
       "205       11           here           here    ADV             here_ADV\n",
       "206       11             at             at    ADP               at_ADP\n",
       "207       11            the            the    DET              the_DET\n",
       "208       11    @WhiteHouse    @whitehouse  PROPN    @whitehouse_PROPN\n",
       "209       11              !              !  PUNCT              !_PUNCT\n",
       "210       11             If             if  SCONJ             if_SCONJ\n",
       "211       11             it             it   PRON              it_PRON\n",
       "212       11             is             be    AUX               be_AUX\n",
       "213       11           MADE           make   VERB            make_VERB\n",
       "214       11             IN             in    ADP               in_ADP"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spt2 = pd.read_csv(\"testkorpus_divers_50_spacy_tags.csv\")\n",
    "display(spt[200:215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spt2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit zu SpaCy:\n",
    "#### SpaCy:\n",
    "- LL.Bean richtig erkannt, @timc1021 ganz gelassen, als X\n",
    "- Thanks zu thank als NOUN, pm als NOUN, EST als PROPN\n",
    "- Url werden ganz gelassen, aber als PROPN, NOUN oder VERB\n",
    "- @ werden gelassen (@_KatherineWebb PROPN, @timc1021, @darhar981, @MagaGlam SYM, @FitnessGov NOUN, @WhiteHouse, @BreitbartNews)\n",
    "- Hashtags werden getrennt (# SYM MissUSA NOUN, # SYM AGENDA47 NOUN, # SYM EnterSandman PROPN, # KellyFile)\n",
    "- Rechtschreibfehler richtig getrennt (former ADJ . PUNCT Miss PROPN Alabama PROPN)\n",
    "- Addressing wird zu address lemmatisiert, VERB\n",
    "- Illnesses PROPN wird nur zu Illnesses lemmatisiert\n",
    "- Barr's wird zu Barr PROPN 's PART\n",
    "- Shreds wird zu shred als VERB\n",
    "- Meet PROPN The PROPN Press PROPN\n",
    "- Todd ADJ, RT PROPN\n",
    "- Emojis als X, NOUN, PROPN (aber richtig abgetrennt)\n",
    "- is wird zu be lemmatisiert, Stores zu store, elected zu elect, am zu be, MADE zu make\n",
    "- National PROPN Baseball PROPN\n",
    "- not PART only ADV a DET great ADJ player NOUN\n",
    "- @macys bleibt @macys\n",
    "- it PRON is AUX the DET BEST PROPN (eigentlich good)\n",
    "- L.L.Bean PROPN, ol' ADJ\n",
    "- violating VERB 1st PROPN Amendment PROPN\n",
    "- We PRON 're AUX going VERB to PART take VERB back ADV our PRON wealth NOUN\n",
    "- RT PROPN\n",
    "\n",
    "#### spacy2: \n",
    "\n",
    "- Shreds richtig als shred erkannt\n",
    "- will AUX be AUX LIVE VERB\n",
    "- pm als NOUN\n",
    "- besser lemmatisiert\n",
    "- Hash SYM MissUSA NOUN, Hash SYM AGENDA47 NOUN, Hash SYM MadeInAmerica PROPN event NOUN, Hash SYM MAGA PROPN, Hash SYM KellyFile PROPN\n",
    "- Url gut beibehalten, aber als PROPN, NOUN (bzw als Teil des Satzes analysiert)\n",
    "- @timc1021 X, @_KatherineWebb PROPN, @darhar981 PROPN, @WhiteHouse NOUN, @LBPerfectMaine ADJ, @Citizens_United wird zu @citizens_unite lemmatisiert und als VERB getaggt\n",
    "- Thanks zu thank lemmatisiert und als NOUN, Looking zu look lemmatisiert, Addressing zu address, being zu be, MADE zu make, BEST bleibt aber BEST, People bleibt people, her wird zu she\n",
    "- Barr's wird zu Barr PROPN 's PART\n",
    "- Not PART only ADV a DET great ADJ player NOUN\n",
    "- Emojis als Teil des Satzes analysiert: X, NOUN, PROPN\n",
    "- L.L.Bean als PROPN, its als PRON, ol' als ADJ (wird nicht zu old lemmatisiert)\n",
    "- doesn't wird zu do AUX und not PART\n",
    "- Via PROPN @BreitbartNews PROPN\n",
    "- violating VERB 1st PROPN Amendment PROPN\n",
    "- RT PROPN\n",
    "\n",
    "#### mit Twitterfunktion:\n",
    "\n",
    "- Satzzeichen werden nicht richtig getrennt (Vegas!\"\" PROPN, Thanks! INTJ, \n",
    "- schlechte Tokenisierung\n",
    "- @timc1021 als X, \"\"@_KatherineWebb: als PUNCT, @darhar981: PROPN, @FitnessGov. NOUN, @WhiteHouse! PROPN, \"\"@HarmonBrew: NOUN, @megynkelly ADV, \"\"@Citizens_United PUNCT\n",
    "- #AGENDA47 NOUN, #EnterSandman PROPN, #HOF2019 PROPN, #MadeInAmerica PROPN, #KellyFile NOUN, #MerryChristmas! NOUN\n",
    "- nicht alle Tags passen (z.B. Meet NOUN the DET press NOUN, USA als ADV)\n",
    "- Barr's bleibt Barr's PROPN\n",
    "- Emojis gut tokenisiert, aber Tags: X, NOUN, PROPN\n",
    "- manche Url werden zerh√§kselt, manche nicht (und als PROPN, SYM PROPN oder NOUN getaggt)\n",
    "- Lemmatisierung gut (Looking wird zu look, Shreds zu shred VERB, NBC's bleibt so als PRON, MADE zu make, BEST! aber best!, her, bleibt her, getting zu get)\n",
    "- Lemmatisierung dann gut, wenn Satzzeichen vorher abgetrennt wurden\n",
    "- Thank VERB you PRON .. support NOUN and CCONJ courage. VERB\n",
    "- L.L.Bean. PROPN\n",
    "- 1st PROPN Amendment PROPN\n",
    "- RT PROPN\n",
    "\n",
    "#### Erg√§nzung durch vier Funktionen:\n",
    "- Hashtags werden dann nicht als solche erkannt, wenn sie in den Satz als Objekt eingebettet sind: dann wird SYM NOUN/PROPN daraus\n",
    "- @ sind alle einwandfrei als PROPN und in einem St√ºck\n",
    "- Tokenisierung gut (Worte und Satzzeichen gut getrennt)\n",
    "- Illnesses nur zu Illnesses lemmatisiert?, Shreds zu shred, Stores zu store, elected zu elect, MADE zu make, stolen zu steal, 're zu be\n",
    "- RT als PROPN, Todd ADJ\n",
    "- Barr's wird zu PROPN PART\n",
    "- Meet PROPN The PROPN Press PROPN\n",
    "- Emojis meist als NFP, aber auch als PROPN\n",
    "- Thank VERB you PRON\n",
    "- @macys bleibt @macys PROPN, her bleibt her PRON\n",
    "- even ADV more ADV (bleibt als Lemma more) now ADV\n",
    "- DonaldTrump PROPN, Via PROPN, 1st Amendment PROPN PROPN\n",
    "- its PRON (statt it's), ol' bleibt ol' ADJ\n",
    "- doesn't wird zu do AUX not PART\n",
    "- 1887.Twisting wird zu 1887.twiste und als URL getaggt, arms?Allowed wird zu arms?allowe VERB\n",
    "- JOBS als PROPN\n",
    "- anti-Trump wird zu anti ADJ - ADJ trump ADJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Flair\n",
    "- https://huggingface.co/flair/pos-english: F1 Score: 98,18\n",
    "- https://huggingface.co/flair/pos-english-fast: 98,10\n",
    "- https://huggingface.co/flair/upos-english: 98,6\n",
    "- https://huggingface.co/flair/upos-english-fast: 98,47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flair # bei Modell pos oder upos w√§hlbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>reminder_INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>the_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>miss</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>miss_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>competition_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>be_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>VERB</td>\n",
       "      <td>live_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>from_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>SYM</td>\n",
       "      <td>the_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>bahamas</td>\n",
       "      <td>NUM</td>\n",
       "      <td>bahamas_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>VERB</td>\n",
       "      <td>tonight_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9pm</td>\n",
       "      <td>9pm</td>\n",
       "      <td>NUM</td>\n",
       "      <td>9pm_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>SYM</td>\n",
       "      <td>(_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>est</td>\n",
       "      <td>NUM</td>\n",
       "      <td>est_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>X</td>\n",
       "      <td>)_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>SYM</td>\n",
       "      <td>on_SYM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word        lemma    pos            lemma_p\n",
       "0         0  2010-11-04     Reminder     reminder   INTJ      reminder_INTJ\n",
       "1         0  2010-11-04            :            :  PUNCT            :_PUNCT\n",
       "2         0  2010-11-04          The          the  PROPN          the_PROPN\n",
       "3         0  2010-11-04         Miss         miss  PROPN         miss_PROPN\n",
       "4         0  2010-11-04     Universe     universe  PROPN     universe_PROPN\n",
       "5         0  2010-11-04  competition  competition  PROPN  competition_PROPN\n",
       "6         0  2010-11-04         will         will    AUX           will_AUX\n",
       "7         0  2010-11-04           be           be   VERB            be_VERB\n",
       "8         0  2010-11-04         LIVE         live   VERB          live_VERB\n",
       "9         0  2010-11-04         from         from    ADP           from_ADP\n",
       "10        0  2010-11-04          the          the    SYM            the_SYM\n",
       "11        0  2010-11-04      Bahamas      bahamas    NUM        bahamas_NUM\n",
       "12        0  2010-11-04            -            -  PUNCT            -_PUNCT\n",
       "13        0  2010-11-04      Tonight      tonight   VERB       tonight_VERB\n",
       "14        0  2010-11-04            @            @    SYM              @_SYM\n",
       "15        0  2010-11-04          9pm          9pm    NUM            9pm_NUM\n",
       "16        0  2010-11-04            (            (    SYM              (_SYM\n",
       "17        0  2010-11-04          EST          est    NUM            est_NUM\n",
       "18        0  2010-11-04            )            )      X                )_X\n",
       "19        0  2010-11-04           on           on    SYM             on_SYM"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Flair mit UPOS ####\n",
    "import logging\n",
    "import pandas as pd\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "logging.getLogger(\"flair\").setLevel(logging.ERROR)\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "df_nonempty = df[df[\"text\"].notna()].copy()\n",
    "tagger = SequenceTagger.load(\"flair/upos-english\")\n",
    "label_type = tagger.label_type\n",
    "\n",
    "sentences = [Sentence(str(t)) for t in df_nonempty[\"text\"]]\n",
    "tagger.predict(sentences, mini_batch_size=32)\n",
    "\n",
    "all_results = []\n",
    "for row, sentence in zip(df_nonempty.itertuples(index=True), sentences):\n",
    "    for token in sentence:\n",
    "        # POS-Label \n",
    "        pos_label = token.get_label(label_type).value if token.has_label(label_type) else None\n",
    "\n",
    "        all_results.append({\n",
    "            \"post_id\": row.Index,\n",
    "            \"date\": getattr(row, \"date\", None),\n",
    "            \"word\": token.text,\n",
    "            \"lemma\": token.text.lower(),           # Flair liefert kein Lemma\n",
    "            \"pos\": pos_label,\n",
    "            \"lemma_p\": f\"{token.text.lower()}_{pos_label}\" if pos_label else token.text.lower()\n",
    "        })\n",
    "        \n",
    "fl = pd.DataFrame(all_results)\n",
    "fl.to_csv(\"testkorpus_divers_50_flair_upos.csv\", index=False)\n",
    "display(fl.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Shreds</td>\n",
       "      <td>shreds</td>\n",
       "      <td>NUM</td>\n",
       "      <td>shreds_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>NBC</td>\n",
       "      <td>nbc</td>\n",
       "      <td>SYM</td>\n",
       "      <td>nbc_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>NUM</td>\n",
       "      <td>‚Äôs_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>chuck</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>chuck_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>SYM</td>\n",
       "      <td>todd_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>For</td>\n",
       "      <td>for</td>\n",
       "      <td>NUM</td>\n",
       "      <td>for_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>SYM</td>\n",
       "      <td>‚Äò_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>NUM</td>\n",
       "      <td>deceptive_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Editing‚Äô</td>\n",
       "      <td>editing‚Äô</td>\n",
       "      <td>SYM</td>\n",
       "      <td>editing‚Äô_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>NUM</td>\n",
       "      <td>of_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Barr</td>\n",
       "      <td>barr</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>barr_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>SYM</td>\n",
       "      <td>‚Äôs_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comments</td>\n",
       "      <td>NUM</td>\n",
       "      <td>comments_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>SYM</td>\n",
       "      <td>on_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>NUM</td>\n",
       "      <td>‚Äú_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>SYM</td>\n",
       "      <td>meet_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>NUM</td>\n",
       "      <td>the_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press</td>\n",
       "      <td>press</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>press_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>SYM</td>\n",
       "      <td>,‚Äù_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>NUM</td>\n",
       "      <td>todd_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT</td>\n",
       "      <td>rt</td>\n",
       "      <td>X</td>\n",
       "      <td>rt_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>X</td>\n",
       "      <td>@_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>MagaGlam</td>\n",
       "      <td>magaglam</td>\n",
       "      <td>X</td>\n",
       "      <td>magaglam_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üá∫üá∏‚ô•</td>\n",
       "      <td>üá∫üá∏‚ô•</td>\n",
       "      <td>SYM</td>\n",
       "      <td>üá∫üá∏‚ô•_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>SYM</td>\n",
       "      <td>back_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>NUM</td>\n",
       "      <td>trump_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>SYM</td>\n",
       "      <td>üíôüá∫üá∏_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CBP</td>\n",
       "      <td>cbp</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>cbp_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Home</td>\n",
       "      <td>home</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>home_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>app</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>app_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "      <td>is_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>now_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>VERB</td>\n",
       "      <td>available_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>ADP</td>\n",
       "      <td>across_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>NUM</td>\n",
       "      <td>all_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>mobile_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>app</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>app_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Stores</td>\n",
       "      <td>stores</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>stores_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>VERB</td>\n",
       "      <td>congratulations_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>to_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>mariano</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>mariano_PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date             word            lemma    pos  \\\n",
       "70         4  2020-05-11           Shreds           shreds    NUM   \n",
       "71         4  2020-05-11              NBC              nbc    SYM   \n",
       "72         4  2020-05-11               ‚Äôs               ‚Äôs    NUM   \n",
       "73         4  2020-05-11            Chuck            chuck   NOUN   \n",
       "74         4  2020-05-11             Todd             todd    SYM   \n",
       "75         4  2020-05-11              For              for    NUM   \n",
       "76         4  2020-05-11                ‚Äò                ‚Äò    SYM   \n",
       "77         4  2020-05-11        Deceptive        deceptive    NUM   \n",
       "78         4  2020-05-11         Editing‚Äô         editing‚Äô    SYM   \n",
       "79         4  2020-05-11               Of               of    NUM   \n",
       "80         4  2020-05-11             Barr             barr  PUNCT   \n",
       "81         4  2020-05-11               ‚Äôs               ‚Äôs    SYM   \n",
       "82         4  2020-05-11         Comments         comments    NUM   \n",
       "83         4  2020-05-11               On               on    SYM   \n",
       "84         4  2020-05-11                ‚Äú                ‚Äú    NUM   \n",
       "85         4  2020-05-11             Meet             meet    SYM   \n",
       "86         4  2020-05-11              The              the    NUM   \n",
       "87         4  2020-05-11            Press            press   NOUN   \n",
       "88         4  2020-05-11               ,‚Äù               ,‚Äù    SYM   \n",
       "89         4  2020-05-11             Todd             todd    NUM   \n",
       "90         4  2020-05-11                ‚Ä¶                ‚Ä¶  PUNCT   \n",
       "91         5  2011-09-07               RT               rt      X   \n",
       "92         5  2011-09-07                @                @      X   \n",
       "93         5  2011-09-07         MagaGlam         magaglam      X   \n",
       "94         5  2011-09-07              üá∫üá∏‚ô•              üá∫üá∏‚ô•    SYM   \n",
       "95         5  2011-09-07            Bring            bring   VERB   \n",
       "96         5  2011-09-07             Back             back    SYM   \n",
       "97         5  2011-09-07            Trump            trump    NUM   \n",
       "98         5  2011-09-07              üíôüá∫üá∏              üíôüá∫üá∏    SYM   \n",
       "99         7  2025-03-19              The              the    DET   \n",
       "100        7  2025-03-19              CBP              cbp  PROPN   \n",
       "101        7  2025-03-19             Home             home  PROPN   \n",
       "102        7  2025-03-19              App              app  PROPN   \n",
       "103        7  2025-03-19               is               is   VERB   \n",
       "104        7  2025-03-19              now              now    ADV   \n",
       "105        7  2025-03-19        available        available   VERB   \n",
       "106        7  2025-03-19           across           across    ADP   \n",
       "107        7  2025-03-19              all              all    NUM   \n",
       "108        7  2025-03-19           mobile           mobile  PROPN   \n",
       "109        7  2025-03-19              App              app  PROPN   \n",
       "110        7  2025-03-19           Stores           stores  PROPN   \n",
       "111        7  2025-03-19                !                !  PUNCT   \n",
       "112        8  2019-01-23  Congratulations  congratulations   VERB   \n",
       "113        8  2019-01-23               to               to  PROPN   \n",
       "114        8  2019-01-23          Mariano          mariano  PROPN   \n",
       "\n",
       "                  lemma_p  \n",
       "70             shreds_NUM  \n",
       "71                nbc_SYM  \n",
       "72                 ‚Äôs_NUM  \n",
       "73             chuck_NOUN  \n",
       "74               todd_SYM  \n",
       "75                for_NUM  \n",
       "76                  ‚Äò_SYM  \n",
       "77          deceptive_NUM  \n",
       "78           editing‚Äô_SYM  \n",
       "79                 of_NUM  \n",
       "80             barr_PUNCT  \n",
       "81                 ‚Äôs_SYM  \n",
       "82           comments_NUM  \n",
       "83                 on_SYM  \n",
       "84                  ‚Äú_NUM  \n",
       "85               meet_SYM  \n",
       "86                the_NUM  \n",
       "87             press_NOUN  \n",
       "88                 ,‚Äù_SYM  \n",
       "89               todd_NUM  \n",
       "90                ‚Ä¶_PUNCT  \n",
       "91                   rt_X  \n",
       "92                    @_X  \n",
       "93             magaglam_X  \n",
       "94                üá∫üá∏‚ô•_SYM  \n",
       "95             bring_VERB  \n",
       "96               back_SYM  \n",
       "97              trump_NUM  \n",
       "98                üíôüá∫üá∏_SYM  \n",
       "99                the_DET  \n",
       "100             cbp_PROPN  \n",
       "101            home_PROPN  \n",
       "102             app_PROPN  \n",
       "103               is_VERB  \n",
       "104               now_ADV  \n",
       "105        available_VERB  \n",
       "106            across_ADP  \n",
       "107               all_NUM  \n",
       "108          mobile_PROPN  \n",
       "109             app_PROPN  \n",
       "110          stores_PROPN  \n",
       "111               !_PUNCT  \n",
       "112  congratulations_VERB  \n",
       "113              to_PROPN  \n",
       "114         mariano_PROPN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fl = pd.read_csv(\"testkorpus_divers_50_flair_upos.csv\")\n",
    "display(fl[70:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NN</td>\n",
       "      <td>reminder_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>:_:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>miss</td>\n",
       "      <td>NNP</td>\n",
       "      <td>miss_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>universe</td>\n",
       "      <td>NNP</td>\n",
       "      <td>universe_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NN</td>\n",
       "      <td>competition_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>will_MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>VB</td>\n",
       "      <td>be_VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>RB</td>\n",
       "      <td>live_RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>from_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>bahamas</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>bahamas_NNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>:</td>\n",
       "      <td>-_:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>NNP</td>\n",
       "      <td>tonight_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>IN</td>\n",
       "      <td>@_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9pm</td>\n",
       "      <td>9pm</td>\n",
       "      <td>NN</td>\n",
       "      <td>9pm_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>:</td>\n",
       "      <td>(_:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>est</td>\n",
       "      <td>NNP</td>\n",
       "      <td>est_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>)_-RRB-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>on_IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word        lemma    pos         lemma_p\n",
       "0         0  2010-11-04     Reminder     reminder     NN     reminder_NN\n",
       "1         0  2010-11-04            :            :      :             :_:\n",
       "2         0  2010-11-04          The          the     DT          the_DT\n",
       "3         0  2010-11-04         Miss         miss    NNP        miss_NNP\n",
       "4         0  2010-11-04     Universe     universe    NNP    universe_NNP\n",
       "5         0  2010-11-04  competition  competition     NN  competition_NN\n",
       "6         0  2010-11-04         will         will     MD         will_MD\n",
       "7         0  2010-11-04           be           be     VB           be_VB\n",
       "8         0  2010-11-04         LIVE         live     RB         live_RB\n",
       "9         0  2010-11-04         from         from     IN         from_IN\n",
       "10        0  2010-11-04          the          the     DT          the_DT\n",
       "11        0  2010-11-04      Bahamas      bahamas   NNPS    bahamas_NNPS\n",
       "12        0  2010-11-04            -            -      :             -_:\n",
       "13        0  2010-11-04      Tonight      tonight    NNP     tonight_NNP\n",
       "14        0  2010-11-04            @            @     IN            @_IN\n",
       "15        0  2010-11-04          9pm          9pm     NN          9pm_NN\n",
       "16        0  2010-11-04            (            (      :             (_:\n",
       "17        0  2010-11-04          EST          est    NNP         est_NNP\n",
       "18        0  2010-11-04            )            )  -RRB-         )_-RRB-\n",
       "19        0  2010-11-04           on           on     IN           on_IN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Flair mit POS ####\n",
    "import logging\n",
    "import pandas as pd\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "logging.getLogger(\"flair\").setLevel(logging.ERROR)\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "df_nonempty = df[df[\"text\"].notna()].copy()\n",
    "tagger = SequenceTagger.load(\"flair/pos-english\")\n",
    "label_type = tagger.label_type\n",
    "\n",
    "sentences = [Sentence(str(t)) for t in df_nonempty[\"text\"]]\n",
    "tagger.predict(sentences, mini_batch_size=32)\n",
    "\n",
    "all_results = []\n",
    "for row, sentence in zip(df_nonempty.itertuples(index=True), sentences):\n",
    "    for token in sentence:\n",
    "        # POS-Label \n",
    "        pos_label = token.get_label(label_type).value if token.has_label(label_type) else None\n",
    "\n",
    "        all_results.append({\n",
    "            \"post_id\": row.Index,\n",
    "            \"date\": getattr(row, \"date\", None),\n",
    "            \"word\": token.text,\n",
    "            \"lemma\": token.text.lower(),           # Flair liefert kein Lemma\n",
    "            \"pos\": pos_label,\n",
    "            \"lemma_p\": f\"{token.text.lower()}_{pos_label}\" if pos_label else token.text.lower()\n",
    "        })\n",
    "        \n",
    "fl2 = pd.DataFrame(all_results)\n",
    "fl2.to_csv(\"testkorpus_divers_50_flair_pos.csv\", index=False)\n",
    "display(fl2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Shreds</td>\n",
       "      <td>shreds</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>shreds_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>NBC</td>\n",
       "      <td>nbc</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nbc_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>‚Äôs_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>chuck</td>\n",
       "      <td>NNP</td>\n",
       "      <td>chuck_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>NNP</td>\n",
       "      <td>todd_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>For</td>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "      <td>for_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>``</td>\n",
       "      <td>‚Äò_``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>JJ</td>\n",
       "      <td>deceptive_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Editing‚Äô</td>\n",
       "      <td>editing‚Äô</td>\n",
       "      <td>NN</td>\n",
       "      <td>editing‚Äô_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Barr</td>\n",
       "      <td>barr</td>\n",
       "      <td>NNP</td>\n",
       "      <td>barr_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>‚Äôs_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comments</td>\n",
       "      <td>NNS</td>\n",
       "      <td>comments_NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>on_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>``</td>\n",
       "      <td>‚Äú_``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>VB</td>\n",
       "      <td>meet_VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press</td>\n",
       "      <td>press</td>\n",
       "      <td>NN</td>\n",
       "      <td>press_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>,</td>\n",
       "      <td>,‚Äù_,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>NNP</td>\n",
       "      <td>todd_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>.</td>\n",
       "      <td>‚Ä¶_.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT</td>\n",
       "      <td>rt</td>\n",
       "      <td>NN</td>\n",
       "      <td>rt_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>MagaGlam</td>\n",
       "      <td>magaglam</td>\n",
       "      <td>NNP</td>\n",
       "      <td>magaglam_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üá∫üá∏‚ô•</td>\n",
       "      <td>üá∫üá∏‚ô•</td>\n",
       "      <td>NFP</td>\n",
       "      <td>üá∫üá∏‚ô•_NFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VB</td>\n",
       "      <td>bring_VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>RB</td>\n",
       "      <td>back_RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>NN</td>\n",
       "      <td>trump_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>NFP</td>\n",
       "      <td>üíôüá∫üá∏_NFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CBP</td>\n",
       "      <td>cbp</td>\n",
       "      <td>NNP</td>\n",
       "      <td>cbp_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Home</td>\n",
       "      <td>home</td>\n",
       "      <td>NNP</td>\n",
       "      <td>home_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>app</td>\n",
       "      <td>NNP</td>\n",
       "      <td>app_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>is_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>RB</td>\n",
       "      <td>now_RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>JJ</td>\n",
       "      <td>available_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>IN</td>\n",
       "      <td>across_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DT</td>\n",
       "      <td>all_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>JJ</td>\n",
       "      <td>mobile_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>app</td>\n",
       "      <td>NNP</td>\n",
       "      <td>app_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Stores</td>\n",
       "      <td>stores</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>stores_NNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>.</td>\n",
       "      <td>!_.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>NNS</td>\n",
       "      <td>congratulations_NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>IN</td>\n",
       "      <td>to_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>mariano</td>\n",
       "      <td>NNP</td>\n",
       "      <td>mariano_NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date             word            lemma   pos  \\\n",
       "70         4  2020-05-11           Shreds           shreds   VBZ   \n",
       "71         4  2020-05-11              NBC              nbc   NNP   \n",
       "72         4  2020-05-11               ‚Äôs               ‚Äôs   VBZ   \n",
       "73         4  2020-05-11            Chuck            chuck   NNP   \n",
       "74         4  2020-05-11             Todd             todd   NNP   \n",
       "75         4  2020-05-11              For              for    IN   \n",
       "76         4  2020-05-11                ‚Äò                ‚Äò    ``   \n",
       "77         4  2020-05-11        Deceptive        deceptive    JJ   \n",
       "78         4  2020-05-11         Editing‚Äô         editing‚Äô    NN   \n",
       "79         4  2020-05-11               Of               of    IN   \n",
       "80         4  2020-05-11             Barr             barr   NNP   \n",
       "81         4  2020-05-11               ‚Äôs               ‚Äôs   VBZ   \n",
       "82         4  2020-05-11         Comments         comments   NNS   \n",
       "83         4  2020-05-11               On               on    IN   \n",
       "84         4  2020-05-11                ‚Äú                ‚Äú    ``   \n",
       "85         4  2020-05-11             Meet             meet    VB   \n",
       "86         4  2020-05-11              The              the    DT   \n",
       "87         4  2020-05-11            Press            press    NN   \n",
       "88         4  2020-05-11               ,‚Äù               ,‚Äù     ,   \n",
       "89         4  2020-05-11             Todd             todd   NNP   \n",
       "90         4  2020-05-11                ‚Ä¶                ‚Ä¶     .   \n",
       "91         5  2011-09-07               RT               rt    NN   \n",
       "92         5  2011-09-07                @                @   SYM   \n",
       "93         5  2011-09-07         MagaGlam         magaglam   NNP   \n",
       "94         5  2011-09-07              üá∫üá∏‚ô•              üá∫üá∏‚ô•   NFP   \n",
       "95         5  2011-09-07            Bring            bring    VB   \n",
       "96         5  2011-09-07             Back             back    RB   \n",
       "97         5  2011-09-07            Trump            trump    NN   \n",
       "98         5  2011-09-07              üíôüá∫üá∏              üíôüá∫üá∏   NFP   \n",
       "99         7  2025-03-19              The              the    DT   \n",
       "100        7  2025-03-19              CBP              cbp   NNP   \n",
       "101        7  2025-03-19             Home             home   NNP   \n",
       "102        7  2025-03-19              App              app   NNP   \n",
       "103        7  2025-03-19               is               is   VBZ   \n",
       "104        7  2025-03-19              now              now    RB   \n",
       "105        7  2025-03-19        available        available    JJ   \n",
       "106        7  2025-03-19           across           across    IN   \n",
       "107        7  2025-03-19              all              all    DT   \n",
       "108        7  2025-03-19           mobile           mobile    JJ   \n",
       "109        7  2025-03-19              App              app   NNP   \n",
       "110        7  2025-03-19           Stores           stores  NNPS   \n",
       "111        7  2025-03-19                !                !     .   \n",
       "112        8  2019-01-23  Congratulations  congratulations   NNS   \n",
       "113        8  2019-01-23               to               to    IN   \n",
       "114        8  2019-01-23          Mariano          mariano   NNP   \n",
       "\n",
       "                 lemma_p  \n",
       "70            shreds_VBZ  \n",
       "71               nbc_NNP  \n",
       "72                ‚Äôs_VBZ  \n",
       "73             chuck_NNP  \n",
       "74              todd_NNP  \n",
       "75                for_IN  \n",
       "76                  ‚Äò_``  \n",
       "77          deceptive_JJ  \n",
       "78           editing‚Äô_NN  \n",
       "79                 of_IN  \n",
       "80              barr_NNP  \n",
       "81                ‚Äôs_VBZ  \n",
       "82          comments_NNS  \n",
       "83                 on_IN  \n",
       "84                  ‚Äú_``  \n",
       "85               meet_VB  \n",
       "86                the_DT  \n",
       "87              press_NN  \n",
       "88                  ,‚Äù_,  \n",
       "89              todd_NNP  \n",
       "90                   ‚Ä¶_.  \n",
       "91                 rt_NN  \n",
       "92                 @_SYM  \n",
       "93          magaglam_NNP  \n",
       "94               üá∫üá∏‚ô•_NFP  \n",
       "95              bring_VB  \n",
       "96               back_RB  \n",
       "97              trump_NN  \n",
       "98               üíôüá∫üá∏_NFP  \n",
       "99                the_DT  \n",
       "100              cbp_NNP  \n",
       "101             home_NNP  \n",
       "102              app_NNP  \n",
       "103               is_VBZ  \n",
       "104               now_RB  \n",
       "105         available_JJ  \n",
       "106            across_IN  \n",
       "107               all_DT  \n",
       "108            mobile_JJ  \n",
       "109              app_NNP  \n",
       "110          stores_NNPS  \n",
       "111                  !_.  \n",
       "112  congratulations_NNS  \n",
       "113                to_IN  \n",
       "114          mariano_NNP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fl2 = pd.read_csv(\"testkorpus_divers_50_flair_pos.csv\")\n",
    "display(fl2[70:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NN</td>\n",
       "      <td>reminder_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>:_:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>miss</td>\n",
       "      <td>NNP</td>\n",
       "      <td>miss_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>universe</td>\n",
       "      <td>NNP</td>\n",
       "      <td>universe_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NN</td>\n",
       "      <td>competition_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>will_MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>VB</td>\n",
       "      <td>be_VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>JJ</td>\n",
       "      <td>live_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>from_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>bahamas</td>\n",
       "      <td>NNP</td>\n",
       "      <td>bahamas_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>HYPH</td>\n",
       "      <td>-_HYPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>NNP</td>\n",
       "      <td>tonight_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>CC</td>\n",
       "      <td>@_CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9pm</td>\n",
       "      <td>9pm</td>\n",
       "      <td>NN</td>\n",
       "      <td>9pm_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>:</td>\n",
       "      <td>(_:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>est</td>\n",
       "      <td>NNP</td>\n",
       "      <td>est_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>)_-RRB-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>on_IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word        lemma    pos         lemma_p\n",
       "0         0  2010-11-04     Reminder     reminder     NN     reminder_NN\n",
       "1         0  2010-11-04            :            :      :             :_:\n",
       "2         0  2010-11-04          The          the     DT          the_DT\n",
       "3         0  2010-11-04         Miss         miss    NNP        miss_NNP\n",
       "4         0  2010-11-04     Universe     universe    NNP    universe_NNP\n",
       "5         0  2010-11-04  competition  competition     NN  competition_NN\n",
       "6         0  2010-11-04         will         will     MD         will_MD\n",
       "7         0  2010-11-04           be           be     VB           be_VB\n",
       "8         0  2010-11-04         LIVE         live     JJ         live_JJ\n",
       "9         0  2010-11-04         from         from     IN         from_IN\n",
       "10        0  2010-11-04          the          the     DT          the_DT\n",
       "11        0  2010-11-04      Bahamas      bahamas    NNP     bahamas_NNP\n",
       "12        0  2010-11-04            -            -   HYPH          -_HYPH\n",
       "13        0  2010-11-04      Tonight      tonight    NNP     tonight_NNP\n",
       "14        0  2010-11-04            @            @     CC            @_CC\n",
       "15        0  2010-11-04          9pm          9pm     NN          9pm_NN\n",
       "16        0  2010-11-04            (            (      :             (_:\n",
       "17        0  2010-11-04          EST          est    NNP         est_NNP\n",
       "18        0  2010-11-04            )            )  -RRB-         )_-RRB-\n",
       "19        0  2010-11-04           on           on     IN           on_IN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Flair und SpaCy ####\n",
    "import pandas as pd\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "tagger = SequenceTagger.load(\"pos-fast\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "\n",
    "    spacy_doc = nlp(str(text))\n",
    "\n",
    "    flair_sentence = Sentence(str(text))\n",
    "    tagger.predict(flair_sentence)\n",
    "\n",
    "    # Achtung: Flair und SpaCy tokenisieren unterschiedlich!\n",
    "    if len(flair_sentence) == len(spacy_doc):\n",
    "        for flair_token, spacy_token in zip(flair_sentence, spacy_doc):\n",
    "            all_results.append({\n",
    "                \"post_id\": idx,\n",
    "                \"date\": row.get(\"date\"),\n",
    "                \"word\": flair_token.text,\n",
    "                \"lemma\": spacy_token.lemma_, #f√ºr Lemma Spacy verwenden\n",
    "                \"pos\": flair_token.get_label('pos').value,\n",
    "                \"lemma_p\": f\"{spacy_token.lemma_}_{flair_token.get_label('pos').value}\"\n",
    "            })\n",
    "    else:\n",
    "        # Falls Tokenanzahl nicht √ºbereinstimmt\n",
    "        for flair_token in flair_sentence:\n",
    "            all_results.append({\n",
    "                \"post_id\": idx,\n",
    "                \"date\": row.get(\"date\"),\n",
    "                \"word\": flair_token.text,\n",
    "                \"lemma\": flair_token.text.lower(),\n",
    "                \"pos\": flair_token.get_label('pos').value,\n",
    "                \"lemma_p\": f\"{flair_token.text.lower()}_{flair_token.get_label('pos').value}\"\n",
    "            })\n",
    "\n",
    "flsp = pd.DataFrame(all_results)\n",
    "flsp.to_csv(\"testkorpus_divers_50_flair_spacy.csv\", index=False)\n",
    "display(flsp.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Shreds</td>\n",
       "      <td>shreds</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>shreds_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>NBC</td>\n",
       "      <td>nbc</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nbc_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>‚Äôs_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>chuck</td>\n",
       "      <td>NNP</td>\n",
       "      <td>chuck_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>NNP</td>\n",
       "      <td>todd_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>For</td>\n",
       "      <td>for</td>\n",
       "      <td>IN</td>\n",
       "      <td>for_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>``</td>\n",
       "      <td>‚Äò_``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>JJ</td>\n",
       "      <td>deceptive_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Editing‚Äô</td>\n",
       "      <td>editing‚Äô</td>\n",
       "      <td>NN</td>\n",
       "      <td>editing‚Äô_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Barr</td>\n",
       "      <td>barr</td>\n",
       "      <td>NNP</td>\n",
       "      <td>barr_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>POS</td>\n",
       "      <td>‚Äôs_POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comments</td>\n",
       "      <td>NNS</td>\n",
       "      <td>comments_NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>IN</td>\n",
       "      <td>on_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>``</td>\n",
       "      <td>‚Äú_``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>VB</td>\n",
       "      <td>meet_VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press</td>\n",
       "      <td>press</td>\n",
       "      <td>NN</td>\n",
       "      <td>press_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>NFP</td>\n",
       "      <td>,‚Äù_NFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>NNP</td>\n",
       "      <td>todd_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>.</td>\n",
       "      <td>‚Ä¶_.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT</td>\n",
       "      <td>rt</td>\n",
       "      <td>NNP</td>\n",
       "      <td>rt_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>CC</td>\n",
       "      <td>@_CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>MagaGlam</td>\n",
       "      <td>magaglam</td>\n",
       "      <td>NNP</td>\n",
       "      <td>magaglam_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üá∫üá∏‚ô•</td>\n",
       "      <td>üá∫üá∏‚ô•</td>\n",
       "      <td>NFP</td>\n",
       "      <td>üá∫üá∏‚ô•_NFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VB</td>\n",
       "      <td>bring_VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>RB</td>\n",
       "      <td>back_RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>NN</td>\n",
       "      <td>trump_NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>NFP</td>\n",
       "      <td>üíôüá∫üá∏_NFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CBP</td>\n",
       "      <td>CBP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>CBP_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Home_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NNP</td>\n",
       "      <td>App_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>be_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>RB</td>\n",
       "      <td>now_RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>JJ</td>\n",
       "      <td>available_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>IN</td>\n",
       "      <td>across_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DT</td>\n",
       "      <td>all_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>JJ</td>\n",
       "      <td>mobile_JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NNP</td>\n",
       "      <td>App_NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Stores</td>\n",
       "      <td>store</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>store_NNPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>.</td>\n",
       "      <td>!_.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>NNS</td>\n",
       "      <td>congratulations_NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>IN</td>\n",
       "      <td>to_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>mariano</td>\n",
       "      <td>NNP</td>\n",
       "      <td>mariano_NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date             word            lemma   pos  \\\n",
       "70         4  2020-05-11           Shreds           shreds   VBZ   \n",
       "71         4  2020-05-11              NBC              nbc   NNP   \n",
       "72         4  2020-05-11               ‚Äôs               ‚Äôs   VBZ   \n",
       "73         4  2020-05-11            Chuck            chuck   NNP   \n",
       "74         4  2020-05-11             Todd             todd   NNP   \n",
       "75         4  2020-05-11              For              for    IN   \n",
       "76         4  2020-05-11                ‚Äò                ‚Äò    ``   \n",
       "77         4  2020-05-11        Deceptive        deceptive    JJ   \n",
       "78         4  2020-05-11         Editing‚Äô         editing‚Äô    NN   \n",
       "79         4  2020-05-11               Of               of    IN   \n",
       "80         4  2020-05-11             Barr             barr   NNP   \n",
       "81         4  2020-05-11               ‚Äôs               ‚Äôs   POS   \n",
       "82         4  2020-05-11         Comments         comments   NNS   \n",
       "83         4  2020-05-11               On               on    IN   \n",
       "84         4  2020-05-11                ‚Äú                ‚Äú    ``   \n",
       "85         4  2020-05-11             Meet             meet    VB   \n",
       "86         4  2020-05-11              The              the    DT   \n",
       "87         4  2020-05-11            Press            press    NN   \n",
       "88         4  2020-05-11               ,‚Äù               ,‚Äù   NFP   \n",
       "89         4  2020-05-11             Todd             todd   NNP   \n",
       "90         4  2020-05-11                ‚Ä¶                ‚Ä¶     .   \n",
       "91         5  2011-09-07               RT               rt   NNP   \n",
       "92         5  2011-09-07                @                @    CC   \n",
       "93         5  2011-09-07         MagaGlam         magaglam   NNP   \n",
       "94         5  2011-09-07              üá∫üá∏‚ô•              üá∫üá∏‚ô•   NFP   \n",
       "95         5  2011-09-07            Bring            bring    VB   \n",
       "96         5  2011-09-07             Back             back    RB   \n",
       "97         5  2011-09-07            Trump            trump    NN   \n",
       "98         5  2011-09-07              üíôüá∫üá∏              üíôüá∫üá∏   NFP   \n",
       "99         7  2025-03-19              The              the    DT   \n",
       "100        7  2025-03-19              CBP              CBP   NNP   \n",
       "101        7  2025-03-19             Home             Home   NNP   \n",
       "102        7  2025-03-19              App              App   NNP   \n",
       "103        7  2025-03-19               is               be   VBZ   \n",
       "104        7  2025-03-19              now              now    RB   \n",
       "105        7  2025-03-19        available        available    JJ   \n",
       "106        7  2025-03-19           across           across    IN   \n",
       "107        7  2025-03-19              all              all    DT   \n",
       "108        7  2025-03-19           mobile           mobile    JJ   \n",
       "109        7  2025-03-19              App              App   NNP   \n",
       "110        7  2025-03-19           Stores            store  NNPS   \n",
       "111        7  2025-03-19                !                !     .   \n",
       "112        8  2019-01-23  Congratulations  congratulations   NNS   \n",
       "113        8  2019-01-23               to               to    IN   \n",
       "114        8  2019-01-23          Mariano          mariano   NNP   \n",
       "\n",
       "                 lemma_p  \n",
       "70            shreds_VBZ  \n",
       "71               nbc_NNP  \n",
       "72                ‚Äôs_VBZ  \n",
       "73             chuck_NNP  \n",
       "74              todd_NNP  \n",
       "75                for_IN  \n",
       "76                  ‚Äò_``  \n",
       "77          deceptive_JJ  \n",
       "78           editing‚Äô_NN  \n",
       "79                 of_IN  \n",
       "80              barr_NNP  \n",
       "81                ‚Äôs_POS  \n",
       "82          comments_NNS  \n",
       "83                 on_IN  \n",
       "84                  ‚Äú_``  \n",
       "85               meet_VB  \n",
       "86                the_DT  \n",
       "87              press_NN  \n",
       "88                ,‚Äù_NFP  \n",
       "89              todd_NNP  \n",
       "90                   ‚Ä¶_.  \n",
       "91                rt_NNP  \n",
       "92                  @_CC  \n",
       "93          magaglam_NNP  \n",
       "94               üá∫üá∏‚ô•_NFP  \n",
       "95              bring_VB  \n",
       "96               back_RB  \n",
       "97              trump_NN  \n",
       "98               üíôüá∫üá∏_NFP  \n",
       "99                the_DT  \n",
       "100              CBP_NNP  \n",
       "101             Home_NNP  \n",
       "102              App_NNP  \n",
       "103               be_VBZ  \n",
       "104               now_RB  \n",
       "105         available_JJ  \n",
       "106            across_IN  \n",
       "107               all_DT  \n",
       "108            mobile_JJ  \n",
       "109              App_NNP  \n",
       "110           store_NNPS  \n",
       "111                  !_.  \n",
       "112  congratulations_NNS  \n",
       "113                to_IN  \n",
       "114          mariano_NNP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "flsp = pd.read_csv(\"testkorpus_divers_50_flair_spacy.csv\")\n",
    "display(flsp[70:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flsp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit zu Flair: \n",
    "(Flair bietet keine Lemmatisierung)\n",
    "#### Flair upos:\n",
    "- Lemmatisierung nur lower\n",
    "- Url zerh√§kselt (mrzad9 als PUNCT)\n",
    "- Emojis als SYM\n",
    "- @_KatherineWebb in \"\"@_ SYM KatherineWebb NUM zerteilt\n",
    "- Hashtags werden zerlegt (# SYM MissUSA NUM, # SYM AGENDA47 NUM)\n",
    "- RT als X, @ X darhar981 X\n",
    "- zu viel NUM (weekend NUM, Vegas NUM, former.Miss NUM (und falsch tokenisiert), illnesses NUM, Attorney NUM, Shreds NUM, Fame NUM)\n",
    "- Barr's wird zu Barr PUNCT 's SYM\n",
    "- @MagaGlam(Emojis) Bring Back Trump Emojis: wird zu @ X MagaGlam X Emojis SYM Bring VERB Back SYM Trump NUM Emojis SYM\n",
    "- available VERB\n",
    "- on INTJ unanimously INTJ (Interjection) being PRON elected VERB\n",
    "- of INTJ L.L.Bean INTJ (und an sp√§terer Stelle L.L.Bean als PUNCT)\n",
    "- @macys wird @ X macys X\n",
    "- !.. X, . X\n",
    "- @ SYM WhiteHouse NUM, AMERICA NUM\n",
    "- This NUM week NOUN we VERB hosted VERB a DET # SYM MadeInAmerica NUM event NOUN\n",
    "\n",
    "#### Flair pos:\n",
    "\n",
    "- Lemmatisierung nur lower\n",
    "- Url zerh√§kselt, aber anders getaggt als upos Modell (mrzad9 als NN)\n",
    "- @_KatherineWebb in \"\"@_ NFP KatherineWebb NNP zerteilt\n",
    "- Hashtags werden zerlegt (# NNP MissUSA NNP, # NFP AGENDA47 CD, # NFP EnterSandman NN)\n",
    "- weekend NN, Vegas NNP, former.Miss NN, Illnesses NNPS\n",
    "- Addressing VBG, Shreds VBZ, Barr NNP 's VBZ\n",
    "- RT NN, @ IN darhar981 CD, elected VBN\n",
    "- @ werden zerlegt (@ SYM MagaGlam NNP Emojis NFP Bring VB Back RB Trump NN Emojis NFP\n",
    "- Emojis als NFP\n",
    "- @macys wird @ NFP macys NNS\n",
    "- This DT week NN we PRP hosted VBD a DT # NN MadeInAmerica NNP event NN\n",
    "\n",
    "#### Flair-spacy: \n",
    "\n",
    "- da die beiden Tagger verschieden tokenisieren, wird Spacys Lemmatisieren nicht immer angewendet (hier schon: Stores wird zu store, aber being bleibt being, elected bleibt elected, BEST wird best, People wird people,longer wird long, takes wird take, harder wird hard, workers zu worker, is zu be, was zu be, stolen zu steal, 're zu be,...)\n",
    "- erweitertes Tagset (pos mit ADD und NFP)\n",
    "- 9pm ungetrennt als NN\n",
    "- Url zerh√§kselt und als Satz getaggt (ADD NFP ADD SYM NNP NFP CD NNS .)\n",
    "- Addressing wird zu addressing lemmatisiert\n",
    "- #AGENDA47 wird zu # NFP AGENDA47 NN\n",
    "- RT als NNP\n",
    "- @ CC darhar981 ADD\n",
    "- Shreds wird zu shreds lemmatisiert und VBZ\n",
    "- Comments wird zu comments lemmatisiert\n",
    "- Trennung von Hashtags und @ (# NFP MAGA NNP, @ CC LBPerfectMaine NNP, # NNP KellyFile NNP)\n",
    "- Emojis als NFP\n",
    "- L.L. Bean als NNP ohne Leerzeichen\n",
    "- even RB more RBR now RB (ist richtig)\n",
    "- its als PRP\n",
    "- doesn't wird zu does (was zu do lemmatisiert wird) VBZ und n't (was zu not lemmatisiert wird) RB\n",
    "- ol' als JJ\n",
    "- nicht konsequent segmentiert: predictions. als NN, 1887.Twisting als VBG\n",
    "- Hashtag als Dollarzeichen? MAGA NN, more JJR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Bert\n",
    "https://huggingface.co/vblagoje/bert-english-uncased-finetuned-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>reminder_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Miss_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>Universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>competition_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>live_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>from_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Bahamas_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>tonight_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>ADP</td>\n",
       "      <td>@_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NUM</td>\n",
       "      <td>9_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>pm</td>\n",
       "      <td>pm</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>pm_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>(_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>EST</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>EST_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>)_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>NBC</td>\n",
       "      <td>NBC</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NBC_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>http</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>/</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>/</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>tiny</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>ur</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>l</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>.</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>http://tinyurl.com/mrzad9_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>com</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>/</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>mr</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>za</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>d</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>http://tinyurl.com/mrzad9_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>@</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@timc1021_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>Tim</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>@timc1021_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>c</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>@timc1021_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>10</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>NUM</td>\n",
       "      <td>@timc1021_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>21</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>NUM</td>\n",
       "      <td>@timc1021_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>thank</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>thank_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>@</td>\n",
       "      <td>@_KatherineWebb</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@_KatherineWebb_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>_</td>\n",
       "      <td>@_KatherineWebb</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@_KatherineWebb_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>@_KatherineWebb</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@_KatherineWebb_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>We</td>\n",
       "      <td>@_KatherineWebb</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@_KatherineWebb_PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word                      lemma    pos  \\\n",
       "0         0  2010-11-04     Reminder                   reminder   NOUN   \n",
       "1         0  2010-11-04            :                          :  PUNCT   \n",
       "2         0  2010-11-04          The                        the    DET   \n",
       "3         0  2010-11-04         Miss                       Miss  PROPN   \n",
       "4         0  2010-11-04     Universe                   Universe  PROPN   \n",
       "5         0  2010-11-04  competition                competition   NOUN   \n",
       "6         0  2010-11-04         will                       will    AUX   \n",
       "7         0  2010-11-04           be                         be    AUX   \n",
       "8         0  2010-11-04         LIVE                       live    ADJ   \n",
       "9         0  2010-11-04         from                       from    ADP   \n",
       "10        0  2010-11-04          the                        the    DET   \n",
       "11        0  2010-11-04      Bahamas                    Bahamas  PROPN   \n",
       "12        0  2010-11-04            -                          -  PUNCT   \n",
       "13        0  2010-11-04      Tonight                    tonight   NOUN   \n",
       "14        0  2010-11-04            @                          @    ADP   \n",
       "15        0  2010-11-04            9                          9    NUM   \n",
       "16        0  2010-11-04           pm                         pm   NOUN   \n",
       "17        0  2010-11-04            (                          (  PUNCT   \n",
       "18        0  2010-11-04          EST                        EST   NOUN   \n",
       "19        0  2010-11-04            )                          )  PUNCT   \n",
       "20        0  2010-11-04           on                         on    ADP   \n",
       "21        0  2010-11-04          NBC                        NBC  PROPN   \n",
       "22        0  2010-11-04            :                          :  PUNCT   \n",
       "23        0  2010-11-04         http  http://tinyurl.com/mrzad9      X   \n",
       "24        0  2010-11-04            :  http://tinyurl.com/mrzad9  PUNCT   \n",
       "25        0  2010-11-04            /  http://tinyurl.com/mrzad9  PUNCT   \n",
       "26        0  2010-11-04            /  http://tinyurl.com/mrzad9  PUNCT   \n",
       "27        0  2010-11-04         tiny  http://tinyurl.com/mrzad9      X   \n",
       "28        0  2010-11-04           ur  http://tinyurl.com/mrzad9      X   \n",
       "29        0  2010-11-04            l  http://tinyurl.com/mrzad9      X   \n",
       "30        0  2010-11-04            .  http://tinyurl.com/mrzad9   NOUN   \n",
       "31        0  2010-11-04          com  http://tinyurl.com/mrzad9  PROPN   \n",
       "32        0  2010-11-04            /  http://tinyurl.com/mrzad9  PUNCT   \n",
       "33        0  2010-11-04           mr  http://tinyurl.com/mrzad9      X   \n",
       "34        0  2010-11-04           za  http://tinyurl.com/mrzad9      X   \n",
       "35        0  2010-11-04            d  http://tinyurl.com/mrzad9      X   \n",
       "36        0  2010-11-04            9  http://tinyurl.com/mrzad9   NOUN   \n",
       "37        1  2013-08-15            @                  @timc1021    SYM   \n",
       "38        1  2013-08-15          Tim                  @timc1021   NOUN   \n",
       "39        1  2013-08-15            c                  @timc1021   NOUN   \n",
       "40        1  2013-08-15           10                  @timc1021    NUM   \n",
       "41        1  2013-08-15           21                  @timc1021    NUM   \n",
       "42        1  2013-08-15       Thanks                      thank   NOUN   \n",
       "43        1  2013-08-15            !                          !  PUNCT   \n",
       "44        2  2013-06-12            \"                          \"  PUNCT   \n",
       "45        2  2013-06-12            \"                          \"  PUNCT   \n",
       "46        2  2013-06-12            @            @_KatherineWebb    SYM   \n",
       "47        2  2013-06-12            _            @_KatherineWebb    SYM   \n",
       "48        2  2013-06-12    Katherine            @_KatherineWebb  PROPN   \n",
       "49        2  2013-06-12           We            @_KatherineWebb  PROPN   \n",
       "\n",
       "                            lemma_p  \n",
       "0                     reminder_NOUN  \n",
       "1                           :_PUNCT  \n",
       "2                           the_DET  \n",
       "3                        Miss_PROPN  \n",
       "4                    Universe_PROPN  \n",
       "5                  competition_NOUN  \n",
       "6                          will_AUX  \n",
       "7                            be_AUX  \n",
       "8                          live_ADJ  \n",
       "9                          from_ADP  \n",
       "10                          the_DET  \n",
       "11                    Bahamas_PROPN  \n",
       "12                          -_PUNCT  \n",
       "13                     tonight_NOUN  \n",
       "14                            @_ADP  \n",
       "15                            9_NUM  \n",
       "16                          pm_NOUN  \n",
       "17                          (_PUNCT  \n",
       "18                         EST_NOUN  \n",
       "19                          )_PUNCT  \n",
       "20                           on_ADP  \n",
       "21                        NBC_PROPN  \n",
       "22                          :_PUNCT  \n",
       "23      http://tinyurl.com/mrzad9_X  \n",
       "24  http://tinyurl.com/mrzad9_PUNCT  \n",
       "25  http://tinyurl.com/mrzad9_PUNCT  \n",
       "26  http://tinyurl.com/mrzad9_PUNCT  \n",
       "27      http://tinyurl.com/mrzad9_X  \n",
       "28      http://tinyurl.com/mrzad9_X  \n",
       "29      http://tinyurl.com/mrzad9_X  \n",
       "30   http://tinyurl.com/mrzad9_NOUN  \n",
       "31  http://tinyurl.com/mrzad9_PROPN  \n",
       "32  http://tinyurl.com/mrzad9_PUNCT  \n",
       "33      http://tinyurl.com/mrzad9_X  \n",
       "34      http://tinyurl.com/mrzad9_X  \n",
       "35      http://tinyurl.com/mrzad9_X  \n",
       "36   http://tinyurl.com/mrzad9_NOUN  \n",
       "37                    @timc1021_SYM  \n",
       "38                   @timc1021_NOUN  \n",
       "39                   @timc1021_NOUN  \n",
       "40                    @timc1021_NUM  \n",
       "41                    @timc1021_NUM  \n",
       "42                       thank_NOUN  \n",
       "43                          !_PUNCT  \n",
       "44                          \"_PUNCT  \n",
       "45                          \"_PUNCT  \n",
       "46              @_KatherineWebb_SYM  \n",
       "47              @_KatherineWebb_SYM  \n",
       "48            @_KatherineWebb_PROPN  \n",
       "49            @_KatherineWebb_PROPN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Bert mit SpaCy ####\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import spacy\n",
    "\n",
    "model_name = \"vblagoje/bert-english-uncased-finetuned-pos\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "id2label = model.config.id2label\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "text_col = \"text\"\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row.get(text_col)\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "\n",
    "    spacy_doc = nlp(str(text))\n",
    "\n",
    "    encoding = tokenizer(str(text), return_tensors=\"pt\", return_offsets_mapping=True, truncation=True)\n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "    offset_mappings = encoding[\"offset_mapping\"][0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    logits = output.logits\n",
    "    predictions = torch.argmax(logits, dim=2)[0].tolist()\n",
    "\n",
    "    for idx_token, pred_id in enumerate(predictions):\n",
    "        start, end = offset_mappings[idx_token].tolist()\n",
    "        if start == end:\n",
    "            continue\n",
    "\n",
    "        word_text = text[start:end]\n",
    "        pos_tag = id2label[pred_id]\n",
    "        lemma = None\n",
    "        for token in spacy_doc:\n",
    "            token_start = token.idx\n",
    "            token_end = token.idx + len(token.text)\n",
    "            if start >= token_start and end <= token_end:\n",
    "                lemma = token.lemma_\n",
    "                break\n",
    "        if lemma is None:\n",
    "            lemma = word_text.lower()\n",
    "\n",
    "        results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"date\": row.get(\"date\"),\n",
    "            \"word\": word_text,\n",
    "            \"lemma\": lemma,\n",
    "            \"pos\": pos_tag,\n",
    "            \"lemma_p\": f\"{lemma}_{pos_tag}\"\n",
    "        })\n",
    "\n",
    "ber = pd.DataFrame(results)\n",
    "ber.to_csv(\"testkorpus_divers_50_bert.csv\", index=False)\n",
    "display(ber.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äô</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>s</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>comment_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>Meet</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Meet_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>The_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Press_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äù</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>todd_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>@</td>\n",
       "      <td>@magaglam</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@magaglam_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>MagaGlamüá∫üá∏‚ô•</td>\n",
       "      <td>magaglamüá∫üá∏‚ô•</td>\n",
       "      <td>SYM</td>\n",
       "      <td>magaglamüá∫üá∏‚ô•_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>back_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>SYM</td>\n",
       "      <td>üíôüá∫üá∏_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CB</td>\n",
       "      <td>CBP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CBP_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>P</td>\n",
       "      <td>CBP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CBP_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Home_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>now_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>available_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>ADP</td>\n",
       "      <td>across_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>mobile_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Stores</td>\n",
       "      <td>store</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>store_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>congratulation_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Mariano_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Rivera_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>on_SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>ADV</td>\n",
       "      <td>unanimously_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>being</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>elected</td>\n",
       "      <td>elect</td>\n",
       "      <td>VERB</td>\n",
       "      <td>elect_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>National</td>\n",
       "      <td>National</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>National_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Baseball</td>\n",
       "      <td>Baseball</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Baseball_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Hall</td>\n",
       "      <td>Hall</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Hall_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Fame</td>\n",
       "      <td>Fame</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Fame_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Not</td>\n",
       "      <td>not</td>\n",
       "      <td>ADV</td>\n",
       "      <td>not_ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date             word           lemma    pos  \\\n",
       "115        4  2020-05-11                ‚Äô              ‚Äôs   PART   \n",
       "116        4  2020-05-11                s              ‚Äôs   PART   \n",
       "117        4  2020-05-11         Comments         comment   NOUN   \n",
       "118        4  2020-05-11               On              on    ADP   \n",
       "119        4  2020-05-11                ‚Äú               \"  PUNCT   \n",
       "120        4  2020-05-11             Meet            Meet   VERB   \n",
       "121        4  2020-05-11              The             The    DET   \n",
       "122        4  2020-05-11            Press           Press  PROPN   \n",
       "123        4  2020-05-11                ,               ,  PUNCT   \n",
       "124        4  2020-05-11                ‚Äù               \"  PUNCT   \n",
       "125        4  2020-05-11             Todd            todd  PROPN   \n",
       "126        4  2020-05-11                ‚Ä¶               ‚Ä¶  PUNCT   \n",
       "127        5  2011-09-07               RT              RT  PROPN   \n",
       "128        5  2011-09-07                @       @magaglam    SYM   \n",
       "129        5  2011-09-07      MagaGlamüá∫üá∏‚ô•     magaglamüá∫üá∏‚ô•    SYM   \n",
       "130        5  2011-09-07            Bring           bring   VERB   \n",
       "131        5  2011-09-07             Back            back    ADV   \n",
       "132        5  2011-09-07            Trump           Trump  PROPN   \n",
       "133        5  2011-09-07              üíôüá∫üá∏             üíôüá∫üá∏    SYM   \n",
       "134        7  2025-03-19              The             the    DET   \n",
       "135        7  2025-03-19               CB             CBP  PROPN   \n",
       "136        7  2025-03-19                P             CBP  PROPN   \n",
       "137        7  2025-03-19             Home            Home   NOUN   \n",
       "138        7  2025-03-19              App             App   NOUN   \n",
       "139        7  2025-03-19               is              be    AUX   \n",
       "140        7  2025-03-19              now             now    ADV   \n",
       "141        7  2025-03-19        available       available    ADJ   \n",
       "142        7  2025-03-19           across          across    ADP   \n",
       "143        7  2025-03-19              all             all    DET   \n",
       "144        7  2025-03-19           mobile          mobile    ADJ   \n",
       "145        7  2025-03-19              App             App   NOUN   \n",
       "146        7  2025-03-19           Stores           store   NOUN   \n",
       "147        7  2025-03-19                !               !  PUNCT   \n",
       "148        8  2019-01-23  Congratulations  congratulation   NOUN   \n",
       "149        8  2019-01-23               to              to    ADP   \n",
       "150        8  2019-01-23          Mariano         Mariano  PROPN   \n",
       "151        8  2019-01-23           Rivera          Rivera  PROPN   \n",
       "152        8  2019-01-23               on              on  SCONJ   \n",
       "153        8  2019-01-23      unanimously     unanimously    ADV   \n",
       "154        8  2019-01-23            being              be    AUX   \n",
       "155        8  2019-01-23          elected           elect   VERB   \n",
       "156        8  2019-01-23               to              to    ADP   \n",
       "157        8  2019-01-23              the             the    DET   \n",
       "158        8  2019-01-23         National        National  PROPN   \n",
       "159        8  2019-01-23         Baseball        Baseball  PROPN   \n",
       "160        8  2019-01-23             Hall            Hall  PROPN   \n",
       "161        8  2019-01-23               of              of    ADP   \n",
       "162        8  2019-01-23             Fame            Fame  PROPN   \n",
       "163        8  2019-01-23                !               !  PUNCT   \n",
       "164        8  2019-01-23              Not             not    ADV   \n",
       "\n",
       "                 lemma_p  \n",
       "115              ‚Äôs_PART  \n",
       "116              ‚Äôs_PART  \n",
       "117         comment_NOUN  \n",
       "118               on_ADP  \n",
       "119              \"_PUNCT  \n",
       "120            Meet_VERB  \n",
       "121              The_DET  \n",
       "122          Press_PROPN  \n",
       "123              ,_PUNCT  \n",
       "124              \"_PUNCT  \n",
       "125           todd_PROPN  \n",
       "126              ‚Ä¶_PUNCT  \n",
       "127             RT_PROPN  \n",
       "128        @magaglam_SYM  \n",
       "129      magaglamüá∫üá∏‚ô•_SYM  \n",
       "130           bring_VERB  \n",
       "131             back_ADV  \n",
       "132          Trump_PROPN  \n",
       "133              üíôüá∫üá∏_SYM  \n",
       "134              the_DET  \n",
       "135            CBP_PROPN  \n",
       "136            CBP_PROPN  \n",
       "137            Home_NOUN  \n",
       "138             App_NOUN  \n",
       "139               be_AUX  \n",
       "140              now_ADV  \n",
       "141        available_ADJ  \n",
       "142           across_ADP  \n",
       "143              all_DET  \n",
       "144           mobile_ADJ  \n",
       "145             App_NOUN  \n",
       "146           store_NOUN  \n",
       "147              !_PUNCT  \n",
       "148  congratulation_NOUN  \n",
       "149               to_ADP  \n",
       "150        Mariano_PROPN  \n",
       "151         Rivera_PROPN  \n",
       "152             on_SCONJ  \n",
       "153      unanimously_ADV  \n",
       "154               be_AUX  \n",
       "155           elect_VERB  \n",
       "156               to_ADP  \n",
       "157              the_DET  \n",
       "158       National_PROPN  \n",
       "159       Baseball_PROPN  \n",
       "160           Hall_PROPN  \n",
       "161               of_ADP  \n",
       "162           Fame_PROPN  \n",
       "163              !_PUNCT  \n",
       "164              not_ADV  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ber = pd.read_csv(\"testkorpus_divers_50_bert.csv\")\n",
    "display(ber[115:165])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>reminder_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Miss_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>Universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>competition_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>live_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>from_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Bahamas_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>tonight_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>ADP</td>\n",
       "      <td>@_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NUM</td>\n",
       "      <td>9_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>pm</td>\n",
       "      <td>pm</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>pm_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>(_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>EST</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>EST_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>)_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>NBC</td>\n",
       "      <td>NBC</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NBC_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>http</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>/</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>/</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>tiny</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>ur</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>l</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>.</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>http://tinyurl.com/mrzad9_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>com</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>/</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>http://tinyurl.com/mrzad9_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>mr</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>za</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>d</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>X</td>\n",
       "      <td>http://tinyurl.com/mrzad9_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9</td>\n",
       "      <td>http://tinyurl.com/mrzad9</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>http://tinyurl.com/mrzad9_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>@</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@timc1021_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>Tim</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>@timc1021_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>c</td>\n",
       "      <td>@timc1021</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>@timc1021_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word                      lemma    pos  \\\n",
       "0         0  2010-11-04     Reminder                   reminder   NOUN   \n",
       "1         0  2010-11-04            :                          :  PUNCT   \n",
       "2         0  2010-11-04          The                        the    DET   \n",
       "3         0  2010-11-04         Miss                       Miss  PROPN   \n",
       "4         0  2010-11-04     Universe                   Universe  PROPN   \n",
       "5         0  2010-11-04  competition                competition   NOUN   \n",
       "6         0  2010-11-04         will                       will    AUX   \n",
       "7         0  2010-11-04           be                         be    AUX   \n",
       "8         0  2010-11-04         LIVE                       live    ADJ   \n",
       "9         0  2010-11-04         from                       from    ADP   \n",
       "10        0  2010-11-04          the                        the    DET   \n",
       "11        0  2010-11-04      Bahamas                    Bahamas  PROPN   \n",
       "12        0  2010-11-04            -                          -  PUNCT   \n",
       "13        0  2010-11-04      Tonight                    tonight   NOUN   \n",
       "14        0  2010-11-04            @                          @    ADP   \n",
       "15        0  2010-11-04            9                          9    NUM   \n",
       "16        0  2010-11-04           pm                         pm   NOUN   \n",
       "17        0  2010-11-04            (                          (  PUNCT   \n",
       "18        0  2010-11-04          EST                        EST   NOUN   \n",
       "19        0  2010-11-04            )                          )  PUNCT   \n",
       "20        0  2010-11-04           on                         on    ADP   \n",
       "21        0  2010-11-04          NBC                        NBC  PROPN   \n",
       "22        0  2010-11-04            :                          :  PUNCT   \n",
       "23        0  2010-11-04         http  http://tinyurl.com/mrzad9      X   \n",
       "24        0  2010-11-04            :  http://tinyurl.com/mrzad9  PUNCT   \n",
       "25        0  2010-11-04            /  http://tinyurl.com/mrzad9  PUNCT   \n",
       "26        0  2010-11-04            /  http://tinyurl.com/mrzad9  PUNCT   \n",
       "27        0  2010-11-04         tiny  http://tinyurl.com/mrzad9      X   \n",
       "28        0  2010-11-04           ur  http://tinyurl.com/mrzad9      X   \n",
       "29        0  2010-11-04            l  http://tinyurl.com/mrzad9      X   \n",
       "30        0  2010-11-04            .  http://tinyurl.com/mrzad9   NOUN   \n",
       "31        0  2010-11-04          com  http://tinyurl.com/mrzad9  PROPN   \n",
       "32        0  2010-11-04            /  http://tinyurl.com/mrzad9  PUNCT   \n",
       "33        0  2010-11-04           mr  http://tinyurl.com/mrzad9      X   \n",
       "34        0  2010-11-04           za  http://tinyurl.com/mrzad9      X   \n",
       "35        0  2010-11-04            d  http://tinyurl.com/mrzad9      X   \n",
       "36        0  2010-11-04            9  http://tinyurl.com/mrzad9   NOUN   \n",
       "37        1  2013-08-15            @                  @timc1021    SYM   \n",
       "38        1  2013-08-15          Tim                  @timc1021   NOUN   \n",
       "39        1  2013-08-15            c                  @timc1021   NOUN   \n",
       "\n",
       "                            lemma_p  \n",
       "0                     reminder_NOUN  \n",
       "1                           :_PUNCT  \n",
       "2                           the_DET  \n",
       "3                        Miss_PROPN  \n",
       "4                    Universe_PROPN  \n",
       "5                  competition_NOUN  \n",
       "6                          will_AUX  \n",
       "7                            be_AUX  \n",
       "8                          live_ADJ  \n",
       "9                          from_ADP  \n",
       "10                          the_DET  \n",
       "11                    Bahamas_PROPN  \n",
       "12                          -_PUNCT  \n",
       "13                     tonight_NOUN  \n",
       "14                            @_ADP  \n",
       "15                            9_NUM  \n",
       "16                          pm_NOUN  \n",
       "17                          (_PUNCT  \n",
       "18                         EST_NOUN  \n",
       "19                          )_PUNCT  \n",
       "20                           on_ADP  \n",
       "21                        NBC_PROPN  \n",
       "22                          :_PUNCT  \n",
       "23      http://tinyurl.com/mrzad9_X  \n",
       "24  http://tinyurl.com/mrzad9_PUNCT  \n",
       "25  http://tinyurl.com/mrzad9_PUNCT  \n",
       "26  http://tinyurl.com/mrzad9_PUNCT  \n",
       "27      http://tinyurl.com/mrzad9_X  \n",
       "28      http://tinyurl.com/mrzad9_X  \n",
       "29      http://tinyurl.com/mrzad9_X  \n",
       "30   http://tinyurl.com/mrzad9_NOUN  \n",
       "31  http://tinyurl.com/mrzad9_PROPN  \n",
       "32  http://tinyurl.com/mrzad9_PUNCT  \n",
       "33      http://tinyurl.com/mrzad9_X  \n",
       "34      http://tinyurl.com/mrzad9_X  \n",
       "35      http://tinyurl.com/mrzad9_X  \n",
       "36   http://tinyurl.com/mrzad9_NOUN  \n",
       "37                    @timc1021_SYM  \n",
       "38                   @timc1021_NOUN  \n",
       "39                   @timc1021_NOUN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Bert ### ohne Pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import spacy\n",
    "\n",
    "model_name = \"vblagoje/bert-english-uncased-finetuned-pos\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "id2label = model.config.id2label\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    spacy_doc = nlp(str(text))\n",
    "    \n",
    "    encoding = tokenizer(str(text), return_tensors=\"pt\", return_offsets_mapping=True, truncation=True)\n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "    offset_mappings = encoding[\"offset_mapping\"][0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "    \n",
    "    logits = output.logits  \n",
    "    predictions = torch.argmax(logits, dim=2)[0].tolist()\n",
    "    \n",
    "    for idx_token, pred_id in enumerate(predictions):\n",
    "        start, end = offset_mappings[idx_token].tolist()\n",
    "        if start == end:\n",
    "            continue\n",
    "        \n",
    "        word_text = text[start:end]\n",
    "        pos_tag = id2label[pred_id]\n",
    "        \n",
    "        lemma = None\n",
    "        for token in spacy_doc:\n",
    "            token_start = token.idx\n",
    "            token_end = token.idx + len(token.text)\n",
    "            if start >= token_start and end <= token_end:\n",
    "                lemma = token.lemma_\n",
    "                break\n",
    "        if lemma is None:\n",
    "            lemma = word_text.lower()\n",
    "        \n",
    "        results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"date\": row.get(\"date\"),\n",
    "            \"word\": word_text,\n",
    "            \"lemma\": lemma,\n",
    "            \"pos\": pos_tag,\n",
    "            \"lemma_p\": f\"{lemma}_{pos_tag}\"\n",
    "        })\n",
    "\n",
    "bert = pd.DataFrame(results)\n",
    "bert.to_csv(\"testkorpus_divers_50_bert2.csv\", index=False)\n",
    "display(bert.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äô</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>s</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>PART</td>\n",
       "      <td>‚Äôs_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>comment_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>Meet</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Meet_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>The_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Press_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äù</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>todd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>todd_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>@</td>\n",
       "      <td>@magaglam</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@magaglam_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>MagaGlamüá∫üá∏‚ô•</td>\n",
       "      <td>magaglamüá∫üá∏‚ô•</td>\n",
       "      <td>SYM</td>\n",
       "      <td>magaglamüá∫üá∏‚ô•_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>back_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>SYM</td>\n",
       "      <td>üíôüá∫üá∏_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CB</td>\n",
       "      <td>CBP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CBP_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>P</td>\n",
       "      <td>CBP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CBP_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Home_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>now_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>available_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>ADP</td>\n",
       "      <td>across_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>mobile_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Stores</td>\n",
       "      <td>store</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>store_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>congratulation_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Mariano_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Rivera_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>on_SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>ADV</td>\n",
       "      <td>unanimously_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>being</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>elected</td>\n",
       "      <td>elect</td>\n",
       "      <td>VERB</td>\n",
       "      <td>elect_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>National</td>\n",
       "      <td>National</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>National_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Baseball</td>\n",
       "      <td>Baseball</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Baseball_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Hall</td>\n",
       "      <td>Hall</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Hall_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Fame</td>\n",
       "      <td>Fame</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Fame_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Not</td>\n",
       "      <td>not</td>\n",
       "      <td>ADV</td>\n",
       "      <td>not_ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date             word           lemma    pos  \\\n",
       "115        4  2020-05-11                ‚Äô              ‚Äôs   PART   \n",
       "116        4  2020-05-11                s              ‚Äôs   PART   \n",
       "117        4  2020-05-11         Comments         comment   NOUN   \n",
       "118        4  2020-05-11               On              on    ADP   \n",
       "119        4  2020-05-11                ‚Äú               \"  PUNCT   \n",
       "120        4  2020-05-11             Meet            Meet   VERB   \n",
       "121        4  2020-05-11              The             The    DET   \n",
       "122        4  2020-05-11            Press           Press  PROPN   \n",
       "123        4  2020-05-11                ,               ,  PUNCT   \n",
       "124        4  2020-05-11                ‚Äù               \"  PUNCT   \n",
       "125        4  2020-05-11             Todd            todd  PROPN   \n",
       "126        4  2020-05-11                ‚Ä¶               ‚Ä¶  PUNCT   \n",
       "127        5  2011-09-07               RT              RT  PROPN   \n",
       "128        5  2011-09-07                @       @magaglam    SYM   \n",
       "129        5  2011-09-07      MagaGlamüá∫üá∏‚ô•     magaglamüá∫üá∏‚ô•    SYM   \n",
       "130        5  2011-09-07            Bring           bring   VERB   \n",
       "131        5  2011-09-07             Back            back    ADV   \n",
       "132        5  2011-09-07            Trump           Trump  PROPN   \n",
       "133        5  2011-09-07              üíôüá∫üá∏             üíôüá∫üá∏    SYM   \n",
       "134        7  2025-03-19              The             the    DET   \n",
       "135        7  2025-03-19               CB             CBP  PROPN   \n",
       "136        7  2025-03-19                P             CBP  PROPN   \n",
       "137        7  2025-03-19             Home            Home   NOUN   \n",
       "138        7  2025-03-19              App             App   NOUN   \n",
       "139        7  2025-03-19               is              be    AUX   \n",
       "140        7  2025-03-19              now             now    ADV   \n",
       "141        7  2025-03-19        available       available    ADJ   \n",
       "142        7  2025-03-19           across          across    ADP   \n",
       "143        7  2025-03-19              all             all    DET   \n",
       "144        7  2025-03-19           mobile          mobile    ADJ   \n",
       "145        7  2025-03-19              App             App   NOUN   \n",
       "146        7  2025-03-19           Stores           store   NOUN   \n",
       "147        7  2025-03-19                !               !  PUNCT   \n",
       "148        8  2019-01-23  Congratulations  congratulation   NOUN   \n",
       "149        8  2019-01-23               to              to    ADP   \n",
       "150        8  2019-01-23          Mariano         Mariano  PROPN   \n",
       "151        8  2019-01-23           Rivera          Rivera  PROPN   \n",
       "152        8  2019-01-23               on              on  SCONJ   \n",
       "153        8  2019-01-23      unanimously     unanimously    ADV   \n",
       "154        8  2019-01-23            being              be    AUX   \n",
       "155        8  2019-01-23          elected           elect   VERB   \n",
       "156        8  2019-01-23               to              to    ADP   \n",
       "157        8  2019-01-23              the             the    DET   \n",
       "158        8  2019-01-23         National        National  PROPN   \n",
       "159        8  2019-01-23         Baseball        Baseball  PROPN   \n",
       "160        8  2019-01-23             Hall            Hall  PROPN   \n",
       "161        8  2019-01-23               of              of    ADP   \n",
       "162        8  2019-01-23             Fame            Fame  PROPN   \n",
       "163        8  2019-01-23                !               !  PUNCT   \n",
       "164        8  2019-01-23              Not             not    ADV   \n",
       "\n",
       "                 lemma_p  \n",
       "115              ‚Äôs_PART  \n",
       "116              ‚Äôs_PART  \n",
       "117         comment_NOUN  \n",
       "118               on_ADP  \n",
       "119              \"_PUNCT  \n",
       "120            Meet_VERB  \n",
       "121              The_DET  \n",
       "122          Press_PROPN  \n",
       "123              ,_PUNCT  \n",
       "124              \"_PUNCT  \n",
       "125           todd_PROPN  \n",
       "126              ‚Ä¶_PUNCT  \n",
       "127             RT_PROPN  \n",
       "128        @magaglam_SYM  \n",
       "129      magaglamüá∫üá∏‚ô•_SYM  \n",
       "130           bring_VERB  \n",
       "131             back_ADV  \n",
       "132          Trump_PROPN  \n",
       "133              üíôüá∫üá∏_SYM  \n",
       "134              the_DET  \n",
       "135            CBP_PROPN  \n",
       "136            CBP_PROPN  \n",
       "137            Home_NOUN  \n",
       "138             App_NOUN  \n",
       "139               be_AUX  \n",
       "140              now_ADV  \n",
       "141        available_ADJ  \n",
       "142           across_ADP  \n",
       "143              all_DET  \n",
       "144           mobile_ADJ  \n",
       "145             App_NOUN  \n",
       "146           store_NOUN  \n",
       "147              !_PUNCT  \n",
       "148  congratulation_NOUN  \n",
       "149               to_ADP  \n",
       "150        Mariano_PROPN  \n",
       "151         Rivera_PROPN  \n",
       "152             on_SCONJ  \n",
       "153      unanimously_ADV  \n",
       "154               be_AUX  \n",
       "155           elect_VERB  \n",
       "156               to_ADP  \n",
       "157              the_DET  \n",
       "158       National_PROPN  \n",
       "159       Baseball_PROPN  \n",
       "160           Hall_PROPN  \n",
       "161               of_ADP  \n",
       "162           Fame_PROPN  \n",
       "163              !_PUNCT  \n",
       "164              not_ADV  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bert = pd.read_csv(\"testkorpus_divers_50_bert2.csv\")\n",
    "display(bert[115:165])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2024, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>were</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>released</td>\n",
       "      <td>release</td>\n",
       "      <td>VERB</td>\n",
       "      <td>release_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>ADP</td>\n",
       "      <td>into_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>our</td>\n",
       "      <td>our</td>\n",
       "      <td>PRON</td>\n",
       "      <td>our_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Country</td>\n",
       "      <td>Country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Country_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>thank</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>thank_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Administration</td>\n",
       "      <td>Administration</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Administration_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Policies</td>\n",
       "      <td>Policies</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Policies_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Border</td>\n",
       "      <td>Border</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Border_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>closed</td>\n",
       "      <td>VERB</td>\n",
       "      <td>closed_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>Illegal</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>Illegal_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Immigrants</td>\n",
       "      <td>Immigrants</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Immigrants_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>Anyone</td>\n",
       "      <td>anyone</td>\n",
       "      <td>PRON</td>\n",
       "      <td>anyone_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "      <td>PRON</td>\n",
       "      <td>who_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>tries</td>\n",
       "      <td>try</td>\n",
       "      <td>VERB</td>\n",
       "      <td>try_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>illegally</td>\n",
       "      <td>illegally</td>\n",
       "      <td>ADV</td>\n",
       "      <td>illegally_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>enter</td>\n",
       "      <td>enter</td>\n",
       "      <td>VERB</td>\n",
       "      <td>enter_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>U</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>U.S.A._PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>U.S.A._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>S</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>U.S.A._PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>U.S.A._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>A</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>U.S.A._PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>U.S.A._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>face</td>\n",
       "      <td>face</td>\n",
       "      <td>VERB</td>\n",
       "      <td>face_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>significant</td>\n",
       "      <td>significant</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>significant_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>criminal</td>\n",
       "      <td>criminal</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>criminal_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>penalties</td>\n",
       "      <td>penalty</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>penalty_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>immediate</td>\n",
       "      <td>immediate</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>immediate_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>deportation</td>\n",
       "      <td>deportation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>deportation_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>49</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id        date            word           lemma    pos  \\\n",
       "1980       49  2025-03-01            were              be    AUX   \n",
       "1981       49  2025-03-01        released         release   VERB   \n",
       "1982       49  2025-03-01            into            into    ADP   \n",
       "1983       49  2025-03-01             our             our   PRON   \n",
       "1984       49  2025-03-01         Country         Country   NOUN   \n",
       "1985       49  2025-03-01               .               .  PUNCT   \n",
       "1986       49  2025-03-01          Thanks           thank   NOUN   \n",
       "1987       49  2025-03-01              to              to    ADP   \n",
       "1988       49  2025-03-01             the             the    DET   \n",
       "1989       49  2025-03-01           Trump           Trump  PROPN   \n",
       "1990       49  2025-03-01  Administration  Administration   NOUN   \n",
       "1991       49  2025-03-01        Policies        Policies   NOUN   \n",
       "1992       49  2025-03-01               ,               ,  PUNCT   \n",
       "1993       49  2025-03-01             the             the    DET   \n",
       "1994       49  2025-03-01          Border          Border   NOUN   \n",
       "1995       49  2025-03-01              is              be    AUX   \n",
       "1996       49  2025-03-01          CLOSED          closed   VERB   \n",
       "1997       49  2025-03-01              to              to    ADP   \n",
       "1998       49  2025-03-01             all             all    DET   \n",
       "1999       49  2025-03-01         Illegal         Illegal    ADJ   \n",
       "2000       49  2025-03-01      Immigrants      Immigrants   NOUN   \n",
       "2001       49  2025-03-01               .               .  PUNCT   \n",
       "2002       49  2025-03-01          Anyone          anyone   PRON   \n",
       "2003       49  2025-03-01             who             who   PRON   \n",
       "2004       49  2025-03-01           tries             try   VERB   \n",
       "2005       49  2025-03-01              to              to   PART   \n",
       "2006       49  2025-03-01       illegally       illegally    ADV   \n",
       "2007       49  2025-03-01           enter           enter   VERB   \n",
       "2008       49  2025-03-01             the             the    DET   \n",
       "2009       49  2025-03-01               U          U.S.A.  PROPN   \n",
       "2010       49  2025-03-01               .          U.S.A.  PUNCT   \n",
       "2011       49  2025-03-01               S          U.S.A.  PROPN   \n",
       "2012       49  2025-03-01               .          U.S.A.  PUNCT   \n",
       "2013       49  2025-03-01               A          U.S.A.  PROPN   \n",
       "2014       49  2025-03-01               .          U.S.A.  PUNCT   \n",
       "2015       49  2025-03-01            will            will    AUX   \n",
       "2016       49  2025-03-01            face            face   VERB   \n",
       "2017       49  2025-03-01     significant     significant    ADJ   \n",
       "2018       49  2025-03-01        criminal        criminal    ADJ   \n",
       "2019       49  2025-03-01       penalties         penalty   NOUN   \n",
       "2020       49  2025-03-01             and             and  CCONJ   \n",
       "2021       49  2025-03-01       immediate       immediate    ADJ   \n",
       "2022       49  2025-03-01     deportation     deportation   NOUN   \n",
       "2023       49  2025-03-01               .               .  PUNCT   \n",
       "\n",
       "                  lemma_p  \n",
       "1980               be_AUX  \n",
       "1981         release_VERB  \n",
       "1982             into_ADP  \n",
       "1983             our_PRON  \n",
       "1984         Country_NOUN  \n",
       "1985              ._PUNCT  \n",
       "1986           thank_NOUN  \n",
       "1987               to_ADP  \n",
       "1988              the_DET  \n",
       "1989          Trump_PROPN  \n",
       "1990  Administration_NOUN  \n",
       "1991        Policies_NOUN  \n",
       "1992              ,_PUNCT  \n",
       "1993              the_DET  \n",
       "1994          Border_NOUN  \n",
       "1995               be_AUX  \n",
       "1996          closed_VERB  \n",
       "1997               to_ADP  \n",
       "1998              all_DET  \n",
       "1999          Illegal_ADJ  \n",
       "2000      Immigrants_NOUN  \n",
       "2001              ._PUNCT  \n",
       "2002          anyone_PRON  \n",
       "2003             who_PRON  \n",
       "2004             try_VERB  \n",
       "2005              to_PART  \n",
       "2006        illegally_ADV  \n",
       "2007           enter_VERB  \n",
       "2008              the_DET  \n",
       "2009         U.S.A._PROPN  \n",
       "2010         U.S.A._PUNCT  \n",
       "2011         U.S.A._PROPN  \n",
       "2012         U.S.A._PUNCT  \n",
       "2013         U.S.A._PROPN  \n",
       "2014         U.S.A._PUNCT  \n",
       "2015             will_AUX  \n",
       "2016            face_VERB  \n",
       "2017      significant_ADJ  \n",
       "2018         criminal_ADJ  \n",
       "2019         penalty_NOUN  \n",
       "2020            and_CCONJ  \n",
       "2021        immediate_ADJ  \n",
       "2022     deportation_NOUN  \n",
       "2023              ._PUNCT  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert[1980:2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit zu Bert:\n",
    "#### Bert 1\n",
    "- 2024 Tags sind deutlich mehr als die anderen Tagger vergaben\n",
    "- Url (und auch andere Abk√ºrzungen wie CBP) werden in zu viele Einzelteile zerlegt und falsch bestimmt - X und PUNCT (sonstige W√∂rter auch: USA(Emoji) wird zu usa(emoji) und SYM, also falsch getrennt)\n",
    "- Hashes und @ werden getrennt (#MadeInAmerica wird zu # Made InA meric a)\n",
    "- Emojis werden als SYM erkannt (und wenn falsch getrennt auch der Rest des Wortes)\n",
    "- richtige Lemmatisierung\n",
    "- ca. 7-8.000 Tags mehr als die anderen Tagger (wegen der Links wahrscheinlich)\n",
    "- @Timc1021 wird zu @ SYM Tim NOUN c NOUN 10 NUM 21 NUM\n",
    "- Thanks wird zu thank lemmatisiert als NOUN, Looking zu look als VERB, skies zu sky NOUN\n",
    "- #MissUSA wird zu # SYM Miss PROPN USA PROPN; Lemma missusa?\n",
    "- @ ADP dar PROPN har PROPN 9 NUM 8 NUM 1 NUM\n",
    "- Shreds wird zu Sh VERB red VERB s VERB\n",
    "- Barr's wird zu Barr PROPN ' PART s PART\n",
    "- Emojis als SYM\n",
    "- @MagaGlam(Emojis) wird zu @ SYM und MagaGlam(Emojis) SYM, @Breitbart-news wird zu @ SYM Br PROPN eit X bar X t X Ne X ws X\n",
    "- CBP Home App wird zu CB P Home App\n",
    "- @macys wird zu @ SYM macy PROPN s PROPN\n",
    "- L.L.Bean wird zu L . L. Bean\n",
    "- People wird zu People lemmatisiert\n",
    "- @LBPerfektMaine wird zu @ LB Per fect Main e als X\n",
    "- its als AUX (eigentlich it's)\n",
    "\n",
    "#### Bert 2\n",
    "\n",
    "- Url (und @ und Hashtags) werden zerh√§kselt und mit X und PUNCT getaggt (auch teilweise andere Tags)\n",
    "- pm bleibt pm (nicht p.m.) als NOUN\n",
    "- 9 als NOUN\n",
    "- @Timc1021 wird zu @ SYM Tim NOUN c NOUN 10 NUM 21 NUM\n",
    "- Thanks wird zu thank lemmatisiert und als NOUN getaggt\n",
    "- @_KatherineWebb wird zu @ SYM _ SYM Katherine PROPN We PROPN bb PROPN\n",
    "- Looking wird zu look\n",
    "- #MissUSA wird zu # Miss USA\n",
    "- Barr's wird Barr ' s\n",
    "- Deceptive wird zu Dec ADJ eptive ADJ\n",
    "- Emojis als SYM\n",
    "- Opioid Drug wird zu Op NOUN io X id PROPN Drug NOUN\n",
    "- @FitnessGov. wird zu @ X Fitness X Go X v X . NOUN\n",
    "- #HOF2019(Emoji) wird zu # SYM HOF2019(Emoji) SYM\n",
    "- @macys wird zu @ SYM macy PROPN s PROPN\n",
    "- @WhiteHouse: @ White House\n",
    "- MADE wird zu make lemmatisiert\n",
    "- USA(Flagge) zu usa(Flagge) SYM\n",
    "- #MAGA wird # MAG A\n",
    "- LL. Bean wird zu L . L . Bean\n",
    "- Donald Trump wird Donald Trum p\n",
    "- its AUX\n",
    "- doesn't zu doesn AUX ' PART t PART\n",
    "- ol ' ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TweebankNLP\n",
    "import stanza\n",
    "\n",
    "# config for the `en_tweet` models (models trained only on Tweebank)\n",
    "config = {\n",
    "          'processors': 'tokenize,lemma,pos,depparse,ner',\n",
    "          'lang': 'en',\n",
    "          'tokenize_pretokenized': True, # disable tokenization\n",
    "          'tokenize_model_path': './twitter-stanza/saved_models/tokenize/en_tweet_tokenizer.pt',\n",
    "          'lemma_model_path': './twitter-stanza/saved_models/lemma/en_tweet_lemmatizer.pt',\n",
    "          \"pos_model_path\": './twitter-stanza/saved_models/pos/en_tweet_tagger.pt',\n",
    "          \"depparse_model_path\": './twitter-stanza/saved_models/depparse/en_tweet_parser.pt',\n",
    "          \"ner_model_path\": './twitter-stanza/saved_models/ner/en_tweet_nertagger.pt',\n",
    "}\n",
    "\n",
    "# Initialize the pipeline using a configuration dict\n",
    "stanza.download(\"en\")\n",
    "nlp = stanza.Pipeline(**config)\n",
    "doc = nlp(\"Oh ikr like Messi better than Ronaldo but we all like Ronaldo more\")\n",
    "print(doc) # Look at the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 TweebankNLP\n",
    "- Twpipe: https://github.com/Oneplus/twpipe (nutzt den Tweeboparser und past in Universal Dependencies)\n",
    "- der Tweeboparser: https://github.com/ikekonglp/TweeboParser\n",
    "- Tweebank V2: https://github.com/Oneplus/Tweebank\n",
    "- https://github.com/mit-ccc/TweebankNLP\n",
    "- pre-trained transformer models: the state-of-the-art Twitter NER and POS tagging models are available on Hugging Face Hub: https://huggingface.co/TweebankNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verschiedene vortrainierte Modelle:\n",
    "- TweebankNLP/bertweet-tb2_ewt-pos-tagging\n",
    "\n",
    "- TweebankNLP/bertweet-tb2-pos-tagging\n",
    "\n",
    "- TweebankNLP/bertweet-tb2-ner\n",
    "\n",
    "- TweebankNLP/bertweet-tb2_wnut17-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentiment', 'offensive', 'irony', 'hate', 'emotion', 'emoji', 'stance_abortion', 'stance_atheism', 'stance_climate', 'stance_feminist', 'stance_hillary', 'topic_classification', 'ner', 'language_model', 'sentence_embedding', 'question_answering', 'question_answer_generation']\n"
     ]
    }
   ],
   "source": [
    "# Die √§ltere Version TweebankNLP unterst√ºtzt kein POS-Tagging:\n",
    "import tweetnlp\n",
    "print(list(tweetnlp.loader.TASK_CLASS.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder@@</td>\n",
       "      <td>Reminder@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Reminder@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>The_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss Universe</td>\n",
       "      <td>Miss Universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Miss Universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>competition_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date           word          lemma    pos  \\\n",
       "0        0  2010-11-04     Reminder@@     Reminder@@   NOUN   \n",
       "1        0  2010-11-04              :              :  PUNCT   \n",
       "2        0  2010-11-04            The            The    DET   \n",
       "3        0  2010-11-04  Miss Universe  Miss Universe  PROPN   \n",
       "4        0  2010-11-04    competition    competition   NOUN   \n",
       "\n",
       "               lemma_p  \n",
       "0      Reminder@@_NOUN  \n",
       "1              :_PUNCT  \n",
       "2              The_DET  \n",
       "3  Miss Universe_PROPN  \n",
       "4     competition_NOUN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### TweebankNLP ####\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n",
    "model_name = \"TweebankNLP/bertweet-tb2_ewt-pos-tagging\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Device: CPU\n",
    "device = -1\n",
    "\n",
    "tagger = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row[\"text\"].strip()\n",
    "    \n",
    "    if text:\n",
    "        tagged = tagger(text)\n",
    "        for token_info in tagged:\n",
    "            word_text = token_info.get(\"word\")\n",
    "            pos_tag = token_info.get(\"entity_group\")\n",
    "            lemma = word_text\n",
    "            results.append({\n",
    "                \"post_id\": idx,\n",
    "                \"date\": row.get(\"date\"),\n",
    "                \"word\": word_text,\n",
    "                \"lemma\": lemma,\n",
    "                \"pos\": pos_tag,\n",
    "                \"lemma_p\": f\"{lemma}_{pos_tag}\"\n",
    "            })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"date\": row.get(\"date\"),\n",
    "            \"word\": \"\",\n",
    "            \"lemma\": \"\",\n",
    "            \"pos\": \"\",\n",
    "            \"lemma_p\": \"\"\n",
    "        })\n",
    "\n",
    "twe = pd.DataFrame(results)\n",
    "twe.to_csv(\"testkorpus_divers_50_tweebank.csv\", index=False, encoding=\"utf-8\")\n",
    "display(twe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Of</td>\n",
       "      <td>Of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Barr@@</td>\n",
       "      <td>Barr@@</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Barr@@_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>&lt;unk&gt; s</td>\n",
       "      <td>&lt;unk&gt; s</td>\n",
       "      <td>PART</td>\n",
       "      <td>&lt;unk&gt; s_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>Comments</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Comments_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>On</td>\n",
       "      <td>ADP</td>\n",
       "      <td>On_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>&lt;unk&gt;_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>Meet</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Meet_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>The_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press@@</td>\n",
       "      <td>Press@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Press@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,‚Äù_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd@@</td>\n",
       "      <td>Todd@@</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Todd@@_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT @MagaGlam@@</td>\n",
       "      <td>RT @MagaGlam@@</td>\n",
       "      <td>X</td>\n",
       "      <td>RT @MagaGlam@@_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>SYM</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>Bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>Back</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Back_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>SYM</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt;_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>The_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CBP Home</td>\n",
       "      <td>CBP Home</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CBP Home_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>AUX</td>\n",
       "      <td>is_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>now_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>available_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>ADP</td>\n",
       "      <td>across_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>mobile_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App Stores@@</td>\n",
       "      <td>App Stores@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App Stores@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Congratulations_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano Rivera</td>\n",
       "      <td>Mariano Rivera</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Mariano Rivera_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>on_SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>ADV</td>\n",
       "      <td>unanimously_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>being</td>\n",
       "      <td>being</td>\n",
       "      <td>AUX</td>\n",
       "      <td>being_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>elected</td>\n",
       "      <td>elected</td>\n",
       "      <td>VERB</td>\n",
       "      <td>elected_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>National</td>\n",
       "      <td>National</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>National_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Baseball Hall</td>\n",
       "      <td>Baseball Hall</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Baseball Hall_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Fam@@</td>\n",
       "      <td>Fam@@</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Fam@@_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>e@@</td>\n",
       "      <td>e@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>e@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date                     word                    lemma  \\\n",
       "70         4  2020-05-11                       Of                       Of   \n",
       "71         4  2020-05-11                   Barr@@                   Barr@@   \n",
       "72         4  2020-05-11                  <unk> s                  <unk> s   \n",
       "73         4  2020-05-11                 Comments                 Comments   \n",
       "74         4  2020-05-11                       On                       On   \n",
       "75         4  2020-05-11                    <unk>                    <unk>   \n",
       "76         4  2020-05-11                     Meet                     Meet   \n",
       "77         4  2020-05-11                      The                      The   \n",
       "78         4  2020-05-11                  Press@@                  Press@@   \n",
       "79         4  2020-05-11                       ,‚Äù                       ,‚Äù   \n",
       "80         4  2020-05-11                   Todd@@                   Todd@@   \n",
       "81         4  2020-05-11                        ‚Ä¶                        ‚Ä¶   \n",
       "82         5  2011-09-07           RT @MagaGlam@@           RT @MagaGlam@@   \n",
       "83         5  2011-09-07  <unk> <unk> <unk> <unk>  <unk> <unk> <unk> <unk>   \n",
       "84         5  2011-09-07                    Bring                    Bring   \n",
       "85         5  2011-09-07                     Back                     Back   \n",
       "86         5  2011-09-07                    Trump                    Trump   \n",
       "87         5  2011-09-07        <unk> <unk> <unk>        <unk> <unk> <unk>   \n",
       "88         6  2011-09-01                      NaN                      NaN   \n",
       "89         7  2025-03-19                      The                      The   \n",
       "90         7  2025-03-19                 CBP Home                 CBP Home   \n",
       "91         7  2025-03-19                      App                      App   \n",
       "92         7  2025-03-19                       is                       is   \n",
       "93         7  2025-03-19                      now                      now   \n",
       "94         7  2025-03-19                available                available   \n",
       "95         7  2025-03-19                   across                   across   \n",
       "96         7  2025-03-19                      all                      all   \n",
       "97         7  2025-03-19                   mobile                   mobile   \n",
       "98         7  2025-03-19             App Stores@@             App Stores@@   \n",
       "99         7  2025-03-19                        !                        !   \n",
       "100        8  2019-01-23          Congratulations          Congratulations   \n",
       "101        8  2019-01-23                       to                       to   \n",
       "102        8  2019-01-23           Mariano Rivera           Mariano Rivera   \n",
       "103        8  2019-01-23                       on                       on   \n",
       "104        8  2019-01-23              unanimously              unanimously   \n",
       "105        8  2019-01-23                    being                    being   \n",
       "106        8  2019-01-23                  elected                  elected   \n",
       "107        8  2019-01-23                       to                       to   \n",
       "108        8  2019-01-23                      the                      the   \n",
       "109        8  2019-01-23                 National                 National   \n",
       "110        8  2019-01-23            Baseball Hall            Baseball Hall   \n",
       "111        8  2019-01-23                       of                       of   \n",
       "112        8  2019-01-23                    Fam@@                    Fam@@   \n",
       "113        8  2019-01-23                      e@@                      e@@   \n",
       "114        8  2019-01-23                        !                        !   \n",
       "\n",
       "       pos                      lemma_p  \n",
       "70     ADP                       Of_ADP  \n",
       "71   PROPN                 Barr@@_PROPN  \n",
       "72    PART                 <unk> s_PART  \n",
       "73    NOUN                Comments_NOUN  \n",
       "74     ADP                       On_ADP  \n",
       "75   PUNCT                  <unk>_PUNCT  \n",
       "76    VERB                    Meet_VERB  \n",
       "77     DET                      The_DET  \n",
       "78    NOUN                 Press@@_NOUN  \n",
       "79   PUNCT                     ,‚Äù_PUNCT  \n",
       "80   PROPN                 Todd@@_PROPN  \n",
       "81   PUNCT                      ‚Ä¶_PUNCT  \n",
       "82       X             RT @MagaGlam@@_X  \n",
       "83     SYM  <unk> <unk> <unk> <unk>_SYM  \n",
       "84    VERB                   Bring_VERB  \n",
       "85     ADP                     Back_ADP  \n",
       "86   PROPN                  Trump_PROPN  \n",
       "87     SYM        <unk> <unk> <unk>_SYM  \n",
       "88     NaN                          NaN  \n",
       "89     DET                      The_DET  \n",
       "90   PROPN               CBP Home_PROPN  \n",
       "91    NOUN                     App_NOUN  \n",
       "92     AUX                       is_AUX  \n",
       "93     ADV                      now_ADV  \n",
       "94     ADJ                available_ADJ  \n",
       "95     ADP                   across_ADP  \n",
       "96     DET                      all_DET  \n",
       "97     ADJ                   mobile_ADJ  \n",
       "98    NOUN            App Stores@@_NOUN  \n",
       "99   PUNCT                      !_PUNCT  \n",
       "100   NOUN         Congratulations_NOUN  \n",
       "101    ADP                       to_ADP  \n",
       "102  PROPN         Mariano Rivera_PROPN  \n",
       "103  SCONJ                     on_SCONJ  \n",
       "104    ADV              unanimously_ADV  \n",
       "105    AUX                    being_AUX  \n",
       "106   VERB                 elected_VERB  \n",
       "107    ADP                       to_ADP  \n",
       "108    DET                      the_DET  \n",
       "109    ADJ                 National_ADJ  \n",
       "110  PROPN          Baseball Hall_PROPN  \n",
       "111    ADP                       of_ADP  \n",
       "112  PROPN                  Fam@@_PROPN  \n",
       "113   NOUN                     e@@_NOUN  \n",
       "114  PUNCT                      !_PUNCT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "twe = pd.read_csv(\"testkorpus_divers_50_tweebank.csv\")\n",
    "display(twe[70:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1225, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twe.shape\n",
    "# Emojis durch @ ersetzt??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder@@</td>\n",
       "      <td>Reminder@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Reminder@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss Universe</td>\n",
       "      <td>Miss Universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Miss Universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>competition_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date           word          lemma    pos  \\\n",
       "0        0  2010-11-04     Reminder@@     Reminder@@   NOUN   \n",
       "1        0  2010-11-04              :              :  PUNCT   \n",
       "2        0  2010-11-04            The            the    DET   \n",
       "3        0  2010-11-04  Miss Universe  Miss Universe  PROPN   \n",
       "4        0  2010-11-04    competition    competition   NOUN   \n",
       "\n",
       "               lemma_p  \n",
       "0      Reminder@@_NOUN  \n",
       "1              :_PUNCT  \n",
       "2              the_DET  \n",
       "3  Miss Universe_PROPN  \n",
       "4     competition_NOUN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Tweebank mit SpaCy ####\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "model_name = \"TweebankNLP/bertweet-tb2_ewt-pos-tagging\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tagger = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"text\"])\n",
    "    date = row.get(\"date\", None)\n",
    "\n",
    "    # POS-Tagging mit Tweebank\n",
    "    pos_tags = tagger(text)\n",
    "\n",
    "    # Lemmatisierung mit spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemma_map = {token.text: token.lemma_ for token in doc}\n",
    "\n",
    "    for token_info in pos_tags:\n",
    "        word_text = token_info[\"word\"]\n",
    "        pos_tag = token_info[\"entity_group\"]\n",
    "        lemma = lemma_map.get(word_text, word_text)\n",
    "\n",
    "        results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"date\": date,\n",
    "            \"word\": word_text,\n",
    "            \"lemma\": lemma,\n",
    "            \"pos\": pos_tag,\n",
    "            \"lemma_p\": f\"{lemma}_{pos_tag}\"\n",
    "        })\n",
    "\n",
    "twesp = pd.DataFrame(results)\n",
    "twesp.to_csv(\"testkorpus_divers_50_twee_spa.csv\", index=False)\n",
    "display(twesp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Barr@@</td>\n",
       "      <td>Barr@@</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Barr@@_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>&lt;unk&gt; s</td>\n",
       "      <td>&lt;unk&gt; s</td>\n",
       "      <td>PART</td>\n",
       "      <td>&lt;unk&gt; s_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>comment_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>&lt;unk&gt;_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>Meet</td>\n",
       "      <td>VERB</td>\n",
       "      <td>Meet_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>DET</td>\n",
       "      <td>The_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press@@</td>\n",
       "      <td>Press@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Press@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>,‚Äù</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,‚Äù_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd@@</td>\n",
       "      <td>Todd@@</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Todd@@_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>‚Ä¶_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT @MagaGlam@@</td>\n",
       "      <td>RT @MagaGlam@@</td>\n",
       "      <td>X</td>\n",
       "      <td>RT @MagaGlam@@_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>SYM</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt;_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADP</td>\n",
       "      <td>back_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt;</td>\n",
       "      <td>SYM</td>\n",
       "      <td>&lt;unk&gt; &lt;unk&gt; &lt;unk&gt;_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nan_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CBP Home</td>\n",
       "      <td>CBP Home</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CBP Home_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>App</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>now_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>available_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>ADP</td>\n",
       "      <td>across_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>mobile_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App Stores@@</td>\n",
       "      <td>App Stores@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>App Stores@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>congratulation_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Mariano Rivera</td>\n",
       "      <td>Mariano Rivera</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Mariano Rivera_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>on_SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>unanimously</td>\n",
       "      <td>ADV</td>\n",
       "      <td>unanimously_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>being</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>elected</td>\n",
       "      <td>elect</td>\n",
       "      <td>VERB</td>\n",
       "      <td>elect_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>to_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>National</td>\n",
       "      <td>National</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>National_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Baseball Hall</td>\n",
       "      <td>Baseball Hall</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Baseball Hall_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>of_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Fam@@</td>\n",
       "      <td>Fam@@</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Fam@@_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>e@@</td>\n",
       "      <td>e@@</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>e@@_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date                     word                    lemma  \\\n",
       "70         4  2020-05-11                       Of                       of   \n",
       "71         4  2020-05-11                   Barr@@                   Barr@@   \n",
       "72         4  2020-05-11                  <unk> s                  <unk> s   \n",
       "73         4  2020-05-11                 Comments                  comment   \n",
       "74         4  2020-05-11                       On                       on   \n",
       "75         4  2020-05-11                    <unk>                    <unk>   \n",
       "76         4  2020-05-11                     Meet                     Meet   \n",
       "77         4  2020-05-11                      The                      The   \n",
       "78         4  2020-05-11                  Press@@                  Press@@   \n",
       "79         4  2020-05-11                       ,‚Äù                       ,‚Äù   \n",
       "80         4  2020-05-11                   Todd@@                   Todd@@   \n",
       "81         4  2020-05-11                        ‚Ä¶                        ‚Ä¶   \n",
       "82         5  2011-09-07           RT @MagaGlam@@           RT @MagaGlam@@   \n",
       "83         5  2011-09-07  <unk> <unk> <unk> <unk>  <unk> <unk> <unk> <unk>   \n",
       "84         5  2011-09-07                    Bring                    bring   \n",
       "85         5  2011-09-07                     Back                     back   \n",
       "86         5  2011-09-07                    Trump                    Trump   \n",
       "87         5  2011-09-07        <unk> <unk> <unk>        <unk> <unk> <unk>   \n",
       "88         6  2011-09-01                      NaN                      NaN   \n",
       "89         7  2025-03-19                      The                      the   \n",
       "90         7  2025-03-19                 CBP Home                 CBP Home   \n",
       "91         7  2025-03-19                      App                      App   \n",
       "92         7  2025-03-19                       is                       be   \n",
       "93         7  2025-03-19                      now                      now   \n",
       "94         7  2025-03-19                available                available   \n",
       "95         7  2025-03-19                   across                   across   \n",
       "96         7  2025-03-19                      all                      all   \n",
       "97         7  2025-03-19                   mobile                   mobile   \n",
       "98         7  2025-03-19             App Stores@@             App Stores@@   \n",
       "99         7  2025-03-19                        !                        !   \n",
       "100        8  2019-01-23          Congratulations           congratulation   \n",
       "101        8  2019-01-23                       to                       to   \n",
       "102        8  2019-01-23           Mariano Rivera           Mariano Rivera   \n",
       "103        8  2019-01-23                       on                       on   \n",
       "104        8  2019-01-23              unanimously              unanimously   \n",
       "105        8  2019-01-23                    being                       be   \n",
       "106        8  2019-01-23                  elected                    elect   \n",
       "107        8  2019-01-23                       to                       to   \n",
       "108        8  2019-01-23                      the                      the   \n",
       "109        8  2019-01-23                 National                 National   \n",
       "110        8  2019-01-23            Baseball Hall            Baseball Hall   \n",
       "111        8  2019-01-23                       of                       of   \n",
       "112        8  2019-01-23                    Fam@@                    Fam@@   \n",
       "113        8  2019-01-23                      e@@                      e@@   \n",
       "114        8  2019-01-23                        !                        !   \n",
       "\n",
       "       pos                      lemma_p  \n",
       "70     ADP                       of_ADP  \n",
       "71   PROPN                 Barr@@_PROPN  \n",
       "72    PART                 <unk> s_PART  \n",
       "73    NOUN                 comment_NOUN  \n",
       "74     ADP                       on_ADP  \n",
       "75   PUNCT                  <unk>_PUNCT  \n",
       "76    VERB                    Meet_VERB  \n",
       "77     DET                      The_DET  \n",
       "78    NOUN                 Press@@_NOUN  \n",
       "79   PUNCT                     ,‚Äù_PUNCT  \n",
       "80   PROPN                 Todd@@_PROPN  \n",
       "81   PUNCT                      ‚Ä¶_PUNCT  \n",
       "82       X             RT @MagaGlam@@_X  \n",
       "83     SYM  <unk> <unk> <unk> <unk>_SYM  \n",
       "84    VERB                   bring_VERB  \n",
       "85     ADP                     back_ADP  \n",
       "86   PROPN                  Trump_PROPN  \n",
       "87     SYM        <unk> <unk> <unk>_SYM  \n",
       "88   PROPN                    nan_PROPN  \n",
       "89     DET                      the_DET  \n",
       "90   PROPN               CBP Home_PROPN  \n",
       "91    NOUN                     App_NOUN  \n",
       "92     AUX                       be_AUX  \n",
       "93     ADV                      now_ADV  \n",
       "94     ADJ                available_ADJ  \n",
       "95     ADP                   across_ADP  \n",
       "96     DET                      all_DET  \n",
       "97     ADJ                   mobile_ADJ  \n",
       "98    NOUN            App Stores@@_NOUN  \n",
       "99   PUNCT                      !_PUNCT  \n",
       "100   NOUN          congratulation_NOUN  \n",
       "101    ADP                       to_ADP  \n",
       "102  PROPN         Mariano Rivera_PROPN  \n",
       "103  SCONJ                     on_SCONJ  \n",
       "104    ADV              unanimously_ADV  \n",
       "105    AUX                       be_AUX  \n",
       "106   VERB                   elect_VERB  \n",
       "107    ADP                       to_ADP  \n",
       "108    DET                      the_DET  \n",
       "109    ADJ                 National_ADJ  \n",
       "110  PROPN          Baseball Hall_PROPN  \n",
       "111    ADP                       of_ADP  \n",
       "112  PROPN                  Fam@@_PROPN  \n",
       "113   NOUN                     e@@_NOUN  \n",
       "114  PUNCT                      !_PUNCT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "twesp = pd.read_csv(\"testkorpus_divers_50_twee_spa.csv\")\n",
    "display(twesp[70:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1225, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twesp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d90ef7a5a64c34aeb963882b5db768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 17:20:09 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-27 17:20:09 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-09-27 17:20:12 INFO: File exists: /Users/vivien/stanza_resources/en/default.zip\n",
      "2025-09-27 17:20:17 INFO: Finished downloading models and saved to /Users/vivien/stanza_resources\n",
      "2025-09-27 17:20:17 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03cb37651be4b848c34e192537805c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 17:20:17 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-27 17:20:17 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-09-27 17:20:17 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-09-27 17:20:17 INFO: Using device: cpu\n",
      "2025-09-27 17:20:17 INFO: Loading: tokenize\n",
      "2025-09-27 17:20:17 INFO: Loading: mwt\n",
      "2025-09-27 17:20:17 INFO: Loading: lemma\n",
      "2025-09-27 17:20:18 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>reminder_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Miss_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>Universe</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Universe_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date      word     lemma    pos        lemma_p\n",
       "0        0  2010-11-04  Reminder  reminder   NOUN  reminder_NOUN\n",
       "1        0  2010-11-04         :         :  PUNCT        :_PUNCT\n",
       "2        0  2010-11-04       The       the    DET        the_DET\n",
       "3        0  2010-11-04      Miss      Miss  PROPN     Miss_PROPN\n",
       "4        0  2010-11-04  Universe  Universe   NOUN  Universe_NOUN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Tweebank mit Stanza ####\n",
    "import pandas as pd\n",
    "import stanza\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "model_name = \"TweebankNLP/bertweet-tb2_ewt-pos-tagging\" \n",
    "#basiert auf einer Kombination aus EWT von UD und tweebank v2\n",
    "#das schneidet laut (Parsing Tweets into UD) besser ab als andere Kombinationen\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tagger = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "stanza.download(\"en\")\n",
    "nlp_stanza = stanza.Pipeline(\n",
    "    lang=\"en\",\n",
    "    processors=\"tokenize,lemma\",\n",
    "    tokenize_engine=\"tokenize/tweet\"  # Tweet-Tokenizer\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"text\"])\n",
    "    date = row.get(\"date\", None)\n",
    "\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    # Tokenisierung und Lemmatisierung mit Stanza\n",
    "    doc = nlp_stanza(text)\n",
    "    tokens = [(w.text, w.lemma) for s in doc.sentences for w in s.words]\n",
    "\n",
    "    words = [t[0] for t in tokens]\n",
    "    pos_tags_nested = tagger(words)\n",
    "    pos_tags = [tag[0] if isinstance(tag, list) else tag for tag in pos_tags_nested]\n",
    "\n",
    "    for token_info, (word_text, lemma) in zip(pos_tags, tokens):\n",
    "        pos_tag = token_info[\"entity_group\"]\n",
    "\n",
    "        results.append({\n",
    "            \"post_id\": idx,\n",
    "            \"date\": date,\n",
    "            \"word\": word_text,\n",
    "            \"lemma\": lemma,\n",
    "            \"pos\": pos_tag,\n",
    "            \"lemma_p\": f\"{lemma}_{pos_tag}\",\n",
    "        })\n",
    "\n",
    "twesta = pd.DataFrame(results)\n",
    "twesta.to_csv(\"testkorpus_divers_50_twee_sta.csv\", index=False, encoding=\"utf-8\")\n",
    "display(twesta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Shreds</td>\n",
       "      <td>shreds</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>shreds_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>NBC</td>\n",
       "      <td>NBC</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NBC_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>'s</td>\n",
       "      <td>PRON</td>\n",
       "      <td>'s_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>Chuck</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Chuck_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Todd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Todd_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>For</td>\n",
       "      <td>for</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>for_INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äò</td>\n",
       "      <td>'</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Deceptive</td>\n",
       "      <td>deceptive</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>deceptive_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Editing</td>\n",
       "      <td>editing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>editing_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äô</td>\n",
       "      <td>'s</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>'s_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADV</td>\n",
       "      <td>of_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Barr</td>\n",
       "      <td>barr</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>barr_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äôs</td>\n",
       "      <td>'s</td>\n",
       "      <td>PRON</td>\n",
       "      <td>'s_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Comments</td>\n",
       "      <td>comment</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>comment_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>On</td>\n",
       "      <td>on</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>on_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äú</td>\n",
       "      <td>''</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>''_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Meet</td>\n",
       "      <td>meet</td>\n",
       "      <td>VERB</td>\n",
       "      <td>meet_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Press</td>\n",
       "      <td>Press</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Press_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Äù</td>\n",
       "      <td>''</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>''_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Todd</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Todd_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>‚Ä¶</td>\n",
       "      <td>SYM</td>\n",
       "      <td>‚Ä¶_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>RT</td>\n",
       "      <td>rt</td>\n",
       "      <td>VERB</td>\n",
       "      <td>rt_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>SYM</td>\n",
       "      <td>@_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>MagaGlamüá∫üá∏‚ô•Ô∏è</td>\n",
       "      <td>magaglamüá∫üá∏‚ô•Ô∏è</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>magaglamüá∫üá∏‚ô•Ô∏è_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Bring</td>\n",
       "      <td>bring</td>\n",
       "      <td>VERB</td>\n",
       "      <td>bring_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Back</td>\n",
       "      <td>back</td>\n",
       "      <td>ADV</td>\n",
       "      <td>back_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Trump_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>üíôüá∫üá∏</td>\n",
       "      <td>SYM</td>\n",
       "      <td>üíôüá∫üá∏_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nan_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>CBP</td>\n",
       "      <td>cbp</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>cbp_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Home_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>app</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>app_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>be_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>now_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>available</td>\n",
       "      <td>available</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>available_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>across</td>\n",
       "      <td>across</td>\n",
       "      <td>ADV</td>\n",
       "      <td>across_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>all_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>mobile</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>mobile_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>App</td>\n",
       "      <td>app</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>app_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>Stores</td>\n",
       "      <td>stores</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>stores_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>congratulation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>congratulation_NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date             word           lemma    pos  \\\n",
       "70         4  2020-05-11           Shreds          shreds   NOUN   \n",
       "71         4  2020-05-11              NBC             NBC  PROPN   \n",
       "72         4  2020-05-11               ‚Äôs              's   PRON   \n",
       "73         4  2020-05-11            Chuck           Chuck  PROPN   \n",
       "74         4  2020-05-11             Todd            Todd  PROPN   \n",
       "75         4  2020-05-11              For             for   INTJ   \n",
       "76         4  2020-05-11                ‚Äò               '  PUNCT   \n",
       "77         4  2020-05-11        Deceptive       deceptive    ADJ   \n",
       "78         4  2020-05-11          Editing         editing   NOUN   \n",
       "79         4  2020-05-11                ‚Äô              's  PUNCT   \n",
       "80         4  2020-05-11               Of              of    ADV   \n",
       "81         4  2020-05-11             Barr            barr  PROPN   \n",
       "82         4  2020-05-11               ‚Äôs              's   PRON   \n",
       "83         4  2020-05-11         Comments         comment   NOUN   \n",
       "84         4  2020-05-11               On              on    ADJ   \n",
       "85         4  2020-05-11                ‚Äú              ''  PUNCT   \n",
       "86         4  2020-05-11             Meet            meet   VERB   \n",
       "87         4  2020-05-11              The             the    DET   \n",
       "88         4  2020-05-11            Press           Press   NOUN   \n",
       "89         4  2020-05-11                ,               ,  PUNCT   \n",
       "90         4  2020-05-11                ‚Äù              ''  PUNCT   \n",
       "91         4  2020-05-11             Todd            Todd  PROPN   \n",
       "92         4  2020-05-11                ‚Ä¶               ‚Ä¶    SYM   \n",
       "93         5  2011-09-07               RT              rt   VERB   \n",
       "94         5  2011-09-07                @               @    SYM   \n",
       "95         5  2011-09-07     MagaGlamüá∫üá∏‚ô•Ô∏è    magaglamüá∫üá∏‚ô•Ô∏è  PROPN   \n",
       "96         5  2011-09-07            Bring           bring   VERB   \n",
       "97         5  2011-09-07             Back            back    ADV   \n",
       "98         5  2011-09-07            Trump           Trump  PROPN   \n",
       "99         5  2011-09-07              üíôüá∫üá∏             üíôüá∫üá∏    SYM   \n",
       "100        6  2011-09-01              NaN             NaN  PROPN   \n",
       "101        7  2025-03-19              The             the    DET   \n",
       "102        7  2025-03-19              CBP             cbp  PROPN   \n",
       "103        7  2025-03-19             Home            Home   NOUN   \n",
       "104        7  2025-03-19              App             app   NOUN   \n",
       "105        7  2025-03-19               is              be   VERB   \n",
       "106        7  2025-03-19              now             now    ADV   \n",
       "107        7  2025-03-19        available       available    ADJ   \n",
       "108        7  2025-03-19           across          across    ADV   \n",
       "109        7  2025-03-19              all             all    DET   \n",
       "110        7  2025-03-19           mobile          mobile    ADJ   \n",
       "111        7  2025-03-19              App             app   NOUN   \n",
       "112        7  2025-03-19           Stores          stores   NOUN   \n",
       "113        7  2025-03-19                !               !  PUNCT   \n",
       "114        8  2019-01-23  Congratulations  congratulation   NOUN   \n",
       "\n",
       "                 lemma_p  \n",
       "70           shreds_NOUN  \n",
       "71             NBC_PROPN  \n",
       "72               's_PRON  \n",
       "73           Chuck_PROPN  \n",
       "74            Todd_PROPN  \n",
       "75              for_INTJ  \n",
       "76               '_PUNCT  \n",
       "77         deceptive_ADJ  \n",
       "78          editing_NOUN  \n",
       "79              's_PUNCT  \n",
       "80                of_ADV  \n",
       "81            barr_PROPN  \n",
       "82               's_PRON  \n",
       "83          comment_NOUN  \n",
       "84                on_ADJ  \n",
       "85              ''_PUNCT  \n",
       "86             meet_VERB  \n",
       "87               the_DET  \n",
       "88            Press_NOUN  \n",
       "89               ,_PUNCT  \n",
       "90              ''_PUNCT  \n",
       "91            Todd_PROPN  \n",
       "92                 ‚Ä¶_SYM  \n",
       "93               rt_VERB  \n",
       "94                 @_SYM  \n",
       "95    magaglamüá∫üá∏‚ô•Ô∏è_PROPN  \n",
       "96            bring_VERB  \n",
       "97              back_ADV  \n",
       "98           Trump_PROPN  \n",
       "99               üíôüá∫üá∏_SYM  \n",
       "100            nan_PROPN  \n",
       "101              the_DET  \n",
       "102            cbp_PROPN  \n",
       "103            Home_NOUN  \n",
       "104             app_NOUN  \n",
       "105              be_VERB  \n",
       "106              now_ADV  \n",
       "107        available_ADJ  \n",
       "108           across_ADV  \n",
       "109              all_DET  \n",
       "110           mobile_ADJ  \n",
       "111             app_NOUN  \n",
       "112          stores_NOUN  \n",
       "113              !_PUNCT  \n",
       "114  congratulation_NOUN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "twesta = pd.read_csv(\"testkorpus_divers_50_twee_sta.csv\")\n",
    "display(twesta[70:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twesta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit zu TweebankNLP:\n",
    "#### Tweebank:\n",
    "- viele @@ bei Segmentierung @Timc1021 wird zu @Timc@@ 1021\n",
    "- Url als X\n",
    "- Tokenisierung bei W√∂rtern mit Satzzeichen misslingt: @_KatherineWeb@@ X b: PUNCT\n",
    "- Hashtags werden ganz gelassen, PROPN oder X\n",
    "- RT @darhar981@@ als X\n",
    "- General ADJ\n",
    "- Shreds wird zu shred VERB\n",
    "- Chuck Todd als PROPN\n",
    "- <unk/> f√ºr ', \" und : unknown\n",
    "- Emojis als unknown und SYM\n",
    "- Mariano Rivera als PROPN\n",
    "- Not only ADV a DET\n",
    "- manche Url werden zerh√§kselt und als Satz analysiert (X PROPN X PROPN X NOUN VERB, ..)\n",
    "- People zu People lemmatisiert (also gar nicht)\n",
    "- May your day be filled with peace! (May als AUX)\n",
    "- jobs als NOUN\n",
    "- keine Lemmatisierung\n",
    "- Tokenisierung mit @@ bei Satzzeichen\n",
    "- anti-@@ Trump@@ getrennt (ADJ PROPN)\n",
    "- Linda Bean als PROPN\n",
    "- LL.Bean (ohne Leerzeichen als PROPN)\n",
    "- its (Rechtschreibfehler) als PRON\n",
    "- good ol' USA. wird zu good ol@@ ADJ ' PART USA. PROPN\n",
    "\n",
    "#### Tweebank mit SpaCy:\n",
    "\n",
    "- Emojis werden in <unk/> umgewandelt plus @@, Segmentieren der W√∂rter klappt nicht\n",
    "- MWEs werden erkannt, aber auch zu viel anderes wird zusammen gelassen (will be als AUX und Miss Universe als PROPN, Childhood Illnesses@@ als NOUN, RT @darhar981@@ als X, Mariano Rivera als PROPN, Not only als ADV, even more now@@ als ADV)\n",
    "- Satzzeichen '\" in unknown umgewandelt, \n",
    "- General als ADJ, Governor Phil Bryant als PROPN\n",
    "- Hashes werden beibehalten, #EnterSandman #HOF2019 mit X getaggt\n",
    "- Shreds zu shred als VERB\n",
    "- @macys bleibt @macys, @LBPerfectMaine wird getrennt\n",
    "- Hashtag #Made@@ In@@ America getrennt (VERB ADP PROPN)\n",
    "- AMERIC@@ A, PROPN PUNCT\n",
    "- election predictions.\" zu election prediction@@ NOUN s.\" PUNCT\n",
    "- joke! zu jo@@ NOUN ke! PUNCT\n",
    "- Worte falsch getrennt (v.a. bei Satzzeichen): 9pm als NUM, Thank@@ NOUN s@@ ADV, Fame! wird zu Fam@@ PROPN e@@ NOUN ! PUNCT\n",
    "- bei Tokenisierung immer @@ erg√§nzt: Vegas!\" wird zu Vegas@@ !\"\"\n",
    "- einen Zeichenfehler gut erkannt\n",
    "- Hashtag bleibt zusammen, aber mit X gelabelt \n",
    "- Emojis als unkown und SYM oder PUNCT gelabelt\n",
    "- Url bleiben meistens ganz und als X; wenn sie zerh√§kselt werden, dann werden sie als Satz analysiert (X PROPN X VERB X NOUN X ADP DET NOUN,..)\n",
    "- kein Unterschied zwischen den zwei Codes (0,1)\n",
    "- Lemma passt oft nicht (BEST@@ bleibt BEST@@, is wird aber zu be)\n",
    "\n",
    "#### Tweebank mit Stanza:\n",
    "\n",
    "- @KatherineWebb und @LBPerfectMaine als X, @macys bleibt @macys (beim lemma)\n",
    "- #AGENDA47 als X, KellyFile als X, BreitbartNews als X\n",
    "- Url im Ganzen, aber X\n",
    "- ol' als SYM?, on als X, of ADV, to als SYM, take als NOUN, jobs als PROPN\n",
    "- May (your day be filled with peace) als PROPN, from als ADP\n",
    "- RT als VERB, BEST zu good lemmatisiert, People zu person, countries zu country, stolen zu steal\n",
    "- Barr's aufgeteilt in PROPN und PRON\n",
    "- Shreds als NOUN\n",
    "- does wird zu do lemmatisiert, und n't zu not (AUX und PART)\n",
    "- Comments zu comment lemmatisiert\n",
    "- getrennte @ und Emojis als SYM\n",
    "- Addressing zu addressing lemmatisiert\n",
    "- Tokenisierung von Stanza (siehe Stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Stanza\n",
    "https://huggingface.co/stanfordnlp/stanza-en\n",
    "https://github.com/stanfordnlp/stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f879145857f9413683986371f59e10f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:57:31 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-24 11:57:31 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-09-24 11:57:34 INFO: File exists: /Users/vivien/stanza_resources/en/default.zip\n",
      "2025-09-24 11:57:39 INFO: Finished downloading models and saved to /Users/vivien/stanza_resources\n",
      "2025-09-24 11:57:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fceede1314bc4617a6b4a356b4a260d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:57:40 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-24 11:57:40 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-09-24 11:57:41 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-09-24 11:57:41 INFO: Using device: cpu\n",
      "2025-09-24 11:57:41 INFO: Loading: tokenize\n",
      "2025-09-24 11:57:41 INFO: Loading: mwt\n",
      "2025-09-24 11:57:41 INFO: Loading: pos\n",
      "2025-09-24 11:57:43 INFO: Loading: lemma\n",
      "2025-09-24 11:57:44 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Donald PROPN NNP\n",
      "Trump Trump PROPN NNP\n",
      "posted post VERB VBD\n",
      "a a DET DT\n",
      "new new ADJ JJ\n",
      "tweet tweet NOUN NN\n",
      ". . PUNCT .\n",
      "#realdonaldtrump #realdonaldtrump PROPN NNP\n",
      "@realdonaldtrump @realdonaldtrump PROPN NNP\n",
      "! ! PUNCT .\n",
      "@ben4appel @ben4appel PROPN ADD\n",
      "ü§£ ü§£ PUNCT .\n",
      ":) :) SYM NFP\n",
      "https://t.co/bsB6rVV7Yn https://t.co/bsB6rVV7Yn PROPN ADD\n",
      "# # SYM NN\n",
      "Canada Canada PROPN NNP\n"
     ]
    }
   ],
   "source": [
    "# kurzer Test\n",
    "import stanza\n",
    "\n",
    "stanza.download(\"en\") \n",
    "# wenn das Modell EWT gew√ºnscht ist, muss package=\"ewt\" erg√§nzt werden\n",
    "# default ist \"en\" seit Version 1.10.0 eine Kombination mehrerer englischer Tagsets\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\", \n",
    "    processors=\"tokenize,pos,lemma\", \n",
    "    tokenize_pretokenized=False,\n",
    "    use_gpu=False, \n",
    "    tokenize_with_spacy=False, \n",
    "    tokenize_no_ssplit=False,\n",
    "    tokenize_engine=\"tokenize/tweet\"\n",
    ")\n",
    "\n",
    "# Beispieltext\n",
    "text = \"Donald Trump posted a new tweet. #realdonaldtrump @realdonaldtrump! @ben4appel ü§£ :) https://t.co/bsB6rVV7Yn #Canada\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word.text, word.lemma, word.upos, word.xpos)\n",
    "# Hashes werden zu 50% getrennt und zu 50% ganz gelassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9724b16fcb49d2adc76f67711aa6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:57:45 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-24 11:57:45 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-09-24 11:57:47 INFO: File exists: /Users/vivien/stanza_resources/en/default.zip\n",
      "2025-09-24 11:57:51 INFO: Finished downloading models and saved to /Users/vivien/stanza_resources\n",
      "2025-09-24 11:57:51 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0072cc874734fefafa66d33e28ed68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:57:51 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-24 11:57:51 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-09-24 11:57:52 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-09-24 11:57:52 INFO: Using device: cpu\n",
      "2025-09-24 11:57:52 INFO: Loading: tokenize\n",
      "2025-09-24 11:57:52 INFO: Loading: mwt\n",
      "2025-09-24 11:57:52 INFO: Loading: pos\n",
      "2025-09-24 11:57:55 INFO: Loading: lemma\n",
      "2025-09-24 11:57:55 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>30</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>\"\"@NPHerron: @realDonaldTrump For president #2...</td>\n",
       "      <td>#</td>\n",
       "      <td>#</td>\n",
       "      <td>SYM</td>\n",
       "      <td>#_SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>30</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>\"\"@NPHerron: @realDonaldTrump For president #2...</td>\n",
       "      <td>2016election</td>\n",
       "      <td>2016election</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>2016election_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>30</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>\"\"@NPHerron: @realDonaldTrump For president #2...</td>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>30</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>\"\"@NPHerron: @realDonaldTrump For president #2...</td>\n",
       "      <td>\"</td>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>Zimmerman</td>\n",
       "      <td>Zimmerman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Zimmerman_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>trial</td>\n",
       "      <td>trial</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>trial_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "      <td>ADV</td>\n",
       "      <td>over_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>It</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>time_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>move</td>\n",
       "      <td>move</td>\n",
       "      <td>VERB</td>\n",
       "      <td>move_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>While</td>\n",
       "      <td>while</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>while_SCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>Zimmerman</td>\n",
       "      <td>Zimmerman</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Zimmerman_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>DET</td>\n",
       "      <td>no_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>angel</td>\n",
       "      <td>angel</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>angel_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>PRON</td>\n",
       "      <td>he_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>acquitted</td>\n",
       "      <td>acquitt</td>\n",
       "      <td>VERB</td>\n",
       "      <td>acquitt_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>and_CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "      <td>AUX</td>\n",
       "      <td>should_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>able</td>\n",
       "      <td>able</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>able_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>to_PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>move</td>\n",
       "      <td>move</td>\n",
       "      <td>VERB</td>\n",
       "      <td>move_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>ADP</td>\n",
       "      <td>on_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>31</td>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>The Zimmerman trial is over.  It is time to mo...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>._PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>@dbongino</td>\n",
       "      <td>@dbongino</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@dbongino_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>Polls</td>\n",
       "      <td>Polls</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Polls_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>Were</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>More</td>\n",
       "      <td>more</td>\n",
       "      <td>ADV</td>\n",
       "      <td>more_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>Wrong</td>\n",
       "      <td>wrong</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>wrong_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>NUM</td>\n",
       "      <td>2020_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>Than</td>\n",
       "      <td>then</td>\n",
       "      <td>ADV</td>\n",
       "      <td>then_ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>in_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>NUM</td>\n",
       "      <td>2016_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>üëáüëá</td>\n",
       "      <td>üëáüëá</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>üëáüëá_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>32</td>\n",
       "      <td>2020-11-07</td>\n",
       "      <td>RT @dbongino: The Polls Were More Wrong in 202...</td>\n",
       "      <td>https://t.co/LpepzKdlp1</td>\n",
       "      <td>https://t.co/LpepzKdlp1</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>https://t.co/LpepzKdlp1_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>33</td>\n",
       "      <td>2011-09-11</td>\n",
       "      <td>RT  @IStandWithTrump47November 5th can‚Äôt  come...</td>\n",
       "      <td>RT</td>\n",
       "      <td>RT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>RT_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>33</td>\n",
       "      <td>2011-09-11</td>\n",
       "      <td>RT  @IStandWithTrump47November 5th can‚Äôt  come...</td>\n",
       "      <td>@IStandWithTrump47November</td>\n",
       "      <td>@IStandWithTrump47November</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>@IStandWithTrump47November_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>33</td>\n",
       "      <td>2011-09-11</td>\n",
       "      <td>RT  @IStandWithTrump47November 5th can‚Äôt  come...</td>\n",
       "      <td>5th</td>\n",
       "      <td>5th</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>5th_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>33</td>\n",
       "      <td>2011-09-11</td>\n",
       "      <td>RT  @IStandWithTrump47November 5th can‚Äôt  come...</td>\n",
       "      <td>can‚Äôt</td>\n",
       "      <td>can</td>\n",
       "      <td>AUX</td>\n",
       "      <td>can_AUX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date                                               text  \\\n",
       "612       30  2014-09-01  \"\"@NPHerron: @realDonaldTrump For president #2...   \n",
       "613       30  2014-09-01  \"\"@NPHerron: @realDonaldTrump For president #2...   \n",
       "614       30  2014-09-01  \"\"@NPHerron: @realDonaldTrump For president #2...   \n",
       "615       30  2014-09-01  \"\"@NPHerron: @realDonaldTrump For president #2...   \n",
       "616       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "617       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "618       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "619       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "620       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "621       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "622       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "623       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "624       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "625       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "626       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "627       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "628       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "629       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "630       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "631       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "632       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "633       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "634       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "635       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "636       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "637       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "638       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "639       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "640       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "641       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "642       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "643       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "644       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "645       31  2013-07-17  The Zimmerman trial is over.  It is time to mo...   \n",
       "646       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "647       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "648       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "649       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "650       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "651       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "652       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "653       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "654       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "655       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "656       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "657       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "658       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "659       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "660       32  2020-11-07  RT @dbongino: The Polls Were More Wrong in 202...   \n",
       "661       33  2011-09-11  RT  @IStandWithTrump47November 5th can‚Äôt  come...   \n",
       "662       33  2011-09-11  RT  @IStandWithTrump47November 5th can‚Äôt  come...   \n",
       "663       33  2011-09-11  RT  @IStandWithTrump47November 5th can‚Äôt  come...   \n",
       "664       33  2011-09-11  RT  @IStandWithTrump47November 5th can‚Äôt  come...   \n",
       "\n",
       "                           word                       lemma    pos  \\\n",
       "612                           #                           #    SYM   \n",
       "613                2016election                2016election  PROPN   \n",
       "614                           \"                           \"  PUNCT   \n",
       "615                           \"                           \"  PUNCT   \n",
       "616                         The                         the    DET   \n",
       "617                   Zimmerman                   Zimmerman  PROPN   \n",
       "618                       trial                       trial   NOUN   \n",
       "619                          is                          be    AUX   \n",
       "620                        over                        over    ADV   \n",
       "621                           .                           .  PUNCT   \n",
       "622                          It                          it   PRON   \n",
       "623                          is                          be    AUX   \n",
       "624                        time                        time   NOUN   \n",
       "625                          to                          to   PART   \n",
       "626                        move                        move   VERB   \n",
       "627                          on                          on    ADP   \n",
       "628                           .                           .  PUNCT   \n",
       "629                       While                       while  SCONJ   \n",
       "630                   Zimmerman                   Zimmerman  PROPN   \n",
       "631                          is                          be    AUX   \n",
       "632                          no                          no    DET   \n",
       "633                       angel                       angel   NOUN   \n",
       "634                           ,                           ,  PUNCT   \n",
       "635                          he                          he   PRON   \n",
       "636                         was                          be    AUX   \n",
       "637                   acquitted                     acquitt   VERB   \n",
       "638                         and                         and  CCONJ   \n",
       "639                      should                      should    AUX   \n",
       "640                          be                          be    AUX   \n",
       "641                        able                        able    ADJ   \n",
       "642                          to                          to   PART   \n",
       "643                        move                        move   VERB   \n",
       "644                          on                          on    ADP   \n",
       "645                           .                           .  PUNCT   \n",
       "646                          RT                          RT  PROPN   \n",
       "647                   @dbongino                   @dbongino  PROPN   \n",
       "648                           :                           :  PUNCT   \n",
       "649                         The                         the    DET   \n",
       "650                       Polls                       Polls  PROPN   \n",
       "651                        Were                          be    AUX   \n",
       "652                        More                        more    ADV   \n",
       "653                       Wrong                       wrong    ADJ   \n",
       "654                          in                          in    ADP   \n",
       "655                        2020                        2020    NUM   \n",
       "656                        Than                        then    ADV   \n",
       "657                          in                          in    ADP   \n",
       "658                        2016                        2016    NUM   \n",
       "659                          üëáüëá                          üëáüëá  PUNCT   \n",
       "660     https://t.co/LpepzKdlp1     https://t.co/LpepzKdlp1  PROPN   \n",
       "661                          RT                          RT  PROPN   \n",
       "662  @IStandWithTrump47November  @IStandWithTrump47November  PROPN   \n",
       "663                         5th                         5th   NOUN   \n",
       "664                       can‚Äôt                         can    AUX   \n",
       "\n",
       "                              lemma_p  \n",
       "612                             #_SYM  \n",
       "613                2016election_PROPN  \n",
       "614                           \"_PUNCT  \n",
       "615                           \"_PUNCT  \n",
       "616                           the_DET  \n",
       "617                   Zimmerman_PROPN  \n",
       "618                        trial_NOUN  \n",
       "619                            be_AUX  \n",
       "620                          over_ADV  \n",
       "621                           ._PUNCT  \n",
       "622                           it_PRON  \n",
       "623                            be_AUX  \n",
       "624                         time_NOUN  \n",
       "625                           to_PART  \n",
       "626                         move_VERB  \n",
       "627                            on_ADP  \n",
       "628                           ._PUNCT  \n",
       "629                       while_SCONJ  \n",
       "630                   Zimmerman_PROPN  \n",
       "631                            be_AUX  \n",
       "632                            no_DET  \n",
       "633                        angel_NOUN  \n",
       "634                           ,_PUNCT  \n",
       "635                           he_PRON  \n",
       "636                            be_AUX  \n",
       "637                      acquitt_VERB  \n",
       "638                         and_CCONJ  \n",
       "639                        should_AUX  \n",
       "640                            be_AUX  \n",
       "641                          able_ADJ  \n",
       "642                           to_PART  \n",
       "643                         move_VERB  \n",
       "644                            on_ADP  \n",
       "645                           ._PUNCT  \n",
       "646                          RT_PROPN  \n",
       "647                   @dbongino_PROPN  \n",
       "648                           :_PUNCT  \n",
       "649                           the_DET  \n",
       "650                       Polls_PROPN  \n",
       "651                            be_AUX  \n",
       "652                          more_ADV  \n",
       "653                         wrong_ADJ  \n",
       "654                            in_ADP  \n",
       "655                          2020_NUM  \n",
       "656                          then_ADV  \n",
       "657                            in_ADP  \n",
       "658                          2016_NUM  \n",
       "659                          üëáüëá_PUNCT  \n",
       "660     https://t.co/LpepzKdlp1_PROPN  \n",
       "661                          RT_PROPN  \n",
       "662  @IStandWithTrump47November_PROPN  \n",
       "663                          5th_NOUN  \n",
       "664                           can_AUX  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### das englische Modell f√ºr Stanza #### basierend auf UD\n",
    "import pandas as pd\n",
    "import stanza\n",
    "stanza.download('en')  \n",
    "nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma', use_gpu=False)\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    if pd.isna(text):\n",
    "        continue\n",
    "    doc = nlp(str(text))\n",
    "    for sentence in doc.sentences:\n",
    "        for token in sentence.tokens:\n",
    "            word = token.text\n",
    "            word_info = token.words[0]\n",
    "            lemma = word_info.lemma\n",
    "            pos = word_info.upos\n",
    "            lemma_p = f\"{lemma}_{pos}\"\n",
    "            \n",
    "            all_results.append({\n",
    "                \"post_id\": idx + 1,\n",
    "                \"date\": row[\"date\"],\n",
    "                \"text\": text,\n",
    "                \"word\": word,\n",
    "                \"lemma\": lemma,\n",
    "                \"pos\": pos,\n",
    "                \"lemma_p\": lemma_p\n",
    "            })\n",
    "\n",
    "sta = pd.DataFrame(all_results)\n",
    "sta.to_csv(\"testkorpus_divers_50_stanza.csv\", index=False, encoding=\"utf-8\")\n",
    "display(sta[612:665])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>BEST</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>good_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>USA_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>üá∫_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>üá∏_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>ICYMI- This week we hosted a #MadeInAmerica ev...</td>\n",
       "      <td>https://t.co/q4vB9GdE5y</td>\n",
       "      <td>https://t.co/q4vB9GdE5y</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>https://t.co/q4vB9GdE5y_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank you Governor Phil Bryant - it was my gre...</td>\n",
       "      <td>Thank</td>\n",
       "      <td>thank</td>\n",
       "      <td>VERB</td>\n",
       "      <td>thank_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank you Governor Phil Bryant - it was my gre...</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>PRON</td>\n",
       "      <td>you_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank you Governor Phil Bryant - it was my gre...</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Governor</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Governor_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank you Governor Phil Bryant - it was my gre...</td>\n",
       "      <td>Phil</td>\n",
       "      <td>Phil</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Phil_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank you Governor Phil Bryant - it was my gre...</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>Bryant</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Bryant_PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date                                               text  \\\n",
       "200       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "201       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "202       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "203       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "204       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "205       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "206       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "207       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "208       11  2017-07-21  ICYMI- This week we hosted a #MadeInAmerica ev...   \n",
       "209       12  2011-08-31  https://www.mediaite.com/tv/trump-team-scored-...   \n",
       "210       13  2018-10-03  Thank you Governor Phil Bryant - it was my gre...   \n",
       "211       13  2018-10-03  Thank you Governor Phil Bryant - it was my gre...   \n",
       "212       13  2018-10-03  Thank you Governor Phil Bryant - it was my gre...   \n",
       "213       13  2018-10-03  Thank you Governor Phil Bryant - it was my gre...   \n",
       "214       13  2018-10-03  Thank you Governor Phil Bryant - it was my gre...   \n",
       "\n",
       "                                                  word  \\\n",
       "200                                                 it   \n",
       "201                                                 is   \n",
       "202                                                the   \n",
       "203                                               BEST   \n",
       "204                                                  !   \n",
       "205                                                USA   \n",
       "206                                                  üá∫   \n",
       "207                                                  üá∏   \n",
       "208                            https://t.co/q4vB9GdE5y   \n",
       "209  https://www.mediaite.com/tv/trump-team-scored-...   \n",
       "210                                              Thank   \n",
       "211                                                you   \n",
       "212                                           Governor   \n",
       "213                                               Phil   \n",
       "214                                             Bryant   \n",
       "\n",
       "                                                 lemma    pos  \\\n",
       "200                                                 it   PRON   \n",
       "201                                                 be    AUX   \n",
       "202                                                the    DET   \n",
       "203                                               good    ADJ   \n",
       "204                                                  !  PUNCT   \n",
       "205                                                USA  PROPN   \n",
       "206                                                  üá∫  PUNCT   \n",
       "207                                                  üá∏  PUNCT   \n",
       "208                            https://t.co/q4vB9GdE5y  PROPN   \n",
       "209  https://www.mediaite.com/tv/trump-team-scored-...  PROPN   \n",
       "210                                              thank   VERB   \n",
       "211                                                you   PRON   \n",
       "212                                           Governor  PROPN   \n",
       "213                                               Phil  PROPN   \n",
       "214                                             Bryant  PROPN   \n",
       "\n",
       "                                               lemma_p  \n",
       "200                                            it_PRON  \n",
       "201                                             be_AUX  \n",
       "202                                            the_DET  \n",
       "203                                           good_ADJ  \n",
       "204                                            !_PUNCT  \n",
       "205                                          USA_PROPN  \n",
       "206                                            üá∫_PUNCT  \n",
       "207                                            üá∏_PUNCT  \n",
       "208                      https://t.co/q4vB9GdE5y_PROPN  \n",
       "209  https://www.mediaite.com/tv/trump-team-scored-...  \n",
       "210                                         thank_VERB  \n",
       "211                                           you_PRON  \n",
       "212                                     Governor_PROPN  \n",
       "213                                         Phil_PROPN  \n",
       "214                                       Bryant_PROPN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sta = pd.read_csv(\"testkorpus_divers_50_stanza.csv\")\n",
    "display(sta[200:215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1190, 7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb95482ca8441d8a06a922ed9851da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:59:52 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-24 11:59:52 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-09-24 11:59:55 INFO: File exists: /Users/vivien/stanza_resources/en/default.zip\n",
      "2025-09-24 11:59:59 INFO: Finished downloading models and saved to /Users/vivien/stanza_resources\n",
      "2025-09-24 11:59:59 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad6f3c4f74d42b6a2e3bd5103b7e4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:59:59 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-24 11:59:59 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-09-24 12:00:00 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-09-24 12:00:00 INFO: Using device: cpu\n",
      "2025-09-24 12:00:00 INFO: Loading: tokenize\n",
      "2025-09-24 12:00:00 INFO: Loading: mwt\n",
      "2025-09-24 12:00:00 INFO: Loading: pos\n",
      "2025-09-24 12:00:03 INFO: Loading: lemma\n",
      "2025-09-24 12:00:05 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>reminder_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Miss_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>Universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>competition_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>MD</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VB</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>live_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>from_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Bahamas_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>tonight_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>@_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>9_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>pm</td>\n",
       "      <td>p.m.</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>p.m._NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-LRB-</td>\n",
       "      <td>(_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>EST</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>EST_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>)_PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word        lemma    pos   xpos  \\\n",
       "0         1  2010-11-04     Reminder     reminder   NOUN     NN   \n",
       "1         1  2010-11-04            :            :  PUNCT      :   \n",
       "2         1  2010-11-04          The          the    DET     DT   \n",
       "3         1  2010-11-04         Miss         Miss  PROPN    NNP   \n",
       "4         1  2010-11-04     Universe     Universe  PROPN    NNP   \n",
       "5         1  2010-11-04  competition  competition   NOUN     NN   \n",
       "6         1  2010-11-04         will         will    AUX     MD   \n",
       "7         1  2010-11-04           be           be    AUX     VB   \n",
       "8         1  2010-11-04         LIVE         live    ADJ     JJ   \n",
       "9         1  2010-11-04         from         from    ADP     IN   \n",
       "10        1  2010-11-04          the          the    DET     DT   \n",
       "11        1  2010-11-04      Bahamas      Bahamas  PROPN    NNP   \n",
       "12        1  2010-11-04            -            -  PUNCT      ,   \n",
       "13        1  2010-11-04      Tonight      tonight   NOUN     NN   \n",
       "14        1  2010-11-04            @            @    ADP     IN   \n",
       "15        1  2010-11-04            9            9    NUM     CD   \n",
       "16        1  2010-11-04           pm         p.m.   NOUN     NN   \n",
       "17        1  2010-11-04            (            (  PUNCT  -LRB-   \n",
       "18        1  2010-11-04          EST          EST  PROPN    NNP   \n",
       "19        1  2010-11-04            )            )  PUNCT  -RRB-   \n",
       "\n",
       "             lemma_p  \n",
       "0      reminder_NOUN  \n",
       "1            :_PUNCT  \n",
       "2            the_DET  \n",
       "3         Miss_PROPN  \n",
       "4     Universe_PROPN  \n",
       "5   competition_NOUN  \n",
       "6           will_AUX  \n",
       "7             be_AUX  \n",
       "8           live_ADJ  \n",
       "9           from_ADP  \n",
       "10           the_DET  \n",
       "11     Bahamas_PROPN  \n",
       "12           -_PUNCT  \n",
       "13      tonight_NOUN  \n",
       "14             @_ADP  \n",
       "15             9_NUM  \n",
       "16         p.m._NOUN  \n",
       "17           (_PUNCT  \n",
       "18         EST_PROPN  \n",
       "19           )_PUNCT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## mit Twitter-Tokenizer\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import emoji\n",
    "\n",
    "stanza.download(\"en\")\n",
    "\n",
    "# Stanza-Pipeline mit Tweet-Tokenizer\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\",\n",
    "    processors=\"tokenize,pos,lemma\", #mwt\n",
    "    tokenize_pretokenized=False,\n",
    "    use_gpu=False,\n",
    "    tokenize_with_spacy=False,\n",
    "    tokenize_no_ssplit=False,\n",
    "    tokenize_engine=\"tokenize/tweet\" # Tweebank v2 im Stanza Tokenizer von TweebankNLP\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row.get(\"text\")\n",
    "    if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            lemma_p = f\"{word.lemma}_{word.upos}\"\n",
    "            all_results.append({\n",
    "                \"post_id\": idx + 1,\n",
    "                \"date\": row.get(\"date\"),\n",
    "                \"word\": word.text,\n",
    "                \"lemma\": word.lemma,\n",
    "                \"pos\": word.upos,   \n",
    "                \"xpos\": word.xpos,\n",
    "                \"lemma_p\": lemma_p,\n",
    "            })\n",
    "\n",
    "statw = pd.DataFrame(all_results)\n",
    "output_file = \"testkorpus_divers_50_stanza_tweets.csv\"\n",
    "statw.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "display(statw.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>MADE</td>\n",
       "      <td>made</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>made_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>in_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>AMERICA</td>\n",
       "      <td>America</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>America_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>BEST</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJS</td>\n",
       "      <td>good_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>USA_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>üá∫_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>üá∏_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>https://t.co/q4vB9GdE5y</td>\n",
       "      <td>https://t.co/q4vB9GdE5y</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADD</td>\n",
       "      <td>https://t.co/q4vB9GdE5y_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>12</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADD</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank</td>\n",
       "      <td>thank</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>thank_VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date                                               word  \\\n",
       "200       11  2017-07-21                                               MADE   \n",
       "201       11  2017-07-21                                                 IN   \n",
       "202       11  2017-07-21                                            AMERICA   \n",
       "203       11  2017-07-21                                                  ,   \n",
       "204       11  2017-07-21                                                 it   \n",
       "205       11  2017-07-21                                                 is   \n",
       "206       11  2017-07-21                                                the   \n",
       "207       11  2017-07-21                                               BEST   \n",
       "208       11  2017-07-21                                                  !   \n",
       "209       11  2017-07-21                                                USA   \n",
       "210       11  2017-07-21                                                  üá∫   \n",
       "211       11  2017-07-21                                                  üá∏   \n",
       "212       11  2017-07-21                            https://t.co/q4vB9GdE5y   \n",
       "213       12  2011-08-31  https://www.mediaite.com/tv/trump-team-scored-...   \n",
       "214       13  2018-10-03                                              Thank   \n",
       "\n",
       "                                                 lemma    pos xpos  \\\n",
       "200                                               made   VERB  VBN   \n",
       "201                                                 in    ADP   IN   \n",
       "202                                            America  PROPN  NNP   \n",
       "203                                                  ,  PUNCT    ,   \n",
       "204                                                 it   PRON  PRP   \n",
       "205                                                 be    AUX  VBZ   \n",
       "206                                                the    DET   DT   \n",
       "207                                               good    ADJ  JJS   \n",
       "208                                                  !  PUNCT    .   \n",
       "209                                                USA  PROPN  NNP   \n",
       "210                                                  üá∫  PUNCT    ,   \n",
       "211                                                  üá∏  PUNCT    .   \n",
       "212                            https://t.co/q4vB9GdE5y  PROPN  ADD   \n",
       "213  https://www.mediaite.com/tv/trump-team-scored-...  PROPN  ADD   \n",
       "214                                              thank   VERB  VBP   \n",
       "\n",
       "                                               lemma_p  \n",
       "200                                          made_VERB  \n",
       "201                                             in_ADP  \n",
       "202                                      America_PROPN  \n",
       "203                                            ,_PUNCT  \n",
       "204                                            it_PRON  \n",
       "205                                             be_AUX  \n",
       "206                                            the_DET  \n",
       "207                                           good_ADJ  \n",
       "208                                            !_PUNCT  \n",
       "209                                          USA_PROPN  \n",
       "210                                            üá∫_PUNCT  \n",
       "211                                            üá∏_PUNCT  \n",
       "212                      https://t.co/q4vB9GdE5y_PROPN  \n",
       "213  https://www.mediaite.com/tv/trump-team-scored-...  \n",
       "214                                         thank_VERB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "statw = pd.read_csv(\"testkorpus_divers_50_stanza_tweets.csv\")\n",
    "display(statw[200:215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1207, 7)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statw.shape\n",
    "# taggt sehr gut, allerdings wird nicht jedes Emoji richtig als NFP erkannt, \n",
    "# sondern oft nur als Satzzeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ac0afb3a504d068c7b6079dfccfdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 17:29:35 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-27 17:29:35 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-09-27 17:29:38 INFO: File exists: /Users/vivien/stanza_resources/en/default.zip\n",
      "2025-09-27 17:29:43 INFO: Finished downloading models and saved to /Users/vivien/stanza_resources\n",
      "2025-09-27 17:29:43 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0be40037c9443b3b2b20c4adc1ec536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 17:29:43 INFO: Downloaded file to /Users/vivien/stanza_resources/resources.json\n",
      "2025-09-27 17:29:43 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-09-27 17:29:44 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-09-27 17:29:44 INFO: Using device: cpu\n",
      "2025-09-27 17:29:44 INFO: Loading: tokenize\n",
      "2025-09-27 17:29:44 INFO: Loading: mwt\n",
      "2025-09-27 17:29:44 INFO: Loading: pos\n",
      "2025-09-27 17:29:47 INFO: Loading: lemma\n",
      "2025-09-27 17:29:48 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>reminder</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>reminder_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>:_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Miss_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Universe</td>\n",
       "      <td>Universe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Universe_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>competition</td>\n",
       "      <td>competition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>competition_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>AUX</td>\n",
       "      <td>MD</td>\n",
       "      <td>will_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VB</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>live</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>live_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>from_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Bahamas_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>-_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>Tonight</td>\n",
       "      <td>tonight</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>tonight_NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>@</td>\n",
       "      <td>@</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>@_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>9_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>pm</td>\n",
       "      <td>p.m.</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>p.m._NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-LRB-</td>\n",
       "      <td>(_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>EST</td>\n",
       "      <td>EST</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>EST_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-04</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>-RRB-</td>\n",
       "      <td>)_PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id        date         word        lemma    pos   xpos  \\\n",
       "0         1  2010-11-04     Reminder     reminder   NOUN     NN   \n",
       "1         1  2010-11-04            :            :  PUNCT      :   \n",
       "2         1  2010-11-04          The          the    DET     DT   \n",
       "3         1  2010-11-04         Miss         Miss  PROPN    NNP   \n",
       "4         1  2010-11-04     Universe     Universe  PROPN    NNP   \n",
       "5         1  2010-11-04  competition  competition   NOUN     NN   \n",
       "6         1  2010-11-04         will         will    AUX     MD   \n",
       "7         1  2010-11-04           be           be    AUX     VB   \n",
       "8         1  2010-11-04         LIVE         live    ADJ     JJ   \n",
       "9         1  2010-11-04         from         from    ADP     IN   \n",
       "10        1  2010-11-04          the          the    DET     DT   \n",
       "11        1  2010-11-04      Bahamas      Bahamas  PROPN    NNP   \n",
       "12        1  2010-11-04            -            -  PUNCT      ,   \n",
       "13        1  2010-11-04      Tonight      tonight   NOUN     NN   \n",
       "14        1  2010-11-04            @            @    ADP     IN   \n",
       "15        1  2010-11-04            9            9    NUM     CD   \n",
       "16        1  2010-11-04           pm         p.m.   NOUN     NN   \n",
       "17        1  2010-11-04            (            (  PUNCT  -LRB-   \n",
       "18        1  2010-11-04          EST          EST  PROPN    NNP   \n",
       "19        1  2010-11-04            )            )  PUNCT  -RRB-   \n",
       "\n",
       "             lemma_p  \n",
       "0      reminder_NOUN  \n",
       "1            :_PUNCT  \n",
       "2            the_DET  \n",
       "3         Miss_PROPN  \n",
       "4     Universe_PROPN  \n",
       "5   competition_NOUN  \n",
       "6           will_AUX  \n",
       "7             be_AUX  \n",
       "8           live_ADJ  \n",
       "9           from_ADP  \n",
       "10           the_DET  \n",
       "11     Bahamas_PROPN  \n",
       "12           -_PUNCT  \n",
       "13      tonight_NOUN  \n",
       "14             @_ADP  \n",
       "15             9_NUM  \n",
       "16         p.m._NOUN  \n",
       "17           (_PUNCT  \n",
       "18         EST_PROPN  \n",
       "19           )_PUNCT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stanza + Tweet-Tokenizer + Emojivariante\n",
    "import pandas as pd\n",
    "import stanza\n",
    "import re\n",
    "\n",
    "stanza.download(\"en\")\n",
    "\n",
    "# Stanza-Pipeline mit Tweet-Tokenizer\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    tokenize_pretokenized=False,\n",
    "    use_gpu=False,\n",
    "    tokenize_with_spacy=False,\n",
    "    tokenize_no_ssplit=False,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    tokenize_engine=\"tokenize/tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Unicode-Emoji-Regex\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # Symbole & Piktogramme\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # Transport & Symbole\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # Flaggen\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# klassische Smileys\n",
    "smiley_pattern = re.compile(r'[:;=8][\\-~]?[)D]', flags=re.UNICODE)\n",
    "\n",
    "def is_emoji_or_smiley(token):\n",
    "    return bool(emoji_pattern.fullmatch(token)) or bool(smiley_pattern.fullmatch(token))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "all_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row.get(\"text\")\n",
    "    if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            xpos = word.xpos\n",
    "            if is_emoji_or_smiley(word.text):\n",
    "                xpos = \"NFP\"\n",
    "\n",
    "            lemma_p = f\"{word.lemma}_{word.upos}\"\n",
    "            all_results.append({\n",
    "                \"post_id\": idx + 1,\n",
    "                \"date\": row.get(\"date\"),\n",
    "                \"word\": word.text,\n",
    "                \"lemma\": word.lemma,\n",
    "                \"pos\": word.upos,   \n",
    "                \"xpos\": xpos,\n",
    "                \"lemma_p\": lemma_p,\n",
    "            })\n",
    "\n",
    "statw2 = pd.DataFrame(all_results)\n",
    "output_file = \"testkorpus_divers_50_stanza_tweets2.csv\"\n",
    "statw2.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "display(statw2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>lemma_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>MADE</td>\n",
       "      <td>made</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>made_VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>in_ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>AMERICA</td>\n",
       "      <td>America</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>America_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>,_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>it_PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>be_AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>the_DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>BEST</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJS</td>\n",
       "      <td>good_ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>!_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>USA_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>üá∫</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NFP</td>\n",
       "      <td>üá∫_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>üá∏</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NFP</td>\n",
       "      <td>üá∏_PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>11</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>https://t.co/q4vB9GdE5y</td>\n",
       "      <td>https://t.co/q4vB9GdE5y</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADD</td>\n",
       "      <td>https://t.co/q4vB9GdE5y_PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>12</td>\n",
       "      <td>2011-08-31</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADD</td>\n",
       "      <td>https://www.mediaite.com/tv/trump-team-scored-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>Thank</td>\n",
       "      <td>thank</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>thank_VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id        date                                               word  \\\n",
       "200       11  2017-07-21                                               MADE   \n",
       "201       11  2017-07-21                                                 IN   \n",
       "202       11  2017-07-21                                            AMERICA   \n",
       "203       11  2017-07-21                                                  ,   \n",
       "204       11  2017-07-21                                                 it   \n",
       "205       11  2017-07-21                                                 is   \n",
       "206       11  2017-07-21                                                the   \n",
       "207       11  2017-07-21                                               BEST   \n",
       "208       11  2017-07-21                                                  !   \n",
       "209       11  2017-07-21                                                USA   \n",
       "210       11  2017-07-21                                                  üá∫   \n",
       "211       11  2017-07-21                                                  üá∏   \n",
       "212       11  2017-07-21                            https://t.co/q4vB9GdE5y   \n",
       "213       12  2011-08-31  https://www.mediaite.com/tv/trump-team-scored-...   \n",
       "214       13  2018-10-03                                              Thank   \n",
       "\n",
       "                                                 lemma    pos xpos  \\\n",
       "200                                               made   VERB  VBN   \n",
       "201                                                 in    ADP   IN   \n",
       "202                                            America  PROPN  NNP   \n",
       "203                                                  ,  PUNCT    ,   \n",
       "204                                                 it   PRON  PRP   \n",
       "205                                                 be    AUX  VBZ   \n",
       "206                                                the    DET   DT   \n",
       "207                                               good    ADJ  JJS   \n",
       "208                                                  !  PUNCT    .   \n",
       "209                                                USA  PROPN  NNP   \n",
       "210                                                  üá∫  PUNCT  NFP   \n",
       "211                                                  üá∏  PUNCT  NFP   \n",
       "212                            https://t.co/q4vB9GdE5y  PROPN  ADD   \n",
       "213  https://www.mediaite.com/tv/trump-team-scored-...  PROPN  ADD   \n",
       "214                                              thank   VERB  VBP   \n",
       "\n",
       "                                               lemma_p  \n",
       "200                                          made_VERB  \n",
       "201                                             in_ADP  \n",
       "202                                      America_PROPN  \n",
       "203                                            ,_PUNCT  \n",
       "204                                            it_PRON  \n",
       "205                                             be_AUX  \n",
       "206                                            the_DET  \n",
       "207                                           good_ADJ  \n",
       "208                                            !_PUNCT  \n",
       "209                                          USA_PROPN  \n",
       "210                                            üá∫_PUNCT  \n",
       "211                                            üá∏_PUNCT  \n",
       "212                      https://t.co/q4vB9GdE5y_PROPN  \n",
       "213  https://www.mediaite.com/tv/trump-team-scored-...  \n",
       "214                                         thank_VERB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "statw2 = pd.read_csv(\"testkorpus_divers_50_stanza_tweets2.csv\")\n",
    "display(statw2[200:215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1207, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statw2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazit zu Stanza:\n",
    "#### Stanza:\n",
    "- weniger Tags als alle anderen Modelle\n",
    "- @ werden meistens gut erkannt (und so belassen wie sie waren): @_KatherineWebb, @Timc1021 wird in @ als PUNCT und Timc1021 als PROPN getrennt, @darhar981, @ MagaGlam\"Emojis\", @macys wird zu @macy lemmatisiert, @WhiteHouse\n",
    "- Emojis werden als Punkt erkannt\n",
    "- Hashes werden oft getrennt # MissUSA, #AGENDA47, # MAGA, # MadeInAmerica\n",
    "- Url als Eigenname, aber werden immer ganz gelassen\n",
    "- richtige Lemmatisierung (Looking wird mit lemma look kategorisiert), pm wird zu p.m., IS wird zu be, BEST zu good\n",
    "- meistens richtiges Tagging\n",
    "- Barr's wird zu Barr als PROPN - Tweebank trennt in Barr 's auf\n",
    "- Shreds (falsch als PROPN) und its (a loser) (Rechtschreibfehler) falsch erkannt, ol' als Noun (eigentl. old, Tweebank hatte ol' als ADJ), Illnesses falsch als PROPN und bleiibt Illnesses (falsch lemmatisiert)\n",
    "- doesn't wird zu do (lemma)\n",
    "- is (He is a joke) als AUX, dabei ist es hier VERB\n",
    "- anti-Trump wird zu anti- ADP und Trump PROPN\n",
    "- We're zu we (und kein are)\n",
    "\n",
    "#### mit Tweet-Tokenizer: \n",
    "\n",
    "- am besten xpos verwenden, da diese Tweet-spezifische Tags beinhalten\n",
    "- xpos vergibt allerdings bei # MAGA (wenn falsch tokenisiert wurde) (NN, NNP)\n",
    "- Hashes und @ werden gut erkannt und entsprechend getaggt\n",
    "- @ und Hashes wie oben\n",
    "- aber @LBPerfectMaine als ADD bei xpos? die anderen @ alle als NNP\n",
    "- Trennung in did n't \n",
    "- Url werden bei xpos mit ADD getagt, bei pos (also nicht tweetspezifisch) mit PROPN, sie werden auch ganz gelassen\n",
    "- Emojis werden meist als Satzzeichen getaggt und nur selten als NFP\n",
    "- Barr's wird aufgeteilt in Barr und 's\n",
    "- Hashes und @ werden allerdings auch genau so oft getrennt, wie sie zusammen gelassen werden\n",
    "- May (your day be filled with peace) als AUX\n",
    "- zwei neue Tags f√ºr Tweets: ADD und NFP\n",
    "- her bleibt auch als lemma her (statt she)\n",
    "- anti-Trump PROPN und (einen Satz sp√§ter) anti- ADP Trump PROPN\n",
    "- We're zu we PRON be AUX\n",
    "- BEST wird zu good lemmatisiert, better zu good, People zu person\n",
    "- ol' bleibt ol' NOUN\n",
    "- Twisting zu twist VERB political ADJ arms zu arm NOUN ? PUNCT\n",
    "- JOBS NOUN\n",
    "- 1st ADJ Amendment NOUN\n",
    "\n",
    "#### Tweet Tokenizer mit Emojis:\n",
    "\n",
    "- Emojis werden besser erkannt als NFP\n",
    "- der Rest ist identisch mit dem ersten Tweet-Tokenizer Modell\n",
    "- more bleibt more, aber getting wird get, better wird good, stolen zu steal, were zu be, BEST zu good\n",
    "- 1st ADJ Amendment NOUN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "XPOS\tBeschreibung\tBeispiele / Typische Tokens\n",
    "NNP\tProper Noun, Singular\tDonald, Canada, #Canada\n",
    "NN\tNoun, Singular\t# (Hashtag-Symbol)\n",
    "ADD\tAddresse / Mention / URL\t@ben4appel, @realdonaldtrump, https://t.co/...\n",
    "NFP\tNon-final punctuation / Emoticons\t:) , ü§£\n",
    "DT\tDeterminer\ta, the\n",
    "JJ\tAdjective\tnew, happy\n",
    "VB\tVerb, base form\tpost, like\n",
    "VBD\tVerb, past tense\tposted\n",
    "PUNCT\tSatzzeichen\t., !, ?\n",
    "SYM\tSymbol\t#, $, %, &\n",
    "PRP$\tPossessive pronoun\tmy, your\n",
    "RB\tAdverb\tquickly, now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finale Entscheidung und Tagging der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich entscheide mich f√ºr... STANZA mit Tweet-Tokenizer (basiert auf Tweebank)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import re\n",
    "\n",
    "stanza.download(\"en\")\n",
    "\n",
    "# Stanza-Pipeline mit Tweet-Tokenizer\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\",\n",
    "    processors=\"tokenize,pos,lemma\",\n",
    "    tokenize_pretokenized=False,\n",
    "    use_gpu=False,\n",
    "    tokenize_with_spacy=False,\n",
    "    tokenize_no_ssplit=False,\n",
    "    tokenize_engine=\"tokenize/tweet\"   # spezieller Tweet-Tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "# Unicode-Emoji-Regex\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # Symbole & Piktogramme\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # Transport & Symbole\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # Flaggen\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# klassische Smileys\n",
    "smiley_pattern = re.compile(r'[:;=8][\\-~]?[)D]', flags=re.UNICODE)\n",
    "\n",
    "def is_emoji_or_smiley(token):\n",
    "    return bool(emoji_pattern.fullmatch(token)) or bool(smiley_pattern.fullmatch(token))\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"testkorpus_divers_50.csv\")\n",
    "all_results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row.get(\"text\")\n",
    "    if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    doc = nlp(text)\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            xpos = word.xpos\n",
    "            if is_emoji_or_smiley(word.text):\n",
    "                xpos = \"NFP\"\n",
    "\n",
    "            lemma_p = f\"{word.lemma}_{word.upos}\"\n",
    "            all_results.append({\n",
    "                \"post_id\": idx + 1,\n",
    "                \"date\": row.get(\"date\"),\n",
    "                \"word\": word.text,\n",
    "                \"lemma\": word.lemma,\n",
    "                \"pos\": word.upos,   \n",
    "                \"xpos\": xpos,\n",
    "                \"lemma_p\": lemma_p,\n",
    "            })\n",
    "\n",
    "pos_df = pd.DataFrame(all_results)\n",
    "output_file = \"testkorpus_divers_50_stanza_tweets2.csv\"\n",
    "pos_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "display(pos_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier die beiden Varianten des Tagging mit extra Tags f√ºr Tweets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Tabelle:\n",
    "| `xpos` (Tweebank / PTB) | `upos` (Universal) | Bedeutung / Beispiele                                                                  |\n",
    "| ----------------------- | ------------------ | -------------------------------------------------------------------------------------- |\n",
    "| **NN**                  | NOUN               | Noun, singular ‚Üí *dog, idea*                                                           |\n",
    "| **NNS**                 | NOUN               | Noun, plural ‚Üí *dogs, cars*                                                            |\n",
    "| **NNP**                 | PROPN              | Proper noun, singular ‚Üí *Trump, Canada*                                                |\n",
    "| **NNPS**                | PROPN              | Proper noun, plural ‚Üí *the Smiths*                                                     |\n",
    "| **PRP**                 | PRON               | Personal pronoun ‚Üí *I, you, he*                                                        |\n",
    "| **PRP\\$**               | PRON               | Possessive pronoun ‚Üí *my, your*                                                        |\n",
    "| **WP**                  | PRON               | Wh-pronoun ‚Üí *who, what*                                                               |\n",
    "| **WP\\$**                | PRON               | Possessive wh-pronoun ‚Üí *whose*                                                        |\n",
    "| **DT**                  | DET                | Determiner ‚Üí *the, a, some*                                                            |\n",
    "| **PDT**                 | DET                | Predeterminer ‚Üí *all the kids*                                                         |\n",
    "| **WDT**                 | DET                | Wh-determiner ‚Üí *which*                                                                |\n",
    "| **JJ**                  | ADJ                | Adjective ‚Üí *big, nice*                                                                |\n",
    "| **JJR**                 | ADJ                | Comparative adj ‚Üí *bigger*                                                             |\n",
    "| **JJS**                 | ADJ                | Superlative adj ‚Üí *biggest*                                                            |\n",
    "| **RB**                  | ADV                | Adverb ‚Üí *quickly*                                                                     |\n",
    "| **RBR**                 | ADV                | Comparative adv ‚Üí *faster*                                                             |\n",
    "| **RBS**                 | ADV                | Superlative adv ‚Üí *fastest*                                                            |\n",
    "| **WRB**                 | ADV                | Wh-adverb ‚Üí *how, when, why*                                                           |\n",
    "| **VB**                  | VERB               | Verb base ‚Üí *eat, go*                                                                  |\n",
    "| **VBD**                 | VERB               | Verb past ‚Üí *ate, went*                                                                |\n",
    "| **VBG**                 | VERB               | Verb gerund/participle ‚Üí *eating*                                                      |\n",
    "| **VBN**                 | VERB               | Verb past participle ‚Üí *eaten*                                                         |\n",
    "| **VBP**                 | VERB               | Verb non-3sg present ‚Üí *eat, go*                                                       |\n",
    "| **VBZ**                 | VERB               | Verb 3sg present ‚Üí *eats, goes*                                                        |\n",
    "| **MD**                  | AUX                | Modal ‚Üí *can, should*                                                                  |\n",
    "| **IN**                  | ADP                | Preposition, subordinating ‚Üí *in, of, because*                                         |\n",
    "| **TO**                  | PART               | Particle *to*                                                                          |\n",
    "| **CC**                  | CCONJ              | Coordinating conj ‚Üí *and, or*                                                          |\n",
    "| **UH**                  | INTJ               | Interjection ‚Üí *oh, hi*                                                                |\n",
    "| **EX**                  | PRON               | Existential *there*                                                                    |\n",
    "| **FW**                  | X                  | Foreign word                                                                           |\n",
    "| **SYM**                 | SYM                | Symbol ‚Üí *%, \\$, +*                                                                    |\n",
    "| **LS**                  | X                  | List item marker                                                                       |\n",
    "| **CD**                  | NUM                | Cardinal number ‚Üí *5, twenty*                                                          |\n",
    "| **POS**                 | PART               | Possessive marker *‚Äôs*                                                                 |\n",
    "| **RP**                  | PART               | Particle ‚Üí *up, off*                                                                   |\n",
    "| **ADD**                 | PROPN              | **Spezialtag Tweebank**: URL, Email, @mention, Hashtag ‚Üí *@user, #hashtag, https\\://‚Ä¶* |\n",
    "| **NFP**                 | SYM                | **Spezialtag Tweebank**: Non-functional punctuation ‚Üí *ü§£, :), ‚ù§Ô∏è*                     |\n",
    "| **. , : ; - etc.**      | PUNCT              | Satzzeichen                                                                            |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
